{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 待解方程\n",
    "$$\n",
    "\\left\\{\\begin{array}{rl}u_{t}(x, t) & =u_{x x}(x, t)-7 * \\sin (2 \\pi x) * u(x, t) \\\\ u(x, t) & =u(x+1, t), \\\\ u(x, 0) & =1\\end{array} \\quad x, t \\in[0,1] .\\right.\n",
    "$$\n",
    "\n",
    "## 定义价值函数\n",
    "\n",
    "由方程构造函数\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}f:=u_{t}(x, t)-u_{x x}(x, t)+c * \\sin (2 \\pi x) * u(x, t) \\\\ g_1:=u(x, t)-u(x+1, t)  \\\\ g_2:=u(x, t)-u(x-1, t)  \\\\ h:=u(x, 0)-1\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "价值函数\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\\text { loss }_{f}=\\frac{1}{N_{f}} \\sum_{i=1}^{N_{f}}\\left|f\\left(x_{f}^{i}, t_{f}^{i}\\right)\\right|^{2} \\\\ \\operatorname{loss}_{g_1}=\\frac{1}{N_{g}} \\sum_{i=1}^{N_{g}}\\left|g_1\\left(x_{g}^{i}, t_{g}^{i}\\right)\\right|^{2} \\\\ \n",
    "\\operatorname{loss}_{g_2}=\\frac{1}{N_{g}} \\sum_{i=1}^{N_{g}}\\left|g_2\\left(x_{g}^{i}, t_{g}^{i}\\right)\\right|^{2} \\\\ \\operatorname{loss}_{h}=\\frac{1}{N_{h}} \\sum_{i=1}^{N_{h}}\\left|h\\left(x_{h}^{i}\\right)\\right|^{2}\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "总的价值函数\n",
    "$$\n",
    "\\text { loss }_{\\text {total }}=\\alpha * \\operatorname{loss}_{f}+\\beta_{1} * \\operatorname{loss}_{g_1} +\\beta_{2} * \\operatorname{loss}_{g_1} +\\beta_{3} * \\operatorname{los} s_{h}\n",
    "$$\n",
    "\n",
    "参考: https://github.com/udemirezen/PINN-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf = 1.\n",
    "beta1 = 50.\n",
    "beta2 = 50.\n",
    "beta3 = 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(2,21)\n",
    "        self.hidden_layer2 = nn.Linear(21,21)\n",
    "        self.hidden_layer3 = nn.Linear(21,21)\n",
    "        self.hidden_layer4 = nn.Linear(21,21)\n",
    "        self.hidden_layer5 = nn.Linear(21,21)\n",
    "        self.output_layer = nn.Linear(21,1)\n",
    "\n",
    "    def forward(self, x,t):\n",
    "        inputs = torch.cat([x,t],axis=1) # combined two arrays of 1 columns each to one array of 2 columns\n",
    "        layer1_out = torch.sigmoid(self.hidden_layer1(inputs))\n",
    "        layer2_out = torch.sigmoid(self.hidden_layer2(layer1_out))\n",
    "        layer3_out = torch.sigmoid(self.hidden_layer3(layer2_out))\n",
    "        layer4_out = torch.sigmoid(self.hidden_layer4(layer3_out))\n",
    "        layer5_out = torch.sigmoid(self.hidden_layer5(layer4_out))\n",
    "        output = self.output_layer(layer5_out) ## For regression, no activation is used in output layer\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "mse_cost_function = torch.nn.MSELoss() # Mean squared error\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,t, net):\n",
    "    u = net(x,t) \n",
    "    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u.sum(), t, create_graph=True)[0]\n",
    "    c = 7\n",
    "    pde = u_t - u_xx + c*torch.sin(2*np.pi*x)*u \n",
    "    return pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init condition \n",
    "x_bc = np.random.uniform(low=0.0, high=1.0, size=(500,1))\n",
    "t_bc = np.zeros((500,1))\n",
    "u_bc = np.ones((500,1))\n",
    "\n",
    "x_periodic = np.random.uniform(low=0.0, high=1.0, size=(500,1))\n",
    "x_periodic_plusone = x_periodic + 1\n",
    "x_periodic_minusone = x_periodic - 1\n",
    "t_periodic = np.random.uniform(low=0.0, high=1.0, size=(500,1))\n",
    "zeros_periodic = np.zeros((500,1))\n",
    "\n",
    "x_collocation = np.random.uniform(low=0.0, high=1.0, size=(500,1))\n",
    "t_collocation = np.random.uniform(low=0.0, high=1.0, size=(500,1))\n",
    "all_zeros = np.zeros((500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Traning Loss: tensor(206.6402)\n",
      "1 Traning Loss: tensor(201.7672)\n",
      "2 Traning Loss: tensor(196.9795)\n",
      "3 Traning Loss: tensor(192.2777)\n",
      "4 Traning Loss: tensor(187.6619)\n",
      "5 Traning Loss: tensor(183.1318)\n",
      "6 Traning Loss: tensor(178.6870)\n",
      "7 Traning Loss: tensor(174.3268)\n",
      "8 Traning Loss: tensor(170.0502)\n",
      "9 Traning Loss: tensor(165.8563)\n",
      "10 Traning Loss: tensor(161.7449)\n",
      "11 Traning Loss: tensor(157.7150)\n",
      "12 Traning Loss: tensor(153.7659)\n",
      "13 Traning Loss: tensor(149.8971)\n",
      "14 Traning Loss: tensor(146.1073)\n",
      "15 Traning Loss: tensor(142.3958)\n",
      "16 Traning Loss: tensor(138.7617)\n",
      "17 Traning Loss: tensor(135.2043)\n",
      "18 Traning Loss: tensor(131.7221)\n",
      "19 Traning Loss: tensor(128.3145)\n",
      "20 Traning Loss: tensor(124.9805)\n",
      "21 Traning Loss: tensor(121.7191)\n",
      "22 Traning Loss: tensor(118.5292)\n",
      "23 Traning Loss: tensor(115.4096)\n",
      "24 Traning Loss: tensor(112.3597)\n",
      "25 Traning Loss: tensor(109.3782)\n",
      "26 Traning Loss: tensor(106.4641)\n",
      "27 Traning Loss: tensor(103.6163)\n",
      "28 Traning Loss: tensor(100.8337)\n",
      "29 Traning Loss: tensor(98.1154)\n",
      "30 Traning Loss: tensor(95.4604)\n",
      "31 Traning Loss: tensor(92.8676)\n",
      "32 Traning Loss: tensor(90.3360)\n",
      "33 Traning Loss: tensor(87.8646)\n",
      "34 Traning Loss: tensor(85.4527)\n",
      "35 Traning Loss: tensor(83.0990)\n",
      "36 Traning Loss: tensor(80.8028)\n",
      "37 Traning Loss: tensor(78.5630)\n",
      "38 Traning Loss: tensor(76.3790)\n",
      "39 Traning Loss: tensor(74.2498)\n",
      "40 Traning Loss: tensor(72.1744)\n",
      "41 Traning Loss: tensor(70.1522)\n",
      "42 Traning Loss: tensor(68.1823)\n",
      "43 Traning Loss: tensor(66.2638)\n",
      "44 Traning Loss: tensor(64.3960)\n",
      "45 Traning Loss: tensor(62.5782)\n",
      "46 Traning Loss: tensor(60.8096)\n",
      "47 Traning Loss: tensor(59.0893)\n",
      "48 Traning Loss: tensor(57.4169)\n",
      "49 Traning Loss: tensor(55.7914)\n",
      "50 Traning Loss: tensor(54.2121)\n",
      "51 Traning Loss: tensor(52.6784)\n",
      "52 Traning Loss: tensor(51.1896)\n",
      "53 Traning Loss: tensor(49.7450)\n",
      "54 Traning Loss: tensor(48.3438)\n",
      "55 Traning Loss: tensor(46.9854)\n",
      "56 Traning Loss: tensor(45.6692)\n",
      "57 Traning Loss: tensor(44.3944)\n",
      "58 Traning Loss: tensor(43.1604)\n",
      "59 Traning Loss: tensor(41.9664)\n",
      "60 Traning Loss: tensor(40.8119)\n",
      "61 Traning Loss: tensor(39.6960)\n",
      "62 Traning Loss: tensor(38.6182)\n",
      "63 Traning Loss: tensor(37.5777)\n",
      "64 Traning Loss: tensor(36.5739)\n",
      "65 Traning Loss: tensor(35.6059)\n",
      "66 Traning Loss: tensor(34.6733)\n",
      "67 Traning Loss: tensor(33.7751)\n",
      "68 Traning Loss: tensor(32.9108)\n",
      "69 Traning Loss: tensor(32.0795)\n",
      "70 Traning Loss: tensor(31.2806)\n",
      "71 Traning Loss: tensor(30.5134)\n",
      "72 Traning Loss: tensor(29.7770)\n",
      "73 Traning Loss: tensor(29.0708)\n",
      "74 Traning Loss: tensor(28.3940)\n",
      "75 Traning Loss: tensor(27.7458)\n",
      "76 Traning Loss: tensor(27.1256)\n",
      "77 Traning Loss: tensor(26.5326)\n",
      "78 Traning Loss: tensor(25.9659)\n",
      "79 Traning Loss: tensor(25.4249)\n",
      "80 Traning Loss: tensor(24.9088)\n",
      "81 Traning Loss: tensor(24.4168)\n",
      "82 Traning Loss: tensor(23.9482)\n",
      "83 Traning Loss: tensor(23.5023)\n",
      "84 Traning Loss: tensor(23.0782)\n",
      "85 Traning Loss: tensor(22.6753)\n",
      "86 Traning Loss: tensor(22.2927)\n",
      "87 Traning Loss: tensor(21.9299)\n",
      "88 Traning Loss: tensor(21.5860)\n",
      "89 Traning Loss: tensor(21.2604)\n",
      "90 Traning Loss: tensor(20.9522)\n",
      "91 Traning Loss: tensor(20.6610)\n",
      "92 Traning Loss: tensor(20.3858)\n",
      "93 Traning Loss: tensor(20.1262)\n",
      "94 Traning Loss: tensor(19.8814)\n",
      "95 Traning Loss: tensor(19.6508)\n",
      "96 Traning Loss: tensor(19.4337)\n",
      "97 Traning Loss: tensor(19.2296)\n",
      "98 Traning Loss: tensor(19.0378)\n",
      "99 Traning Loss: tensor(18.8578)\n",
      "100 Traning Loss: tensor(18.6889)\n",
      "101 Traning Loss: tensor(18.5307)\n",
      "102 Traning Loss: tensor(18.3826)\n",
      "103 Traning Loss: tensor(18.2441)\n",
      "104 Traning Loss: tensor(18.1146)\n",
      "105 Traning Loss: tensor(17.9938)\n",
      "106 Traning Loss: tensor(17.8810)\n",
      "107 Traning Loss: tensor(17.7760)\n",
      "108 Traning Loss: tensor(17.6782)\n",
      "109 Traning Loss: tensor(17.5872)\n",
      "110 Traning Loss: tensor(17.5027)\n",
      "111 Traning Loss: tensor(17.4242)\n",
      "112 Traning Loss: tensor(17.3514)\n",
      "113 Traning Loss: tensor(17.2840)\n",
      "114 Traning Loss: tensor(17.2216)\n",
      "115 Traning Loss: tensor(17.1638)\n",
      "116 Traning Loss: tensor(17.1105)\n",
      "117 Traning Loss: tensor(17.0613)\n",
      "118 Traning Loss: tensor(17.0159)\n",
      "119 Traning Loss: tensor(16.9741)\n",
      "120 Traning Loss: tensor(16.9357)\n",
      "121 Traning Loss: tensor(16.9003)\n",
      "122 Traning Loss: tensor(16.8679)\n",
      "123 Traning Loss: tensor(16.8381)\n",
      "124 Traning Loss: tensor(16.8109)\n",
      "125 Traning Loss: tensor(16.7859)\n",
      "126 Traning Loss: tensor(16.7631)\n",
      "127 Traning Loss: tensor(16.7423)\n",
      "128 Traning Loss: tensor(16.7233)\n",
      "129 Traning Loss: tensor(16.7060)\n",
      "130 Traning Loss: tensor(16.6902)\n",
      "131 Traning Loss: tensor(16.6759)\n",
      "132 Traning Loss: tensor(16.6629)\n",
      "133 Traning Loss: tensor(16.6511)\n",
      "134 Traning Loss: tensor(16.6404)\n",
      "135 Traning Loss: tensor(16.6308)\n",
      "136 Traning Loss: tensor(16.6220)\n",
      "137 Traning Loss: tensor(16.6141)\n",
      "138 Traning Loss: tensor(16.6071)\n",
      "139 Traning Loss: tensor(16.6007)\n",
      "140 Traning Loss: tensor(16.5949)\n",
      "141 Traning Loss: tensor(16.5898)\n",
      "142 Traning Loss: tensor(16.5852)\n",
      "143 Traning Loss: tensor(16.5810)\n",
      "144 Traning Loss: tensor(16.5773)\n",
      "145 Traning Loss: tensor(16.5741)\n",
      "146 Traning Loss: tensor(16.5711)\n",
      "147 Traning Loss: tensor(16.5685)\n",
      "148 Traning Loss: tensor(16.5662)\n",
      "149 Traning Loss: tensor(16.5641)\n",
      "150 Traning Loss: tensor(16.5623)\n",
      "151 Traning Loss: tensor(16.5607)\n",
      "152 Traning Loss: tensor(16.5592)\n",
      "153 Traning Loss: tensor(16.5580)\n",
      "154 Traning Loss: tensor(16.5569)\n",
      "155 Traning Loss: tensor(16.5559)\n",
      "156 Traning Loss: tensor(16.5550)\n",
      "157 Traning Loss: tensor(16.5543)\n",
      "158 Traning Loss: tensor(16.5536)\n",
      "159 Traning Loss: tensor(16.5531)\n",
      "160 Traning Loss: tensor(16.5525)\n",
      "161 Traning Loss: tensor(16.5521)\n",
      "162 Traning Loss: tensor(16.5517)\n",
      "163 Traning Loss: tensor(16.5514)\n",
      "164 Traning Loss: tensor(16.5511)\n",
      "165 Traning Loss: tensor(16.5508)\n",
      "166 Traning Loss: tensor(16.5506)\n",
      "167 Traning Loss: tensor(16.5504)\n",
      "168 Traning Loss: tensor(16.5502)\n",
      "169 Traning Loss: tensor(16.5500)\n",
      "170 Traning Loss: tensor(16.5499)\n",
      "171 Traning Loss: tensor(16.5498)\n",
      "172 Traning Loss: tensor(16.5496)\n",
      "173 Traning Loss: tensor(16.5495)\n",
      "174 Traning Loss: tensor(16.5494)\n",
      "175 Traning Loss: tensor(16.5493)\n",
      "176 Traning Loss: tensor(16.5492)\n",
      "177 Traning Loss: tensor(16.5492)\n",
      "178 Traning Loss: tensor(16.5491)\n",
      "179 Traning Loss: tensor(16.5490)\n",
      "180 Traning Loss: tensor(16.5489)\n",
      "181 Traning Loss: tensor(16.5489)\n",
      "182 Traning Loss: tensor(16.5488)\n",
      "183 Traning Loss: tensor(16.5487)\n",
      "184 Traning Loss: tensor(16.5486)\n",
      "185 Traning Loss: tensor(16.5486)\n",
      "186 Traning Loss: tensor(16.5485)\n",
      "187 Traning Loss: tensor(16.5484)\n",
      "188 Traning Loss: tensor(16.5484)\n",
      "189 Traning Loss: tensor(16.5483)\n",
      "190 Traning Loss: tensor(16.5482)\n",
      "191 Traning Loss: tensor(16.5482)\n",
      "192 Traning Loss: tensor(16.5481)\n",
      "193 Traning Loss: tensor(16.5480)\n",
      "194 Traning Loss: tensor(16.5479)\n",
      "195 Traning Loss: tensor(16.5479)\n",
      "196 Traning Loss: tensor(16.5478)\n",
      "197 Traning Loss: tensor(16.5477)\n",
      "198 Traning Loss: tensor(16.5477)\n",
      "199 Traning Loss: tensor(16.5476)\n",
      "200 Traning Loss: tensor(16.5475)\n",
      "201 Traning Loss: tensor(16.5474)\n",
      "202 Traning Loss: tensor(16.5474)\n",
      "203 Traning Loss: tensor(16.5473)\n",
      "204 Traning Loss: tensor(16.5472)\n",
      "205 Traning Loss: tensor(16.5471)\n",
      "206 Traning Loss: tensor(16.5471)\n",
      "207 Traning Loss: tensor(16.5470)\n",
      "208 Traning Loss: tensor(16.5469)\n",
      "209 Traning Loss: tensor(16.5468)\n",
      "210 Traning Loss: tensor(16.5468)\n",
      "211 Traning Loss: tensor(16.5467)\n",
      "212 Traning Loss: tensor(16.5466)\n",
      "213 Traning Loss: tensor(16.5466)\n",
      "214 Traning Loss: tensor(16.5465)\n",
      "215 Traning Loss: tensor(16.5464)\n",
      "216 Traning Loss: tensor(16.5463)\n",
      "217 Traning Loss: tensor(16.5463)\n",
      "218 Traning Loss: tensor(16.5462)\n",
      "219 Traning Loss: tensor(16.5461)\n",
      "220 Traning Loss: tensor(16.5460)\n",
      "221 Traning Loss: tensor(16.5460)\n",
      "222 Traning Loss: tensor(16.5459)\n",
      "223 Traning Loss: tensor(16.5458)\n",
      "224 Traning Loss: tensor(16.5457)\n",
      "225 Traning Loss: tensor(16.5457)\n",
      "226 Traning Loss: tensor(16.5456)\n",
      "227 Traning Loss: tensor(16.5455)\n",
      "228 Traning Loss: tensor(16.5454)\n",
      "229 Traning Loss: tensor(16.5454)\n",
      "230 Traning Loss: tensor(16.5453)\n",
      "231 Traning Loss: tensor(16.5452)\n",
      "232 Traning Loss: tensor(16.5452)\n",
      "233 Traning Loss: tensor(16.5451)\n",
      "234 Traning Loss: tensor(16.5450)\n",
      "235 Traning Loss: tensor(16.5449)\n",
      "236 Traning Loss: tensor(16.5449)\n",
      "237 Traning Loss: tensor(16.5448)\n",
      "238 Traning Loss: tensor(16.5447)\n",
      "239 Traning Loss: tensor(16.5446)\n",
      "240 Traning Loss: tensor(16.5446)\n",
      "241 Traning Loss: tensor(16.5445)\n",
      "242 Traning Loss: tensor(16.5444)\n",
      "243 Traning Loss: tensor(16.5443)\n",
      "244 Traning Loss: tensor(16.5443)\n",
      "245 Traning Loss: tensor(16.5442)\n",
      "246 Traning Loss: tensor(16.5441)\n",
      "247 Traning Loss: tensor(16.5440)\n",
      "248 Traning Loss: tensor(16.5440)\n",
      "249 Traning Loss: tensor(16.5439)\n",
      "250 Traning Loss: tensor(16.5438)\n",
      "251 Traning Loss: tensor(16.5437)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252 Traning Loss: tensor(16.5437)\n",
      "253 Traning Loss: tensor(16.5436)\n",
      "254 Traning Loss: tensor(16.5435)\n",
      "255 Traning Loss: tensor(16.5434)\n",
      "256 Traning Loss: tensor(16.5434)\n",
      "257 Traning Loss: tensor(16.5433)\n",
      "258 Traning Loss: tensor(16.5432)\n",
      "259 Traning Loss: tensor(16.5431)\n",
      "260 Traning Loss: tensor(16.5431)\n",
      "261 Traning Loss: tensor(16.5430)\n",
      "262 Traning Loss: tensor(16.5429)\n",
      "263 Traning Loss: tensor(16.5428)\n",
      "264 Traning Loss: tensor(16.5428)\n",
      "265 Traning Loss: tensor(16.5427)\n",
      "266 Traning Loss: tensor(16.5426)\n",
      "267 Traning Loss: tensor(16.5425)\n",
      "268 Traning Loss: tensor(16.5425)\n",
      "269 Traning Loss: tensor(16.5424)\n",
      "270 Traning Loss: tensor(16.5423)\n",
      "271 Traning Loss: tensor(16.5422)\n",
      "272 Traning Loss: tensor(16.5422)\n",
      "273 Traning Loss: tensor(16.5421)\n",
      "274 Traning Loss: tensor(16.5420)\n",
      "275 Traning Loss: tensor(16.5419)\n",
      "276 Traning Loss: tensor(16.5419)\n",
      "277 Traning Loss: tensor(16.5418)\n",
      "278 Traning Loss: tensor(16.5417)\n",
      "279 Traning Loss: tensor(16.5416)\n",
      "280 Traning Loss: tensor(16.5415)\n",
      "281 Traning Loss: tensor(16.5415)\n",
      "282 Traning Loss: tensor(16.5414)\n",
      "283 Traning Loss: tensor(16.5413)\n",
      "284 Traning Loss: tensor(16.5412)\n",
      "285 Traning Loss: tensor(16.5411)\n",
      "286 Traning Loss: tensor(16.5411)\n",
      "287 Traning Loss: tensor(16.5410)\n",
      "288 Traning Loss: tensor(16.5409)\n",
      "289 Traning Loss: tensor(16.5408)\n",
      "290 Traning Loss: tensor(16.5407)\n",
      "291 Traning Loss: tensor(16.5407)\n",
      "292 Traning Loss: tensor(16.5406)\n",
      "293 Traning Loss: tensor(16.5405)\n",
      "294 Traning Loss: tensor(16.5404)\n",
      "295 Traning Loss: tensor(16.5404)\n",
      "296 Traning Loss: tensor(16.5403)\n",
      "297 Traning Loss: tensor(16.5402)\n",
      "298 Traning Loss: tensor(16.5401)\n",
      "299 Traning Loss: tensor(16.5400)\n",
      "300 Traning Loss: tensor(16.5399)\n",
      "301 Traning Loss: tensor(16.5399)\n",
      "302 Traning Loss: tensor(16.5398)\n",
      "303 Traning Loss: tensor(16.5397)\n",
      "304 Traning Loss: tensor(16.5396)\n",
      "305 Traning Loss: tensor(16.5395)\n",
      "306 Traning Loss: tensor(16.5395)\n",
      "307 Traning Loss: tensor(16.5394)\n",
      "308 Traning Loss: tensor(16.5393)\n",
      "309 Traning Loss: tensor(16.5392)\n",
      "310 Traning Loss: tensor(16.5391)\n",
      "311 Traning Loss: tensor(16.5390)\n",
      "312 Traning Loss: tensor(16.5390)\n",
      "313 Traning Loss: tensor(16.5389)\n",
      "314 Traning Loss: tensor(16.5388)\n",
      "315 Traning Loss: tensor(16.5387)\n",
      "316 Traning Loss: tensor(16.5386)\n",
      "317 Traning Loss: tensor(16.5385)\n",
      "318 Traning Loss: tensor(16.5385)\n",
      "319 Traning Loss: tensor(16.5384)\n",
      "320 Traning Loss: tensor(16.5383)\n",
      "321 Traning Loss: tensor(16.5382)\n",
      "322 Traning Loss: tensor(16.5381)\n",
      "323 Traning Loss: tensor(16.5380)\n",
      "324 Traning Loss: tensor(16.5380)\n",
      "325 Traning Loss: tensor(16.5379)\n",
      "326 Traning Loss: tensor(16.5378)\n",
      "327 Traning Loss: tensor(16.5377)\n",
      "328 Traning Loss: tensor(16.5376)\n",
      "329 Traning Loss: tensor(16.5375)\n",
      "330 Traning Loss: tensor(16.5374)\n",
      "331 Traning Loss: tensor(16.5373)\n",
      "332 Traning Loss: tensor(16.5373)\n",
      "333 Traning Loss: tensor(16.5372)\n",
      "334 Traning Loss: tensor(16.5371)\n",
      "335 Traning Loss: tensor(16.5370)\n",
      "336 Traning Loss: tensor(16.5369)\n",
      "337 Traning Loss: tensor(16.5368)\n",
      "338 Traning Loss: tensor(16.5367)\n",
      "339 Traning Loss: tensor(16.5366)\n",
      "340 Traning Loss: tensor(16.5366)\n",
      "341 Traning Loss: tensor(16.5365)\n",
      "342 Traning Loss: tensor(16.5364)\n",
      "343 Traning Loss: tensor(16.5363)\n",
      "344 Traning Loss: tensor(16.5362)\n",
      "345 Traning Loss: tensor(16.5361)\n",
      "346 Traning Loss: tensor(16.5360)\n",
      "347 Traning Loss: tensor(16.5359)\n",
      "348 Traning Loss: tensor(16.5358)\n",
      "349 Traning Loss: tensor(16.5358)\n",
      "350 Traning Loss: tensor(16.5357)\n",
      "351 Traning Loss: tensor(16.5356)\n",
      "352 Traning Loss: tensor(16.5355)\n",
      "353 Traning Loss: tensor(16.5354)\n",
      "354 Traning Loss: tensor(16.5353)\n",
      "355 Traning Loss: tensor(16.5352)\n",
      "356 Traning Loss: tensor(16.5351)\n",
      "357 Traning Loss: tensor(16.5350)\n",
      "358 Traning Loss: tensor(16.5349)\n",
      "359 Traning Loss: tensor(16.5348)\n",
      "360 Traning Loss: tensor(16.5347)\n",
      "361 Traning Loss: tensor(16.5346)\n",
      "362 Traning Loss: tensor(16.5345)\n",
      "363 Traning Loss: tensor(16.5345)\n",
      "364 Traning Loss: tensor(16.5344)\n",
      "365 Traning Loss: tensor(16.5343)\n",
      "366 Traning Loss: tensor(16.5342)\n",
      "367 Traning Loss: tensor(16.5341)\n",
      "368 Traning Loss: tensor(16.5340)\n",
      "369 Traning Loss: tensor(16.5339)\n",
      "370 Traning Loss: tensor(16.5338)\n",
      "371 Traning Loss: tensor(16.5337)\n",
      "372 Traning Loss: tensor(16.5336)\n",
      "373 Traning Loss: tensor(16.5335)\n",
      "374 Traning Loss: tensor(16.5334)\n",
      "375 Traning Loss: tensor(16.5333)\n",
      "376 Traning Loss: tensor(16.5332)\n",
      "377 Traning Loss: tensor(16.5331)\n",
      "378 Traning Loss: tensor(16.5330)\n",
      "379 Traning Loss: tensor(16.5329)\n",
      "380 Traning Loss: tensor(16.5328)\n",
      "381 Traning Loss: tensor(16.5327)\n",
      "382 Traning Loss: tensor(16.5326)\n",
      "383 Traning Loss: tensor(16.5325)\n",
      "384 Traning Loss: tensor(16.5324)\n",
      "385 Traning Loss: tensor(16.5323)\n",
      "386 Traning Loss: tensor(16.5322)\n",
      "387 Traning Loss: tensor(16.5321)\n",
      "388 Traning Loss: tensor(16.5320)\n",
      "389 Traning Loss: tensor(16.5319)\n",
      "390 Traning Loss: tensor(16.5318)\n",
      "391 Traning Loss: tensor(16.5317)\n",
      "392 Traning Loss: tensor(16.5316)\n",
      "393 Traning Loss: tensor(16.5315)\n",
      "394 Traning Loss: tensor(16.5314)\n",
      "395 Traning Loss: tensor(16.5313)\n",
      "396 Traning Loss: tensor(16.5312)\n",
      "397 Traning Loss: tensor(16.5311)\n",
      "398 Traning Loss: tensor(16.5310)\n",
      "399 Traning Loss: tensor(16.5309)\n",
      "400 Traning Loss: tensor(16.5308)\n",
      "401 Traning Loss: tensor(16.5307)\n",
      "402 Traning Loss: tensor(16.5305)\n",
      "403 Traning Loss: tensor(16.5304)\n",
      "404 Traning Loss: tensor(16.5303)\n",
      "405 Traning Loss: tensor(16.5302)\n",
      "406 Traning Loss: tensor(16.5301)\n",
      "407 Traning Loss: tensor(16.5300)\n",
      "408 Traning Loss: tensor(16.5299)\n",
      "409 Traning Loss: tensor(16.5298)\n",
      "410 Traning Loss: tensor(16.5297)\n",
      "411 Traning Loss: tensor(16.5296)\n",
      "412 Traning Loss: tensor(16.5295)\n",
      "413 Traning Loss: tensor(16.5294)\n",
      "414 Traning Loss: tensor(16.5292)\n",
      "415 Traning Loss: tensor(16.5291)\n",
      "416 Traning Loss: tensor(16.5290)\n",
      "417 Traning Loss: tensor(16.5289)\n",
      "418 Traning Loss: tensor(16.5288)\n",
      "419 Traning Loss: tensor(16.5287)\n",
      "420 Traning Loss: tensor(16.5286)\n",
      "421 Traning Loss: tensor(16.5285)\n",
      "422 Traning Loss: tensor(16.5283)\n",
      "423 Traning Loss: tensor(16.5282)\n",
      "424 Traning Loss: tensor(16.5281)\n",
      "425 Traning Loss: tensor(16.5280)\n",
      "426 Traning Loss: tensor(16.5279)\n",
      "427 Traning Loss: tensor(16.5278)\n",
      "428 Traning Loss: tensor(16.5277)\n",
      "429 Traning Loss: tensor(16.5275)\n",
      "430 Traning Loss: tensor(16.5274)\n",
      "431 Traning Loss: tensor(16.5273)\n",
      "432 Traning Loss: tensor(16.5272)\n",
      "433 Traning Loss: tensor(16.5271)\n",
      "434 Traning Loss: tensor(16.5269)\n",
      "435 Traning Loss: tensor(16.5268)\n",
      "436 Traning Loss: tensor(16.5267)\n",
      "437 Traning Loss: tensor(16.5266)\n",
      "438 Traning Loss: tensor(16.5265)\n",
      "439 Traning Loss: tensor(16.5263)\n",
      "440 Traning Loss: tensor(16.5262)\n",
      "441 Traning Loss: tensor(16.5261)\n",
      "442 Traning Loss: tensor(16.5260)\n",
      "443 Traning Loss: tensor(16.5259)\n",
      "444 Traning Loss: tensor(16.5257)\n",
      "445 Traning Loss: tensor(16.5256)\n",
      "446 Traning Loss: tensor(16.5255)\n",
      "447 Traning Loss: tensor(16.5254)\n",
      "448 Traning Loss: tensor(16.5252)\n",
      "449 Traning Loss: tensor(16.5251)\n",
      "450 Traning Loss: tensor(16.5250)\n",
      "451 Traning Loss: tensor(16.5248)\n",
      "452 Traning Loss: tensor(16.5247)\n",
      "453 Traning Loss: tensor(16.5246)\n",
      "454 Traning Loss: tensor(16.5245)\n",
      "455 Traning Loss: tensor(16.5243)\n",
      "456 Traning Loss: tensor(16.5242)\n",
      "457 Traning Loss: tensor(16.5241)\n",
      "458 Traning Loss: tensor(16.5239)\n",
      "459 Traning Loss: tensor(16.5238)\n",
      "460 Traning Loss: tensor(16.5237)\n",
      "461 Traning Loss: tensor(16.5235)\n",
      "462 Traning Loss: tensor(16.5234)\n",
      "463 Traning Loss: tensor(16.5233)\n",
      "464 Traning Loss: tensor(16.5232)\n",
      "465 Traning Loss: tensor(16.5230)\n",
      "466 Traning Loss: tensor(16.5229)\n",
      "467 Traning Loss: tensor(16.5227)\n",
      "468 Traning Loss: tensor(16.5226)\n",
      "469 Traning Loss: tensor(16.5225)\n",
      "470 Traning Loss: tensor(16.5223)\n",
      "471 Traning Loss: tensor(16.5222)\n",
      "472 Traning Loss: tensor(16.5221)\n",
      "473 Traning Loss: tensor(16.5219)\n",
      "474 Traning Loss: tensor(16.5218)\n",
      "475 Traning Loss: tensor(16.5216)\n",
      "476 Traning Loss: tensor(16.5215)\n",
      "477 Traning Loss: tensor(16.5213)\n",
      "478 Traning Loss: tensor(16.5212)\n",
      "479 Traning Loss: tensor(16.5211)\n",
      "480 Traning Loss: tensor(16.5209)\n",
      "481 Traning Loss: tensor(16.5208)\n",
      "482 Traning Loss: tensor(16.5206)\n",
      "483 Traning Loss: tensor(16.5205)\n",
      "484 Traning Loss: tensor(16.5203)\n",
      "485 Traning Loss: tensor(16.5202)\n",
      "486 Traning Loss: tensor(16.5200)\n",
      "487 Traning Loss: tensor(16.5199)\n",
      "488 Traning Loss: tensor(16.5197)\n",
      "489 Traning Loss: tensor(16.5196)\n",
      "490 Traning Loss: tensor(16.5194)\n",
      "491 Traning Loss: tensor(16.5193)\n",
      "492 Traning Loss: tensor(16.5191)\n",
      "493 Traning Loss: tensor(16.5190)\n",
      "494 Traning Loss: tensor(16.5188)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 Traning Loss: tensor(16.5187)\n",
      "496 Traning Loss: tensor(16.5185)\n",
      "497 Traning Loss: tensor(16.5184)\n",
      "498 Traning Loss: tensor(16.5182)\n",
      "499 Traning Loss: tensor(16.5181)\n",
      "500 Traning Loss: tensor(16.5179)\n",
      "501 Traning Loss: tensor(16.5177)\n",
      "502 Traning Loss: tensor(16.5176)\n",
      "503 Traning Loss: tensor(16.5174)\n",
      "504 Traning Loss: tensor(16.5173)\n",
      "505 Traning Loss: tensor(16.5171)\n",
      "506 Traning Loss: tensor(16.5169)\n",
      "507 Traning Loss: tensor(16.5168)\n",
      "508 Traning Loss: tensor(16.5166)\n",
      "509 Traning Loss: tensor(16.5164)\n",
      "510 Traning Loss: tensor(16.5163)\n",
      "511 Traning Loss: tensor(16.5161)\n",
      "512 Traning Loss: tensor(16.5159)\n",
      "513 Traning Loss: tensor(16.5158)\n",
      "514 Traning Loss: tensor(16.5156)\n",
      "515 Traning Loss: tensor(16.5154)\n",
      "516 Traning Loss: tensor(16.5153)\n",
      "517 Traning Loss: tensor(16.5151)\n",
      "518 Traning Loss: tensor(16.5149)\n",
      "519 Traning Loss: tensor(16.5147)\n",
      "520 Traning Loss: tensor(16.5146)\n",
      "521 Traning Loss: tensor(16.5144)\n",
      "522 Traning Loss: tensor(16.5142)\n",
      "523 Traning Loss: tensor(16.5140)\n",
      "524 Traning Loss: tensor(16.5139)\n",
      "525 Traning Loss: tensor(16.5137)\n",
      "526 Traning Loss: tensor(16.5135)\n",
      "527 Traning Loss: tensor(16.5133)\n",
      "528 Traning Loss: tensor(16.5131)\n",
      "529 Traning Loss: tensor(16.5129)\n",
      "530 Traning Loss: tensor(16.5128)\n",
      "531 Traning Loss: tensor(16.5126)\n",
      "532 Traning Loss: tensor(16.5124)\n",
      "533 Traning Loss: tensor(16.5122)\n",
      "534 Traning Loss: tensor(16.5120)\n",
      "535 Traning Loss: tensor(16.5118)\n",
      "536 Traning Loss: tensor(16.5116)\n",
      "537 Traning Loss: tensor(16.5114)\n",
      "538 Traning Loss: tensor(16.5112)\n",
      "539 Traning Loss: tensor(16.5111)\n",
      "540 Traning Loss: tensor(16.5109)\n",
      "541 Traning Loss: tensor(16.5107)\n",
      "542 Traning Loss: tensor(16.5105)\n",
      "543 Traning Loss: tensor(16.5103)\n",
      "544 Traning Loss: tensor(16.5101)\n",
      "545 Traning Loss: tensor(16.5099)\n",
      "546 Traning Loss: tensor(16.5097)\n",
      "547 Traning Loss: tensor(16.5095)\n",
      "548 Traning Loss: tensor(16.5093)\n",
      "549 Traning Loss: tensor(16.5090)\n",
      "550 Traning Loss: tensor(16.5088)\n",
      "551 Traning Loss: tensor(16.5086)\n",
      "552 Traning Loss: tensor(16.5084)\n",
      "553 Traning Loss: tensor(16.5082)\n",
      "554 Traning Loss: tensor(16.5080)\n",
      "555 Traning Loss: tensor(16.5078)\n",
      "556 Traning Loss: tensor(16.5076)\n",
      "557 Traning Loss: tensor(16.5073)\n",
      "558 Traning Loss: tensor(16.5071)\n",
      "559 Traning Loss: tensor(16.5069)\n",
      "560 Traning Loss: tensor(16.5067)\n",
      "561 Traning Loss: tensor(16.5065)\n",
      "562 Traning Loss: tensor(16.5062)\n",
      "563 Traning Loss: tensor(16.5060)\n",
      "564 Traning Loss: tensor(16.5058)\n",
      "565 Traning Loss: tensor(16.5056)\n",
      "566 Traning Loss: tensor(16.5053)\n",
      "567 Traning Loss: tensor(16.5051)\n",
      "568 Traning Loss: tensor(16.5049)\n",
      "569 Traning Loss: tensor(16.5046)\n",
      "570 Traning Loss: tensor(16.5044)\n",
      "571 Traning Loss: tensor(16.5042)\n",
      "572 Traning Loss: tensor(16.5039)\n",
      "573 Traning Loss: tensor(16.5037)\n",
      "574 Traning Loss: tensor(16.5035)\n",
      "575 Traning Loss: tensor(16.5032)\n",
      "576 Traning Loss: tensor(16.5030)\n",
      "577 Traning Loss: tensor(16.5027)\n",
      "578 Traning Loss: tensor(16.5025)\n",
      "579 Traning Loss: tensor(16.5022)\n",
      "580 Traning Loss: tensor(16.5020)\n",
      "581 Traning Loss: tensor(16.5017)\n",
      "582 Traning Loss: tensor(16.5015)\n",
      "583 Traning Loss: tensor(16.5012)\n",
      "584 Traning Loss: tensor(16.5009)\n",
      "585 Traning Loss: tensor(16.5007)\n",
      "586 Traning Loss: tensor(16.5004)\n",
      "587 Traning Loss: tensor(16.5002)\n",
      "588 Traning Loss: tensor(16.4999)\n",
      "589 Traning Loss: tensor(16.4996)\n",
      "590 Traning Loss: tensor(16.4994)\n",
      "591 Traning Loss: tensor(16.4991)\n",
      "592 Traning Loss: tensor(16.4988)\n",
      "593 Traning Loss: tensor(16.4985)\n",
      "594 Traning Loss: tensor(16.4983)\n",
      "595 Traning Loss: tensor(16.4980)\n",
      "596 Traning Loss: tensor(16.4977)\n",
      "597 Traning Loss: tensor(16.4974)\n",
      "598 Traning Loss: tensor(16.4971)\n",
      "599 Traning Loss: tensor(16.4968)\n",
      "600 Traning Loss: tensor(16.4965)\n",
      "601 Traning Loss: tensor(16.4963)\n",
      "602 Traning Loss: tensor(16.4960)\n",
      "603 Traning Loss: tensor(16.4957)\n",
      "604 Traning Loss: tensor(16.4954)\n",
      "605 Traning Loss: tensor(16.4951)\n",
      "606 Traning Loss: tensor(16.4948)\n",
      "607 Traning Loss: tensor(16.4945)\n",
      "608 Traning Loss: tensor(16.4941)\n",
      "609 Traning Loss: tensor(16.4938)\n",
      "610 Traning Loss: tensor(16.4935)\n",
      "611 Traning Loss: tensor(16.4932)\n",
      "612 Traning Loss: tensor(16.4929)\n",
      "613 Traning Loss: tensor(16.4926)\n",
      "614 Traning Loss: tensor(16.4922)\n",
      "615 Traning Loss: tensor(16.4919)\n",
      "616 Traning Loss: tensor(16.4916)\n",
      "617 Traning Loss: tensor(16.4913)\n",
      "618 Traning Loss: tensor(16.4909)\n",
      "619 Traning Loss: tensor(16.4906)\n",
      "620 Traning Loss: tensor(16.4903)\n",
      "621 Traning Loss: tensor(16.4899)\n",
      "622 Traning Loss: tensor(16.4896)\n",
      "623 Traning Loss: tensor(16.4892)\n",
      "624 Traning Loss: tensor(16.4889)\n",
      "625 Traning Loss: tensor(16.4885)\n",
      "626 Traning Loss: tensor(16.4882)\n",
      "627 Traning Loss: tensor(16.4878)\n",
      "628 Traning Loss: tensor(16.4874)\n",
      "629 Traning Loss: tensor(16.4871)\n",
      "630 Traning Loss: tensor(16.4867)\n",
      "631 Traning Loss: tensor(16.4863)\n",
      "632 Traning Loss: tensor(16.4860)\n",
      "633 Traning Loss: tensor(16.4856)\n",
      "634 Traning Loss: tensor(16.4852)\n",
      "635 Traning Loss: tensor(16.4848)\n",
      "636 Traning Loss: tensor(16.4844)\n",
      "637 Traning Loss: tensor(16.4841)\n",
      "638 Traning Loss: tensor(16.4837)\n",
      "639 Traning Loss: tensor(16.4833)\n",
      "640 Traning Loss: tensor(16.4829)\n",
      "641 Traning Loss: tensor(16.4825)\n",
      "642 Traning Loss: tensor(16.4821)\n",
      "643 Traning Loss: tensor(16.4817)\n",
      "644 Traning Loss: tensor(16.4812)\n",
      "645 Traning Loss: tensor(16.4808)\n",
      "646 Traning Loss: tensor(16.4804)\n",
      "647 Traning Loss: tensor(16.4800)\n",
      "648 Traning Loss: tensor(16.4795)\n",
      "649 Traning Loss: tensor(16.4791)\n",
      "650 Traning Loss: tensor(16.4787)\n",
      "651 Traning Loss: tensor(16.4782)\n",
      "652 Traning Loss: tensor(16.4778)\n",
      "653 Traning Loss: tensor(16.4774)\n",
      "654 Traning Loss: tensor(16.4769)\n",
      "655 Traning Loss: tensor(16.4764)\n",
      "656 Traning Loss: tensor(16.4760)\n",
      "657 Traning Loss: tensor(16.4755)\n",
      "658 Traning Loss: tensor(16.4750)\n",
      "659 Traning Loss: tensor(16.4746)\n",
      "660 Traning Loss: tensor(16.4741)\n",
      "661 Traning Loss: tensor(16.4736)\n",
      "662 Traning Loss: tensor(16.4731)\n",
      "663 Traning Loss: tensor(16.4726)\n",
      "664 Traning Loss: tensor(16.4722)\n",
      "665 Traning Loss: tensor(16.4717)\n",
      "666 Traning Loss: tensor(16.4711)\n",
      "667 Traning Loss: tensor(16.4706)\n",
      "668 Traning Loss: tensor(16.4701)\n",
      "669 Traning Loss: tensor(16.4696)\n",
      "670 Traning Loss: tensor(16.4691)\n",
      "671 Traning Loss: tensor(16.4686)\n",
      "672 Traning Loss: tensor(16.4680)\n",
      "673 Traning Loss: tensor(16.4675)\n",
      "674 Traning Loss: tensor(16.4669)\n",
      "675 Traning Loss: tensor(16.4664)\n",
      "676 Traning Loss: tensor(16.4658)\n",
      "677 Traning Loss: tensor(16.4653)\n",
      "678 Traning Loss: tensor(16.4647)\n",
      "679 Traning Loss: tensor(16.4641)\n",
      "680 Traning Loss: tensor(16.4636)\n",
      "681 Traning Loss: tensor(16.4630)\n",
      "682 Traning Loss: tensor(16.4624)\n",
      "683 Traning Loss: tensor(16.4618)\n",
      "684 Traning Loss: tensor(16.4612)\n",
      "685 Traning Loss: tensor(16.4606)\n",
      "686 Traning Loss: tensor(16.4600)\n",
      "687 Traning Loss: tensor(16.4594)\n",
      "688 Traning Loss: tensor(16.4588)\n",
      "689 Traning Loss: tensor(16.4581)\n",
      "690 Traning Loss: tensor(16.4575)\n",
      "691 Traning Loss: tensor(16.4569)\n",
      "692 Traning Loss: tensor(16.4562)\n",
      "693 Traning Loss: tensor(16.4556)\n",
      "694 Traning Loss: tensor(16.4549)\n",
      "695 Traning Loss: tensor(16.4542)\n",
      "696 Traning Loss: tensor(16.4536)\n",
      "697 Traning Loss: tensor(16.4529)\n",
      "698 Traning Loss: tensor(16.4522)\n",
      "699 Traning Loss: tensor(16.4515)\n",
      "700 Traning Loss: tensor(16.4508)\n",
      "701 Traning Loss: tensor(16.4501)\n",
      "702 Traning Loss: tensor(16.4494)\n",
      "703 Traning Loss: tensor(16.4487)\n",
      "704 Traning Loss: tensor(16.4479)\n",
      "705 Traning Loss: tensor(16.4472)\n",
      "706 Traning Loss: tensor(16.4465)\n",
      "707 Traning Loss: tensor(16.4457)\n",
      "708 Traning Loss: tensor(16.4450)\n",
      "709 Traning Loss: tensor(16.4442)\n",
      "710 Traning Loss: tensor(16.4434)\n",
      "711 Traning Loss: tensor(16.4426)\n",
      "712 Traning Loss: tensor(16.4418)\n",
      "713 Traning Loss: tensor(16.4410)\n",
      "714 Traning Loss: tensor(16.4402)\n",
      "715 Traning Loss: tensor(16.4394)\n",
      "716 Traning Loss: tensor(16.4386)\n",
      "717 Traning Loss: tensor(16.4378)\n",
      "718 Traning Loss: tensor(16.4369)\n",
      "719 Traning Loss: tensor(16.4361)\n",
      "720 Traning Loss: tensor(16.4352)\n",
      "721 Traning Loss: tensor(16.4343)\n",
      "722 Traning Loss: tensor(16.4335)\n",
      "723 Traning Loss: tensor(16.4326)\n",
      "724 Traning Loss: tensor(16.4317)\n",
      "725 Traning Loss: tensor(16.4308)\n",
      "726 Traning Loss: tensor(16.4299)\n",
      "727 Traning Loss: tensor(16.4289)\n",
      "728 Traning Loss: tensor(16.4280)\n",
      "729 Traning Loss: tensor(16.4271)\n",
      "730 Traning Loss: tensor(16.4261)\n",
      "731 Traning Loss: tensor(16.4251)\n",
      "732 Traning Loss: tensor(16.4242)\n",
      "733 Traning Loss: tensor(16.4232)\n",
      "734 Traning Loss: tensor(16.4222)\n",
      "735 Traning Loss: tensor(16.4212)\n",
      "736 Traning Loss: tensor(16.4202)\n",
      "737 Traning Loss: tensor(16.4191)\n",
      "738 Traning Loss: tensor(16.4181)\n",
      "739 Traning Loss: tensor(16.4171)\n",
      "740 Traning Loss: tensor(16.4160)\n",
      "741 Traning Loss: tensor(16.4149)\n",
      "742 Traning Loss: tensor(16.4138)\n",
      "743 Traning Loss: tensor(16.4127)\n",
      "744 Traning Loss: tensor(16.4116)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745 Traning Loss: tensor(16.4105)\n",
      "746 Traning Loss: tensor(16.4094)\n",
      "747 Traning Loss: tensor(16.4082)\n",
      "748 Traning Loss: tensor(16.4071)\n",
      "749 Traning Loss: tensor(16.4059)\n",
      "750 Traning Loss: tensor(16.4047)\n",
      "751 Traning Loss: tensor(16.4035)\n",
      "752 Traning Loss: tensor(16.4023)\n",
      "753 Traning Loss: tensor(16.4011)\n",
      "754 Traning Loss: tensor(16.3999)\n",
      "755 Traning Loss: tensor(16.3986)\n",
      "756 Traning Loss: tensor(16.3974)\n",
      "757 Traning Loss: tensor(16.3961)\n",
      "758 Traning Loss: tensor(16.3948)\n",
      "759 Traning Loss: tensor(16.3935)\n",
      "760 Traning Loss: tensor(16.3922)\n",
      "761 Traning Loss: tensor(16.3908)\n",
      "762 Traning Loss: tensor(16.3895)\n",
      "763 Traning Loss: tensor(16.3881)\n",
      "764 Traning Loss: tensor(16.3868)\n",
      "765 Traning Loss: tensor(16.3854)\n",
      "766 Traning Loss: tensor(16.3840)\n",
      "767 Traning Loss: tensor(16.3825)\n",
      "768 Traning Loss: tensor(16.3811)\n",
      "769 Traning Loss: tensor(16.3796)\n",
      "770 Traning Loss: tensor(16.3782)\n",
      "771 Traning Loss: tensor(16.3767)\n",
      "772 Traning Loss: tensor(16.3752)\n",
      "773 Traning Loss: tensor(16.3737)\n",
      "774 Traning Loss: tensor(16.3721)\n",
      "775 Traning Loss: tensor(16.3706)\n",
      "776 Traning Loss: tensor(16.3690)\n",
      "777 Traning Loss: tensor(16.3674)\n",
      "778 Traning Loss: tensor(16.3658)\n",
      "779 Traning Loss: tensor(16.3642)\n",
      "780 Traning Loss: tensor(16.3625)\n",
      "781 Traning Loss: tensor(16.3609)\n",
      "782 Traning Loss: tensor(16.3592)\n",
      "783 Traning Loss: tensor(16.3575)\n",
      "784 Traning Loss: tensor(16.3558)\n",
      "785 Traning Loss: tensor(16.3540)\n",
      "786 Traning Loss: tensor(16.3523)\n",
      "787 Traning Loss: tensor(16.3505)\n",
      "788 Traning Loss: tensor(16.3487)\n",
      "789 Traning Loss: tensor(16.3469)\n",
      "790 Traning Loss: tensor(16.3450)\n",
      "791 Traning Loss: tensor(16.3432)\n",
      "792 Traning Loss: tensor(16.3413)\n",
      "793 Traning Loss: tensor(16.3394)\n",
      "794 Traning Loss: tensor(16.3374)\n",
      "795 Traning Loss: tensor(16.3355)\n",
      "796 Traning Loss: tensor(16.3335)\n",
      "797 Traning Loss: tensor(16.3315)\n",
      "798 Traning Loss: tensor(16.3295)\n",
      "799 Traning Loss: tensor(16.3275)\n",
      "800 Traning Loss: tensor(16.3254)\n",
      "801 Traning Loss: tensor(16.3233)\n",
      "802 Traning Loss: tensor(16.3212)\n",
      "803 Traning Loss: tensor(16.3191)\n",
      "804 Traning Loss: tensor(16.3169)\n",
      "805 Traning Loss: tensor(16.3147)\n",
      "806 Traning Loss: tensor(16.3125)\n",
      "807 Traning Loss: tensor(16.3103)\n",
      "808 Traning Loss: tensor(16.3080)\n",
      "809 Traning Loss: tensor(16.3057)\n",
      "810 Traning Loss: tensor(16.3034)\n",
      "811 Traning Loss: tensor(16.3011)\n",
      "812 Traning Loss: tensor(16.2987)\n",
      "813 Traning Loss: tensor(16.2963)\n",
      "814 Traning Loss: tensor(16.2939)\n",
      "815 Traning Loss: tensor(16.2914)\n",
      "816 Traning Loss: tensor(16.2889)\n",
      "817 Traning Loss: tensor(16.2864)\n",
      "818 Traning Loss: tensor(16.2839)\n",
      "819 Traning Loss: tensor(16.2813)\n",
      "820 Traning Loss: tensor(16.2787)\n",
      "821 Traning Loss: tensor(16.2761)\n",
      "822 Traning Loss: tensor(16.2734)\n",
      "823 Traning Loss: tensor(16.2707)\n",
      "824 Traning Loss: tensor(16.2680)\n",
      "825 Traning Loss: tensor(16.2652)\n",
      "826 Traning Loss: tensor(16.2624)\n",
      "827 Traning Loss: tensor(16.2596)\n",
      "828 Traning Loss: tensor(16.2567)\n",
      "829 Traning Loss: tensor(16.2538)\n",
      "830 Traning Loss: tensor(16.2509)\n",
      "831 Traning Loss: tensor(16.2479)\n",
      "832 Traning Loss: tensor(16.2449)\n",
      "833 Traning Loss: tensor(16.2418)\n",
      "834 Traning Loss: tensor(16.2388)\n",
      "835 Traning Loss: tensor(16.2356)\n",
      "836 Traning Loss: tensor(16.2325)\n",
      "837 Traning Loss: tensor(16.2293)\n",
      "838 Traning Loss: tensor(16.2260)\n",
      "839 Traning Loss: tensor(16.2227)\n",
      "840 Traning Loss: tensor(16.2194)\n",
      "841 Traning Loss: tensor(16.2161)\n",
      "842 Traning Loss: tensor(16.2126)\n",
      "843 Traning Loss: tensor(16.2092)\n",
      "844 Traning Loss: tensor(16.2057)\n",
      "845 Traning Loss: tensor(16.2022)\n",
      "846 Traning Loss: tensor(16.1986)\n",
      "847 Traning Loss: tensor(16.1949)\n",
      "848 Traning Loss: tensor(16.1913)\n",
      "849 Traning Loss: tensor(16.1875)\n",
      "850 Traning Loss: tensor(16.1838)\n",
      "851 Traning Loss: tensor(16.1799)\n",
      "852 Traning Loss: tensor(16.1761)\n",
      "853 Traning Loss: tensor(16.1721)\n",
      "854 Traning Loss: tensor(16.1682)\n",
      "855 Traning Loss: tensor(16.1641)\n",
      "856 Traning Loss: tensor(16.1601)\n",
      "857 Traning Loss: tensor(16.1559)\n",
      "858 Traning Loss: tensor(16.1517)\n",
      "859 Traning Loss: tensor(16.1475)\n",
      "860 Traning Loss: tensor(16.1432)\n",
      "861 Traning Loss: tensor(16.1388)\n",
      "862 Traning Loss: tensor(16.1344)\n",
      "863 Traning Loss: tensor(16.1299)\n",
      "864 Traning Loss: tensor(16.1254)\n",
      "865 Traning Loss: tensor(16.1208)\n",
      "866 Traning Loss: tensor(16.1161)\n",
      "867 Traning Loss: tensor(16.1114)\n",
      "868 Traning Loss: tensor(16.1066)\n",
      "869 Traning Loss: tensor(16.1018)\n",
      "870 Traning Loss: tensor(16.0969)\n",
      "871 Traning Loss: tensor(16.0919)\n",
      "872 Traning Loss: tensor(16.0868)\n",
      "873 Traning Loss: tensor(16.0817)\n",
      "874 Traning Loss: tensor(16.0765)\n",
      "875 Traning Loss: tensor(16.0712)\n",
      "876 Traning Loss: tensor(16.0659)\n",
      "877 Traning Loss: tensor(16.0605)\n",
      "878 Traning Loss: tensor(16.0550)\n",
      "879 Traning Loss: tensor(16.0494)\n",
      "880 Traning Loss: tensor(16.0438)\n",
      "881 Traning Loss: tensor(16.0381)\n",
      "882 Traning Loss: tensor(16.0323)\n",
      "883 Traning Loss: tensor(16.0264)\n",
      "884 Traning Loss: tensor(16.0204)\n",
      "885 Traning Loss: tensor(16.0144)\n",
      "886 Traning Loss: tensor(16.0082)\n",
      "887 Traning Loss: tensor(16.0020)\n",
      "888 Traning Loss: tensor(15.9957)\n",
      "889 Traning Loss: tensor(15.9893)\n",
      "890 Traning Loss: tensor(15.9828)\n",
      "891 Traning Loss: tensor(15.9762)\n",
      "892 Traning Loss: tensor(15.9696)\n",
      "893 Traning Loss: tensor(15.9628)\n",
      "894 Traning Loss: tensor(15.9560)\n",
      "895 Traning Loss: tensor(15.9490)\n",
      "896 Traning Loss: tensor(15.9420)\n",
      "897 Traning Loss: tensor(15.9348)\n",
      "898 Traning Loss: tensor(15.9275)\n",
      "899 Traning Loss: tensor(15.9202)\n",
      "900 Traning Loss: tensor(15.9127)\n",
      "901 Traning Loss: tensor(15.9052)\n",
      "902 Traning Loss: tensor(15.8975)\n",
      "903 Traning Loss: tensor(15.8897)\n",
      "904 Traning Loss: tensor(15.8818)\n",
      "905 Traning Loss: tensor(15.8738)\n",
      "906 Traning Loss: tensor(15.8657)\n",
      "907 Traning Loss: tensor(15.8575)\n",
      "908 Traning Loss: tensor(15.8491)\n",
      "909 Traning Loss: tensor(15.8406)\n",
      "910 Traning Loss: tensor(15.8320)\n",
      "911 Traning Loss: tensor(15.8233)\n",
      "912 Traning Loss: tensor(15.8145)\n",
      "913 Traning Loss: tensor(15.8056)\n",
      "914 Traning Loss: tensor(15.7965)\n",
      "915 Traning Loss: tensor(15.7873)\n",
      "916 Traning Loss: tensor(15.7779)\n",
      "917 Traning Loss: tensor(15.7684)\n",
      "918 Traning Loss: tensor(15.7588)\n",
      "919 Traning Loss: tensor(15.7491)\n",
      "920 Traning Loss: tensor(15.7392)\n",
      "921 Traning Loss: tensor(15.7292)\n",
      "922 Traning Loss: tensor(15.7190)\n",
      "923 Traning Loss: tensor(15.7087)\n",
      "924 Traning Loss: tensor(15.6982)\n",
      "925 Traning Loss: tensor(15.6877)\n",
      "926 Traning Loss: tensor(15.6769)\n",
      "927 Traning Loss: tensor(15.6660)\n",
      "928 Traning Loss: tensor(15.6549)\n",
      "929 Traning Loss: tensor(15.6437)\n",
      "930 Traning Loss: tensor(15.6324)\n",
      "931 Traning Loss: tensor(15.6208)\n",
      "932 Traning Loss: tensor(15.6092)\n",
      "933 Traning Loss: tensor(15.5973)\n",
      "934 Traning Loss: tensor(15.5853)\n",
      "935 Traning Loss: tensor(15.5731)\n",
      "936 Traning Loss: tensor(15.5607)\n",
      "937 Traning Loss: tensor(15.5482)\n",
      "938 Traning Loss: tensor(15.5355)\n",
      "939 Traning Loss: tensor(15.5226)\n",
      "940 Traning Loss: tensor(15.5095)\n",
      "941 Traning Loss: tensor(15.4963)\n",
      "942 Traning Loss: tensor(15.4828)\n",
      "943 Traning Loss: tensor(15.4692)\n",
      "944 Traning Loss: tensor(15.4554)\n",
      "945 Traning Loss: tensor(15.4414)\n",
      "946 Traning Loss: tensor(15.4272)\n",
      "947 Traning Loss: tensor(15.4127)\n",
      "948 Traning Loss: tensor(15.3981)\n",
      "949 Traning Loss: tensor(15.3833)\n",
      "950 Traning Loss: tensor(15.3683)\n",
      "951 Traning Loss: tensor(15.3531)\n",
      "952 Traning Loss: tensor(15.3376)\n",
      "953 Traning Loss: tensor(15.3219)\n",
      "954 Traning Loss: tensor(15.3060)\n",
      "955 Traning Loss: tensor(15.2899)\n",
      "956 Traning Loss: tensor(15.2736)\n",
      "957 Traning Loss: tensor(15.2570)\n",
      "958 Traning Loss: tensor(15.2402)\n",
      "959 Traning Loss: tensor(15.2231)\n",
      "960 Traning Loss: tensor(15.2058)\n",
      "961 Traning Loss: tensor(15.1883)\n",
      "962 Traning Loss: tensor(15.1705)\n",
      "963 Traning Loss: tensor(15.1525)\n",
      "964 Traning Loss: tensor(15.1342)\n",
      "965 Traning Loss: tensor(15.1156)\n",
      "966 Traning Loss: tensor(15.0968)\n",
      "967 Traning Loss: tensor(15.0777)\n",
      "968 Traning Loss: tensor(15.0583)\n",
      "969 Traning Loss: tensor(15.0386)\n",
      "970 Traning Loss: tensor(15.0187)\n",
      "971 Traning Loss: tensor(14.9985)\n",
      "972 Traning Loss: tensor(14.9779)\n",
      "973 Traning Loss: tensor(14.9571)\n",
      "974 Traning Loss: tensor(14.9360)\n",
      "975 Traning Loss: tensor(14.9145)\n",
      "976 Traning Loss: tensor(14.8928)\n",
      "977 Traning Loss: tensor(14.8707)\n",
      "978 Traning Loss: tensor(14.8483)\n",
      "979 Traning Loss: tensor(14.8255)\n",
      "980 Traning Loss: tensor(14.8025)\n",
      "981 Traning Loss: tensor(14.7790)\n",
      "982 Traning Loss: tensor(14.7553)\n",
      "983 Traning Loss: tensor(14.7312)\n",
      "984 Traning Loss: tensor(14.7067)\n",
      "985 Traning Loss: tensor(14.6819)\n",
      "986 Traning Loss: tensor(14.6567)\n",
      "987 Traning Loss: tensor(14.6311)\n",
      "988 Traning Loss: tensor(14.6051)\n",
      "989 Traning Loss: tensor(14.5788)\n",
      "990 Traning Loss: tensor(14.5520)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 Traning Loss: tensor(14.5249)\n",
      "992 Traning Loss: tensor(14.4974)\n",
      "993 Traning Loss: tensor(14.4694)\n",
      "994 Traning Loss: tensor(14.4411)\n",
      "995 Traning Loss: tensor(14.4124)\n",
      "996 Traning Loss: tensor(14.3832)\n",
      "997 Traning Loss: tensor(14.3536)\n",
      "998 Traning Loss: tensor(14.3236)\n",
      "999 Traning Loss: tensor(14.2931)\n",
      "1000 Traning Loss: tensor(14.2622)\n",
      "1001 Traning Loss: tensor(14.2309)\n",
      "1002 Traning Loss: tensor(14.1992)\n",
      "1003 Traning Loss: tensor(14.1670)\n",
      "1004 Traning Loss: tensor(14.1343)\n",
      "1005 Traning Loss: tensor(14.1012)\n",
      "1006 Traning Loss: tensor(14.0677)\n",
      "1007 Traning Loss: tensor(14.0337)\n",
      "1008 Traning Loss: tensor(13.9993)\n",
      "1009 Traning Loss: tensor(13.9644)\n",
      "1010 Traning Loss: tensor(13.9291)\n",
      "1011 Traning Loss: tensor(13.8933)\n",
      "1012 Traning Loss: tensor(13.8571)\n",
      "1013 Traning Loss: tensor(13.8204)\n",
      "1014 Traning Loss: tensor(13.7832)\n",
      "1015 Traning Loss: tensor(13.7457)\n",
      "1016 Traning Loss: tensor(13.7076)\n",
      "1017 Traning Loss: tensor(13.6691)\n",
      "1018 Traning Loss: tensor(13.6302)\n",
      "1019 Traning Loss: tensor(13.5908)\n",
      "1020 Traning Loss: tensor(13.5510)\n",
      "1021 Traning Loss: tensor(13.5108)\n",
      "1022 Traning Loss: tensor(13.4701)\n",
      "1023 Traning Loss: tensor(13.4290)\n",
      "1024 Traning Loss: tensor(13.3875)\n",
      "1025 Traning Loss: tensor(13.3455)\n",
      "1026 Traning Loss: tensor(13.3031)\n",
      "1027 Traning Loss: tensor(13.2603)\n",
      "1028 Traning Loss: tensor(13.2171)\n",
      "1029 Traning Loss: tensor(13.1734)\n",
      "1030 Traning Loss: tensor(13.1294)\n",
      "1031 Traning Loss: tensor(13.0850)\n",
      "1032 Traning Loss: tensor(13.0401)\n",
      "1033 Traning Loss: tensor(12.9949)\n",
      "1034 Traning Loss: tensor(12.9493)\n",
      "1035 Traning Loss: tensor(12.9033)\n",
      "1036 Traning Loss: tensor(12.8569)\n",
      "1037 Traning Loss: tensor(12.8102)\n",
      "1038 Traning Loss: tensor(12.7631)\n",
      "1039 Traning Loss: tensor(12.7156)\n",
      "1040 Traning Loss: tensor(12.6677)\n",
      "1041 Traning Loss: tensor(12.6195)\n",
      "1042 Traning Loss: tensor(12.5710)\n",
      "1043 Traning Loss: tensor(12.5220)\n",
      "1044 Traning Loss: tensor(12.4728)\n",
      "1045 Traning Loss: tensor(12.4232)\n",
      "1046 Traning Loss: tensor(12.3733)\n",
      "1047 Traning Loss: tensor(12.3231)\n",
      "1048 Traning Loss: tensor(12.2725)\n",
      "1049 Traning Loss: tensor(12.2216)\n",
      "1050 Traning Loss: tensor(12.1704)\n",
      "1051 Traning Loss: tensor(12.1189)\n",
      "1052 Traning Loss: tensor(12.0670)\n",
      "1053 Traning Loss: tensor(12.0149)\n",
      "1054 Traning Loss: tensor(11.9625)\n",
      "1055 Traning Loss: tensor(11.9097)\n",
      "1056 Traning Loss: tensor(11.8567)\n",
      "1057 Traning Loss: tensor(11.8034)\n",
      "1058 Traning Loss: tensor(11.7498)\n",
      "1059 Traning Loss: tensor(11.6959)\n",
      "1060 Traning Loss: tensor(11.6418)\n",
      "1061 Traning Loss: tensor(11.5873)\n",
      "1062 Traning Loss: tensor(11.5326)\n",
      "1063 Traning Loss: tensor(11.4777)\n",
      "1064 Traning Loss: tensor(11.4224)\n",
      "1065 Traning Loss: tensor(11.3669)\n",
      "1066 Traning Loss: tensor(11.3112)\n",
      "1067 Traning Loss: tensor(11.2552)\n",
      "1068 Traning Loss: tensor(11.1990)\n",
      "1069 Traning Loss: tensor(11.1425)\n",
      "1070 Traning Loss: tensor(11.0858)\n",
      "1071 Traning Loss: tensor(11.0288)\n",
      "1072 Traning Loss: tensor(10.9716)\n",
      "1073 Traning Loss: tensor(10.9142)\n",
      "1074 Traning Loss: tensor(10.8566)\n",
      "1075 Traning Loss: tensor(10.7987)\n",
      "1076 Traning Loss: tensor(10.7406)\n",
      "1077 Traning Loss: tensor(10.6824)\n",
      "1078 Traning Loss: tensor(10.6239)\n",
      "1079 Traning Loss: tensor(10.5652)\n",
      "1080 Traning Loss: tensor(10.5064)\n",
      "1081 Traning Loss: tensor(10.4473)\n",
      "1082 Traning Loss: tensor(10.3881)\n",
      "1083 Traning Loss: tensor(10.3287)\n",
      "1084 Traning Loss: tensor(10.2691)\n",
      "1085 Traning Loss: tensor(10.2094)\n",
      "1086 Traning Loss: tensor(10.1495)\n",
      "1087 Traning Loss: tensor(10.0895)\n",
      "1088 Traning Loss: tensor(10.0294)\n",
      "1089 Traning Loss: tensor(9.9691)\n",
      "1090 Traning Loss: tensor(9.9087)\n",
      "1091 Traning Loss: tensor(9.8481)\n",
      "1092 Traning Loss: tensor(9.7875)\n",
      "1093 Traning Loss: tensor(9.7268)\n",
      "1094 Traning Loss: tensor(9.6660)\n",
      "1095 Traning Loss: tensor(9.6051)\n",
      "1096 Traning Loss: tensor(9.5441)\n",
      "1097 Traning Loss: tensor(9.4831)\n",
      "1098 Traning Loss: tensor(9.4221)\n",
      "1099 Traning Loss: tensor(9.3610)\n",
      "1100 Traning Loss: tensor(9.2998)\n",
      "1101 Traning Loss: tensor(9.2387)\n",
      "1102 Traning Loss: tensor(9.1776)\n",
      "1103 Traning Loss: tensor(9.1164)\n",
      "1104 Traning Loss: tensor(9.0553)\n",
      "1105 Traning Loss: tensor(8.9942)\n",
      "1106 Traning Loss: tensor(8.9332)\n",
      "1107 Traning Loss: tensor(8.8722)\n",
      "1108 Traning Loss: tensor(8.8113)\n",
      "1109 Traning Loss: tensor(8.7505)\n",
      "1110 Traning Loss: tensor(8.6897)\n",
      "1111 Traning Loss: tensor(8.6291)\n",
      "1112 Traning Loss: tensor(8.5686)\n",
      "1113 Traning Loss: tensor(8.5082)\n",
      "1114 Traning Loss: tensor(8.4480)\n",
      "1115 Traning Loss: tensor(8.3879)\n",
      "1116 Traning Loss: tensor(8.3280)\n",
      "1117 Traning Loss: tensor(8.2683)\n",
      "1118 Traning Loss: tensor(8.2088)\n",
      "1119 Traning Loss: tensor(8.1495)\n",
      "1120 Traning Loss: tensor(8.0904)\n",
      "1121 Traning Loss: tensor(8.0316)\n",
      "1122 Traning Loss: tensor(7.9730)\n",
      "1123 Traning Loss: tensor(7.9147)\n",
      "1124 Traning Loss: tensor(7.8567)\n",
      "1125 Traning Loss: tensor(7.7990)\n",
      "1126 Traning Loss: tensor(7.7415)\n",
      "1127 Traning Loss: tensor(7.6844)\n",
      "1128 Traning Loss: tensor(7.6276)\n",
      "1129 Traning Loss: tensor(7.5712)\n",
      "1130 Traning Loss: tensor(7.5151)\n",
      "1131 Traning Loss: tensor(7.4594)\n",
      "1132 Traning Loss: tensor(7.4041)\n",
      "1133 Traning Loss: tensor(7.3492)\n",
      "1134 Traning Loss: tensor(7.2946)\n",
      "1135 Traning Loss: tensor(7.2405)\n",
      "1136 Traning Loss: tensor(7.1868)\n",
      "1137 Traning Loss: tensor(7.1336)\n",
      "1138 Traning Loss: tensor(7.0808)\n",
      "1139 Traning Loss: tensor(7.0284)\n",
      "1140 Traning Loss: tensor(6.9765)\n",
      "1141 Traning Loss: tensor(6.9251)\n",
      "1142 Traning Loss: tensor(6.8742)\n",
      "1143 Traning Loss: tensor(6.8238)\n",
      "1144 Traning Loss: tensor(6.7738)\n",
      "1145 Traning Loss: tensor(6.7244)\n",
      "1146 Traning Loss: tensor(6.6755)\n",
      "1147 Traning Loss: tensor(6.6271)\n",
      "1148 Traning Loss: tensor(6.5793)\n",
      "1149 Traning Loss: tensor(6.5320)\n",
      "1150 Traning Loss: tensor(6.4852)\n",
      "1151 Traning Loss: tensor(6.4390)\n",
      "1152 Traning Loss: tensor(6.3933)\n",
      "1153 Traning Loss: tensor(6.3482)\n",
      "1154 Traning Loss: tensor(6.3037)\n",
      "1155 Traning Loss: tensor(6.2597)\n",
      "1156 Traning Loss: tensor(6.2163)\n",
      "1157 Traning Loss: tensor(6.1735)\n",
      "1158 Traning Loss: tensor(6.1312)\n",
      "1159 Traning Loss: tensor(6.0896)\n",
      "1160 Traning Loss: tensor(6.0485)\n",
      "1161 Traning Loss: tensor(6.0080)\n",
      "1162 Traning Loss: tensor(5.9681)\n",
      "1163 Traning Loss: tensor(5.9288)\n",
      "1164 Traning Loss: tensor(5.8901)\n",
      "1165 Traning Loss: tensor(5.8520)\n",
      "1166 Traning Loss: tensor(5.8144)\n",
      "1167 Traning Loss: tensor(5.7775)\n",
      "1168 Traning Loss: tensor(5.7411)\n",
      "1169 Traning Loss: tensor(5.7054)\n",
      "1170 Traning Loss: tensor(5.6702)\n",
      "1171 Traning Loss: tensor(5.6356)\n",
      "1172 Traning Loss: tensor(5.6016)\n",
      "1173 Traning Loss: tensor(5.5682)\n",
      "1174 Traning Loss: tensor(5.5354)\n",
      "1175 Traning Loss: tensor(5.5031)\n",
      "1176 Traning Loss: tensor(5.4714)\n",
      "1177 Traning Loss: tensor(5.4403)\n",
      "1178 Traning Loss: tensor(5.4098)\n",
      "1179 Traning Loss: tensor(5.3799)\n",
      "1180 Traning Loss: tensor(5.3505)\n",
      "1181 Traning Loss: tensor(5.3216)\n",
      "1182 Traning Loss: tensor(5.2933)\n",
      "1183 Traning Loss: tensor(5.2656)\n",
      "1184 Traning Loss: tensor(5.2384)\n",
      "1185 Traning Loss: tensor(5.2118)\n",
      "1186 Traning Loss: tensor(5.1857)\n",
      "1187 Traning Loss: tensor(5.1601)\n",
      "1188 Traning Loss: tensor(5.1351)\n",
      "1189 Traning Loss: tensor(5.1106)\n",
      "1190 Traning Loss: tensor(5.0866)\n",
      "1191 Traning Loss: tensor(5.0631)\n",
      "1192 Traning Loss: tensor(5.0401)\n",
      "1193 Traning Loss: tensor(5.0176)\n",
      "1194 Traning Loss: tensor(4.9956)\n",
      "1195 Traning Loss: tensor(4.9741)\n",
      "1196 Traning Loss: tensor(4.9531)\n",
      "1197 Traning Loss: tensor(4.9325)\n",
      "1198 Traning Loss: tensor(4.9124)\n",
      "1199 Traning Loss: tensor(4.8928)\n",
      "1200 Traning Loss: tensor(4.8736)\n",
      "1201 Traning Loss: tensor(4.8549)\n",
      "1202 Traning Loss: tensor(4.8366)\n",
      "1203 Traning Loss: tensor(4.8187)\n",
      "1204 Traning Loss: tensor(4.8013)\n",
      "1205 Traning Loss: tensor(4.7842)\n",
      "1206 Traning Loss: tensor(4.7676)\n",
      "1207 Traning Loss: tensor(4.7514)\n",
      "1208 Traning Loss: tensor(4.7356)\n",
      "1209 Traning Loss: tensor(4.7202)\n",
      "1210 Traning Loss: tensor(4.7051)\n",
      "1211 Traning Loss: tensor(4.6904)\n",
      "1212 Traning Loss: tensor(4.6761)\n",
      "1213 Traning Loss: tensor(4.6622)\n",
      "1214 Traning Loss: tensor(4.6486)\n",
      "1215 Traning Loss: tensor(4.6353)\n",
      "1216 Traning Loss: tensor(4.6224)\n",
      "1217 Traning Loss: tensor(4.6098)\n",
      "1218 Traning Loss: tensor(4.5975)\n",
      "1219 Traning Loss: tensor(4.5856)\n",
      "1220 Traning Loss: tensor(4.5739)\n",
      "1221 Traning Loss: tensor(4.5626)\n",
      "1222 Traning Loss: tensor(4.5516)\n",
      "1223 Traning Loss: tensor(4.5408)\n",
      "1224 Traning Loss: tensor(4.5303)\n",
      "1225 Traning Loss: tensor(4.5201)\n",
      "1226 Traning Loss: tensor(4.5102)\n",
      "1227 Traning Loss: tensor(4.5005)\n",
      "1228 Traning Loss: tensor(4.4910)\n",
      "1229 Traning Loss: tensor(4.4819)\n",
      "1230 Traning Loss: tensor(4.4729)\n",
      "1231 Traning Loss: tensor(4.4642)\n",
      "1232 Traning Loss: tensor(4.4557)\n",
      "1233 Traning Loss: tensor(4.4474)\n",
      "1234 Traning Loss: tensor(4.4394)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1235 Traning Loss: tensor(4.4315)\n",
      "1236 Traning Loss: tensor(4.4239)\n",
      "1237 Traning Loss: tensor(4.4165)\n",
      "1238 Traning Loss: tensor(4.4092)\n",
      "1239 Traning Loss: tensor(4.4021)\n",
      "1240 Traning Loss: tensor(4.3952)\n",
      "1241 Traning Loss: tensor(4.3885)\n",
      "1242 Traning Loss: tensor(4.3820)\n",
      "1243 Traning Loss: tensor(4.3756)\n",
      "1244 Traning Loss: tensor(4.3693)\n",
      "1245 Traning Loss: tensor(4.3633)\n",
      "1246 Traning Loss: tensor(4.3573)\n",
      "1247 Traning Loss: tensor(4.3515)\n",
      "1248 Traning Loss: tensor(4.3459)\n",
      "1249 Traning Loss: tensor(4.3404)\n",
      "1250 Traning Loss: tensor(4.3350)\n",
      "1251 Traning Loss: tensor(4.3297)\n",
      "1252 Traning Loss: tensor(4.3245)\n",
      "1253 Traning Loss: tensor(4.3195)\n",
      "1254 Traning Loss: tensor(4.3146)\n",
      "1255 Traning Loss: tensor(4.3098)\n",
      "1256 Traning Loss: tensor(4.3051)\n",
      "1257 Traning Loss: tensor(4.3005)\n",
      "1258 Traning Loss: tensor(4.2959)\n",
      "1259 Traning Loss: tensor(4.2915)\n",
      "1260 Traning Loss: tensor(4.2872)\n",
      "1261 Traning Loss: tensor(4.2829)\n",
      "1262 Traning Loss: tensor(4.2788)\n",
      "1263 Traning Loss: tensor(4.2747)\n",
      "1264 Traning Loss: tensor(4.2707)\n",
      "1265 Traning Loss: tensor(4.2668)\n",
      "1266 Traning Loss: tensor(4.2629)\n",
      "1267 Traning Loss: tensor(4.2591)\n",
      "1268 Traning Loss: tensor(4.2554)\n",
      "1269 Traning Loss: tensor(4.2518)\n",
      "1270 Traning Loss: tensor(4.2482)\n",
      "1271 Traning Loss: tensor(4.2447)\n",
      "1272 Traning Loss: tensor(4.2412)\n",
      "1273 Traning Loss: tensor(4.2378)\n",
      "1274 Traning Loss: tensor(4.2344)\n",
      "1275 Traning Loss: tensor(4.2311)\n",
      "1276 Traning Loss: tensor(4.2279)\n",
      "1277 Traning Loss: tensor(4.2247)\n",
      "1278 Traning Loss: tensor(4.2215)\n",
      "1279 Traning Loss: tensor(4.2184)\n",
      "1280 Traning Loss: tensor(4.2154)\n",
      "1281 Traning Loss: tensor(4.2124)\n",
      "1282 Traning Loss: tensor(4.2094)\n",
      "1283 Traning Loss: tensor(4.2065)\n",
      "1284 Traning Loss: tensor(4.2036)\n",
      "1285 Traning Loss: tensor(4.2007)\n",
      "1286 Traning Loss: tensor(4.1979)\n",
      "1287 Traning Loss: tensor(4.1952)\n",
      "1288 Traning Loss: tensor(4.1924)\n",
      "1289 Traning Loss: tensor(4.1897)\n",
      "1290 Traning Loss: tensor(4.1871)\n",
      "1291 Traning Loss: tensor(4.1845)\n",
      "1292 Traning Loss: tensor(4.1819)\n",
      "1293 Traning Loss: tensor(4.1793)\n",
      "1294 Traning Loss: tensor(4.1768)\n",
      "1295 Traning Loss: tensor(4.1743)\n",
      "1296 Traning Loss: tensor(4.1719)\n",
      "1297 Traning Loss: tensor(4.1695)\n",
      "1298 Traning Loss: tensor(4.1671)\n",
      "1299 Traning Loss: tensor(4.1647)\n",
      "1300 Traning Loss: tensor(4.1624)\n",
      "1301 Traning Loss: tensor(4.1601)\n",
      "1302 Traning Loss: tensor(4.1578)\n",
      "1303 Traning Loss: tensor(4.1555)\n",
      "1304 Traning Loss: tensor(4.1533)\n",
      "1305 Traning Loss: tensor(4.1511)\n",
      "1306 Traning Loss: tensor(4.1489)\n",
      "1307 Traning Loss: tensor(4.1468)\n",
      "1308 Traning Loss: tensor(4.1446)\n",
      "1309 Traning Loss: tensor(4.1425)\n",
      "1310 Traning Loss: tensor(4.1405)\n",
      "1311 Traning Loss: tensor(4.1384)\n",
      "1312 Traning Loss: tensor(4.1364)\n",
      "1313 Traning Loss: tensor(4.1344)\n",
      "1314 Traning Loss: tensor(4.1324)\n",
      "1315 Traning Loss: tensor(4.1304)\n",
      "1316 Traning Loss: tensor(4.1284)\n",
      "1317 Traning Loss: tensor(4.1265)\n",
      "1318 Traning Loss: tensor(4.1246)\n",
      "1319 Traning Loss: tensor(4.1227)\n",
      "1320 Traning Loss: tensor(4.1208)\n",
      "1321 Traning Loss: tensor(4.1190)\n",
      "1322 Traning Loss: tensor(4.1171)\n",
      "1323 Traning Loss: tensor(4.1153)\n",
      "1324 Traning Loss: tensor(4.1135)\n",
      "1325 Traning Loss: tensor(4.1117)\n",
      "1326 Traning Loss: tensor(4.1099)\n",
      "1327 Traning Loss: tensor(4.1082)\n",
      "1328 Traning Loss: tensor(4.1064)\n",
      "1329 Traning Loss: tensor(4.1047)\n",
      "1330 Traning Loss: tensor(4.1030)\n",
      "1331 Traning Loss: tensor(4.1013)\n",
      "1332 Traning Loss: tensor(4.0996)\n",
      "1333 Traning Loss: tensor(4.0979)\n",
      "1334 Traning Loss: tensor(4.0963)\n",
      "1335 Traning Loss: tensor(4.0946)\n",
      "1336 Traning Loss: tensor(4.0930)\n",
      "1337 Traning Loss: tensor(4.0914)\n",
      "1338 Traning Loss: tensor(4.0897)\n",
      "1339 Traning Loss: tensor(4.0882)\n",
      "1340 Traning Loss: tensor(4.0866)\n",
      "1341 Traning Loss: tensor(4.0850)\n",
      "1342 Traning Loss: tensor(4.0834)\n",
      "1343 Traning Loss: tensor(4.0819)\n",
      "1344 Traning Loss: tensor(4.0803)\n",
      "1345 Traning Loss: tensor(4.0788)\n",
      "1346 Traning Loss: tensor(4.0773)\n",
      "1347 Traning Loss: tensor(4.0758)\n",
      "1348 Traning Loss: tensor(4.0743)\n",
      "1349 Traning Loss: tensor(4.0728)\n",
      "1350 Traning Loss: tensor(4.0713)\n",
      "1351 Traning Loss: tensor(4.0699)\n",
      "1352 Traning Loss: tensor(4.0684)\n",
      "1353 Traning Loss: tensor(4.0670)\n",
      "1354 Traning Loss: tensor(4.0655)\n",
      "1355 Traning Loss: tensor(4.0641)\n",
      "1356 Traning Loss: tensor(4.0627)\n",
      "1357 Traning Loss: tensor(4.0613)\n",
      "1358 Traning Loss: tensor(4.0599)\n",
      "1359 Traning Loss: tensor(4.0585)\n",
      "1360 Traning Loss: tensor(4.0571)\n",
      "1361 Traning Loss: tensor(4.0557)\n",
      "1362 Traning Loss: tensor(4.0544)\n",
      "1363 Traning Loss: tensor(4.0530)\n",
      "1364 Traning Loss: tensor(4.0517)\n",
      "1365 Traning Loss: tensor(4.0503)\n",
      "1366 Traning Loss: tensor(4.0490)\n",
      "1367 Traning Loss: tensor(4.0477)\n",
      "1368 Traning Loss: tensor(4.0463)\n",
      "1369 Traning Loss: tensor(4.0450)\n",
      "1370 Traning Loss: tensor(4.0437)\n",
      "1371 Traning Loss: tensor(4.0425)\n",
      "1372 Traning Loss: tensor(4.0412)\n",
      "1373 Traning Loss: tensor(4.0399)\n",
      "1374 Traning Loss: tensor(4.0386)\n",
      "1375 Traning Loss: tensor(4.0374)\n",
      "1376 Traning Loss: tensor(4.0361)\n",
      "1377 Traning Loss: tensor(4.0349)\n",
      "1378 Traning Loss: tensor(4.0336)\n",
      "1379 Traning Loss: tensor(4.0324)\n",
      "1380 Traning Loss: tensor(4.0312)\n",
      "1381 Traning Loss: tensor(4.0300)\n",
      "1382 Traning Loss: tensor(4.0288)\n",
      "1383 Traning Loss: tensor(4.0276)\n",
      "1384 Traning Loss: tensor(4.0264)\n",
      "1385 Traning Loss: tensor(4.0252)\n",
      "1386 Traning Loss: tensor(4.0240)\n",
      "1387 Traning Loss: tensor(4.0228)\n",
      "1388 Traning Loss: tensor(4.0216)\n",
      "1389 Traning Loss: tensor(4.0205)\n",
      "1390 Traning Loss: tensor(4.0193)\n",
      "1391 Traning Loss: tensor(4.0182)\n",
      "1392 Traning Loss: tensor(4.0170)\n",
      "1393 Traning Loss: tensor(4.0159)\n",
      "1394 Traning Loss: tensor(4.0147)\n",
      "1395 Traning Loss: tensor(4.0136)\n",
      "1396 Traning Loss: tensor(4.0125)\n",
      "1397 Traning Loss: tensor(4.0114)\n",
      "1398 Traning Loss: tensor(4.0102)\n",
      "1399 Traning Loss: tensor(4.0091)\n",
      "1400 Traning Loss: tensor(4.0080)\n",
      "1401 Traning Loss: tensor(4.0069)\n",
      "1402 Traning Loss: tensor(4.0058)\n",
      "1403 Traning Loss: tensor(4.0047)\n",
      "1404 Traning Loss: tensor(4.0036)\n",
      "1405 Traning Loss: tensor(4.0025)\n",
      "1406 Traning Loss: tensor(4.0015)\n",
      "1407 Traning Loss: tensor(4.0004)\n",
      "1408 Traning Loss: tensor(3.9993)\n",
      "1409 Traning Loss: tensor(3.9982)\n",
      "1410 Traning Loss: tensor(3.9972)\n",
      "1411 Traning Loss: tensor(3.9961)\n",
      "1412 Traning Loss: tensor(3.9950)\n",
      "1413 Traning Loss: tensor(3.9940)\n",
      "1414 Traning Loss: tensor(3.9929)\n",
      "1415 Traning Loss: tensor(3.9919)\n",
      "1416 Traning Loss: tensor(3.9908)\n",
      "1417 Traning Loss: tensor(3.9898)\n",
      "1418 Traning Loss: tensor(3.9887)\n",
      "1419 Traning Loss: tensor(3.9877)\n",
      "1420 Traning Loss: tensor(3.9866)\n",
      "1421 Traning Loss: tensor(3.9856)\n",
      "1422 Traning Loss: tensor(3.9845)\n",
      "1423 Traning Loss: tensor(3.9835)\n",
      "1424 Traning Loss: tensor(3.9824)\n",
      "1425 Traning Loss: tensor(3.9814)\n",
      "1426 Traning Loss: tensor(3.9804)\n",
      "1427 Traning Loss: tensor(3.9793)\n",
      "1428 Traning Loss: tensor(3.9783)\n",
      "1429 Traning Loss: tensor(3.9772)\n",
      "1430 Traning Loss: tensor(3.9762)\n",
      "1431 Traning Loss: tensor(3.9752)\n",
      "1432 Traning Loss: tensor(3.9741)\n",
      "1433 Traning Loss: tensor(3.9731)\n",
      "1434 Traning Loss: tensor(3.9721)\n",
      "1435 Traning Loss: tensor(3.9710)\n",
      "1436 Traning Loss: tensor(3.9700)\n",
      "1437 Traning Loss: tensor(3.9689)\n",
      "1438 Traning Loss: tensor(3.9679)\n",
      "1439 Traning Loss: tensor(3.9669)\n",
      "1440 Traning Loss: tensor(3.9658)\n",
      "1441 Traning Loss: tensor(3.9648)\n",
      "1442 Traning Loss: tensor(3.9637)\n",
      "1443 Traning Loss: tensor(3.9627)\n",
      "1444 Traning Loss: tensor(3.9616)\n",
      "1445 Traning Loss: tensor(3.9606)\n",
      "1446 Traning Loss: tensor(3.9596)\n",
      "1447 Traning Loss: tensor(3.9585)\n",
      "1448 Traning Loss: tensor(3.9575)\n",
      "1449 Traning Loss: tensor(3.9564)\n",
      "1450 Traning Loss: tensor(3.9554)\n",
      "1451 Traning Loss: tensor(3.9543)\n",
      "1452 Traning Loss: tensor(3.9532)\n",
      "1453 Traning Loss: tensor(3.9522)\n",
      "1454 Traning Loss: tensor(3.9511)\n",
      "1455 Traning Loss: tensor(3.9501)\n",
      "1456 Traning Loss: tensor(3.9490)\n",
      "1457 Traning Loss: tensor(3.9479)\n",
      "1458 Traning Loss: tensor(3.9469)\n",
      "1459 Traning Loss: tensor(3.9458)\n",
      "1460 Traning Loss: tensor(3.9447)\n",
      "1461 Traning Loss: tensor(3.9437)\n",
      "1462 Traning Loss: tensor(3.9426)\n",
      "1463 Traning Loss: tensor(3.9415)\n",
      "1464 Traning Loss: tensor(3.9405)\n",
      "1465 Traning Loss: tensor(3.9394)\n",
      "1466 Traning Loss: tensor(3.9383)\n",
      "1467 Traning Loss: tensor(3.9372)\n",
      "1468 Traning Loss: tensor(3.9362)\n",
      "1469 Traning Loss: tensor(3.9351)\n",
      "1470 Traning Loss: tensor(3.9340)\n",
      "1471 Traning Loss: tensor(3.9329)\n",
      "1472 Traning Loss: tensor(3.9318)\n",
      "1473 Traning Loss: tensor(3.9308)\n",
      "1474 Traning Loss: tensor(3.9297)\n",
      "1475 Traning Loss: tensor(3.9286)\n",
      "1476 Traning Loss: tensor(3.9275)\n",
      "1477 Traning Loss: tensor(3.9265)\n",
      "1478 Traning Loss: tensor(3.9254)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479 Traning Loss: tensor(3.9243)\n",
      "1480 Traning Loss: tensor(3.9232)\n",
      "1481 Traning Loss: tensor(3.9222)\n",
      "1482 Traning Loss: tensor(3.9211)\n",
      "1483 Traning Loss: tensor(3.9200)\n",
      "1484 Traning Loss: tensor(3.9190)\n",
      "1485 Traning Loss: tensor(3.9179)\n",
      "1486 Traning Loss: tensor(3.9168)\n",
      "1487 Traning Loss: tensor(3.9158)\n",
      "1488 Traning Loss: tensor(3.9147)\n",
      "1489 Traning Loss: tensor(3.9137)\n",
      "1490 Traning Loss: tensor(3.9126)\n",
      "1491 Traning Loss: tensor(3.9116)\n",
      "1492 Traning Loss: tensor(3.9105)\n",
      "1493 Traning Loss: tensor(3.9095)\n",
      "1494 Traning Loss: tensor(3.9084)\n",
      "1495 Traning Loss: tensor(3.9074)\n",
      "1496 Traning Loss: tensor(3.9064)\n",
      "1497 Traning Loss: tensor(3.9054)\n",
      "1498 Traning Loss: tensor(3.9043)\n",
      "1499 Traning Loss: tensor(3.9033)\n",
      "1500 Traning Loss: tensor(3.9023)\n",
      "1501 Traning Loss: tensor(3.9013)\n",
      "1502 Traning Loss: tensor(3.9003)\n",
      "1503 Traning Loss: tensor(3.8993)\n",
      "1504 Traning Loss: tensor(3.8983)\n",
      "1505 Traning Loss: tensor(3.8973)\n",
      "1506 Traning Loss: tensor(3.8963)\n",
      "1507 Traning Loss: tensor(3.8953)\n",
      "1508 Traning Loss: tensor(3.8944)\n",
      "1509 Traning Loss: tensor(3.8934)\n",
      "1510 Traning Loss: tensor(3.8924)\n",
      "1511 Traning Loss: tensor(3.8915)\n",
      "1512 Traning Loss: tensor(3.8905)\n",
      "1513 Traning Loss: tensor(3.8896)\n",
      "1514 Traning Loss: tensor(3.8887)\n",
      "1515 Traning Loss: tensor(3.8877)\n",
      "1516 Traning Loss: tensor(3.8868)\n",
      "1517 Traning Loss: tensor(3.8859)\n",
      "1518 Traning Loss: tensor(3.8850)\n",
      "1519 Traning Loss: tensor(3.8841)\n",
      "1520 Traning Loss: tensor(3.8832)\n",
      "1521 Traning Loss: tensor(3.8823)\n",
      "1522 Traning Loss: tensor(3.8814)\n",
      "1523 Traning Loss: tensor(3.8805)\n",
      "1524 Traning Loss: tensor(3.8796)\n",
      "1525 Traning Loss: tensor(3.8788)\n",
      "1526 Traning Loss: tensor(3.8779)\n",
      "1527 Traning Loss: tensor(3.8771)\n",
      "1528 Traning Loss: tensor(3.8762)\n",
      "1529 Traning Loss: tensor(3.8754)\n",
      "1530 Traning Loss: tensor(3.8746)\n",
      "1531 Traning Loss: tensor(3.8737)\n",
      "1532 Traning Loss: tensor(3.8729)\n",
      "1533 Traning Loss: tensor(3.8721)\n",
      "1534 Traning Loss: tensor(3.8713)\n",
      "1535 Traning Loss: tensor(3.8705)\n",
      "1536 Traning Loss: tensor(3.8697)\n",
      "1537 Traning Loss: tensor(3.8690)\n",
      "1538 Traning Loss: tensor(3.8682)\n",
      "1539 Traning Loss: tensor(3.8674)\n",
      "1540 Traning Loss: tensor(3.8667)\n",
      "1541 Traning Loss: tensor(3.8659)\n",
      "1542 Traning Loss: tensor(3.8652)\n",
      "1543 Traning Loss: tensor(3.8644)\n",
      "1544 Traning Loss: tensor(3.8637)\n",
      "1545 Traning Loss: tensor(3.8630)\n",
      "1546 Traning Loss: tensor(3.8623)\n",
      "1547 Traning Loss: tensor(3.8616)\n",
      "1548 Traning Loss: tensor(3.8609)\n",
      "1549 Traning Loss: tensor(3.8602)\n",
      "1550 Traning Loss: tensor(3.8595)\n",
      "1551 Traning Loss: tensor(3.8588)\n",
      "1552 Traning Loss: tensor(3.8581)\n",
      "1553 Traning Loss: tensor(3.8575)\n",
      "1554 Traning Loss: tensor(3.8568)\n",
      "1555 Traning Loss: tensor(3.8561)\n",
      "1556 Traning Loss: tensor(3.8555)\n",
      "1557 Traning Loss: tensor(3.8549)\n",
      "1558 Traning Loss: tensor(3.8542)\n",
      "1559 Traning Loss: tensor(3.8536)\n",
      "1560 Traning Loss: tensor(3.8530)\n",
      "1561 Traning Loss: tensor(3.8524)\n",
      "1562 Traning Loss: tensor(3.8518)\n",
      "1563 Traning Loss: tensor(3.8512)\n",
      "1564 Traning Loss: tensor(3.8506)\n",
      "1565 Traning Loss: tensor(3.8500)\n",
      "1566 Traning Loss: tensor(3.8494)\n",
      "1567 Traning Loss: tensor(3.8488)\n",
      "1568 Traning Loss: tensor(3.8482)\n",
      "1569 Traning Loss: tensor(3.8477)\n",
      "1570 Traning Loss: tensor(3.8471)\n",
      "1571 Traning Loss: tensor(3.8466)\n",
      "1572 Traning Loss: tensor(3.8460)\n",
      "1573 Traning Loss: tensor(3.8455)\n",
      "1574 Traning Loss: tensor(3.8450)\n",
      "1575 Traning Loss: tensor(3.8444)\n",
      "1576 Traning Loss: tensor(3.8439)\n",
      "1577 Traning Loss: tensor(3.8434)\n",
      "1578 Traning Loss: tensor(3.8429)\n",
      "1579 Traning Loss: tensor(3.8424)\n",
      "1580 Traning Loss: tensor(3.8419)\n",
      "1581 Traning Loss: tensor(3.8414)\n",
      "1582 Traning Loss: tensor(3.8409)\n",
      "1583 Traning Loss: tensor(3.8404)\n",
      "1584 Traning Loss: tensor(3.8399)\n",
      "1585 Traning Loss: tensor(3.8394)\n",
      "1586 Traning Loss: tensor(3.8390)\n",
      "1587 Traning Loss: tensor(3.8385)\n",
      "1588 Traning Loss: tensor(3.8380)\n",
      "1589 Traning Loss: tensor(3.8376)\n",
      "1590 Traning Loss: tensor(3.8371)\n",
      "1591 Traning Loss: tensor(3.8367)\n",
      "1592 Traning Loss: tensor(3.8362)\n",
      "1593 Traning Loss: tensor(3.8358)\n",
      "1594 Traning Loss: tensor(3.8353)\n",
      "1595 Traning Loss: tensor(3.8349)\n",
      "1596 Traning Loss: tensor(3.8345)\n",
      "1597 Traning Loss: tensor(3.8341)\n",
      "1598 Traning Loss: tensor(3.8336)\n",
      "1599 Traning Loss: tensor(3.8332)\n",
      "1600 Traning Loss: tensor(3.8328)\n",
      "1601 Traning Loss: tensor(3.8324)\n",
      "1602 Traning Loss: tensor(3.8320)\n",
      "1603 Traning Loss: tensor(3.8316)\n",
      "1604 Traning Loss: tensor(3.8312)\n",
      "1605 Traning Loss: tensor(3.8308)\n",
      "1606 Traning Loss: tensor(3.8304)\n",
      "1607 Traning Loss: tensor(3.8301)\n",
      "1608 Traning Loss: tensor(3.8297)\n",
      "1609 Traning Loss: tensor(3.8293)\n",
      "1610 Traning Loss: tensor(3.8289)\n",
      "1611 Traning Loss: tensor(3.8286)\n",
      "1612 Traning Loss: tensor(3.8282)\n",
      "1613 Traning Loss: tensor(3.8278)\n",
      "1614 Traning Loss: tensor(3.8275)\n",
      "1615 Traning Loss: tensor(3.8271)\n",
      "1616 Traning Loss: tensor(3.8268)\n",
      "1617 Traning Loss: tensor(3.8264)\n",
      "1618 Traning Loss: tensor(3.8261)\n",
      "1619 Traning Loss: tensor(3.8257)\n",
      "1620 Traning Loss: tensor(3.8254)\n",
      "1621 Traning Loss: tensor(3.8250)\n",
      "1622 Traning Loss: tensor(3.8247)\n",
      "1623 Traning Loss: tensor(3.8244)\n",
      "1624 Traning Loss: tensor(3.8240)\n",
      "1625 Traning Loss: tensor(3.8237)\n",
      "1626 Traning Loss: tensor(3.8234)\n",
      "1627 Traning Loss: tensor(3.8231)\n",
      "1628 Traning Loss: tensor(3.8227)\n",
      "1629 Traning Loss: tensor(3.8224)\n",
      "1630 Traning Loss: tensor(3.8221)\n",
      "1631 Traning Loss: tensor(3.8218)\n",
      "1632 Traning Loss: tensor(3.8215)\n",
      "1633 Traning Loss: tensor(3.8212)\n",
      "1634 Traning Loss: tensor(3.8209)\n",
      "1635 Traning Loss: tensor(3.8206)\n",
      "1636 Traning Loss: tensor(3.8202)\n",
      "1637 Traning Loss: tensor(3.8199)\n",
      "1638 Traning Loss: tensor(3.8196)\n",
      "1639 Traning Loss: tensor(3.8194)\n",
      "1640 Traning Loss: tensor(3.8191)\n",
      "1641 Traning Loss: tensor(3.8188)\n",
      "1642 Traning Loss: tensor(3.8185)\n",
      "1643 Traning Loss: tensor(3.8182)\n",
      "1644 Traning Loss: tensor(3.8179)\n",
      "1645 Traning Loss: tensor(3.8176)\n",
      "1646 Traning Loss: tensor(3.8173)\n",
      "1647 Traning Loss: tensor(3.8171)\n",
      "1648 Traning Loss: tensor(3.8168)\n",
      "1649 Traning Loss: tensor(3.8165)\n",
      "1650 Traning Loss: tensor(3.8162)\n",
      "1651 Traning Loss: tensor(3.8159)\n",
      "1652 Traning Loss: tensor(3.8157)\n",
      "1653 Traning Loss: tensor(3.8154)\n",
      "1654 Traning Loss: tensor(3.8151)\n",
      "1655 Traning Loss: tensor(3.8149)\n",
      "1656 Traning Loss: tensor(3.8146)\n",
      "1657 Traning Loss: tensor(3.8143)\n",
      "1658 Traning Loss: tensor(3.8141)\n",
      "1659 Traning Loss: tensor(3.8138)\n",
      "1660 Traning Loss: tensor(3.8135)\n",
      "1661 Traning Loss: tensor(3.8133)\n",
      "1662 Traning Loss: tensor(3.8130)\n",
      "1663 Traning Loss: tensor(3.8128)\n",
      "1664 Traning Loss: tensor(3.8125)\n",
      "1665 Traning Loss: tensor(3.8123)\n",
      "1666 Traning Loss: tensor(3.8120)\n",
      "1667 Traning Loss: tensor(3.8117)\n",
      "1668 Traning Loss: tensor(3.8115)\n",
      "1669 Traning Loss: tensor(3.8112)\n",
      "1670 Traning Loss: tensor(3.8110)\n",
      "1671 Traning Loss: tensor(3.8107)\n",
      "1672 Traning Loss: tensor(3.8105)\n",
      "1673 Traning Loss: tensor(3.8103)\n",
      "1674 Traning Loss: tensor(3.8100)\n",
      "1675 Traning Loss: tensor(3.8098)\n",
      "1676 Traning Loss: tensor(3.8095)\n",
      "1677 Traning Loss: tensor(3.8093)\n",
      "1678 Traning Loss: tensor(3.8090)\n",
      "1679 Traning Loss: tensor(3.8088)\n",
      "1680 Traning Loss: tensor(3.8086)\n",
      "1681 Traning Loss: tensor(3.8083)\n",
      "1682 Traning Loss: tensor(3.8081)\n",
      "1683 Traning Loss: tensor(3.8078)\n",
      "1684 Traning Loss: tensor(3.8076)\n",
      "1685 Traning Loss: tensor(3.8074)\n",
      "1686 Traning Loss: tensor(3.8071)\n",
      "1687 Traning Loss: tensor(3.8069)\n",
      "1688 Traning Loss: tensor(3.8067)\n",
      "1689 Traning Loss: tensor(3.8064)\n",
      "1690 Traning Loss: tensor(3.8062)\n",
      "1691 Traning Loss: tensor(3.8060)\n",
      "1692 Traning Loss: tensor(3.8058)\n",
      "1693 Traning Loss: tensor(3.8055)\n",
      "1694 Traning Loss: tensor(3.8053)\n",
      "1695 Traning Loss: tensor(3.8051)\n",
      "1696 Traning Loss: tensor(3.8048)\n",
      "1697 Traning Loss: tensor(3.8046)\n",
      "1698 Traning Loss: tensor(3.8044)\n",
      "1699 Traning Loss: tensor(3.8042)\n",
      "1700 Traning Loss: tensor(3.8039)\n",
      "1701 Traning Loss: tensor(3.8037)\n",
      "1702 Traning Loss: tensor(3.8035)\n",
      "1703 Traning Loss: tensor(3.8033)\n",
      "1704 Traning Loss: tensor(3.8031)\n",
      "1705 Traning Loss: tensor(3.8028)\n",
      "1706 Traning Loss: tensor(3.8026)\n",
      "1707 Traning Loss: tensor(3.8024)\n",
      "1708 Traning Loss: tensor(3.8022)\n",
      "1709 Traning Loss: tensor(3.8020)\n",
      "1710 Traning Loss: tensor(3.8017)\n",
      "1711 Traning Loss: tensor(3.8015)\n",
      "1712 Traning Loss: tensor(3.8013)\n",
      "1713 Traning Loss: tensor(3.8011)\n",
      "1714 Traning Loss: tensor(3.8009)\n",
      "1715 Traning Loss: tensor(3.8007)\n",
      "1716 Traning Loss: tensor(3.8004)\n",
      "1717 Traning Loss: tensor(3.8002)\n",
      "1718 Traning Loss: tensor(3.8000)\n",
      "1719 Traning Loss: tensor(3.7998)\n",
      "1720 Traning Loss: tensor(3.7996)\n",
      "1721 Traning Loss: tensor(3.7994)\n",
      "1722 Traning Loss: tensor(3.7991)\n",
      "1723 Traning Loss: tensor(3.7989)\n",
      "1724 Traning Loss: tensor(3.7987)\n",
      "1725 Traning Loss: tensor(3.7985)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726 Traning Loss: tensor(3.7983)\n",
      "1727 Traning Loss: tensor(3.7981)\n",
      "1728 Traning Loss: tensor(3.7979)\n",
      "1729 Traning Loss: tensor(3.7977)\n",
      "1730 Traning Loss: tensor(3.7975)\n",
      "1731 Traning Loss: tensor(3.7972)\n",
      "1732 Traning Loss: tensor(3.7970)\n",
      "1733 Traning Loss: tensor(3.7968)\n",
      "1734 Traning Loss: tensor(3.7966)\n",
      "1735 Traning Loss: tensor(3.7964)\n",
      "1736 Traning Loss: tensor(3.7962)\n",
      "1737 Traning Loss: tensor(3.7960)\n",
      "1738 Traning Loss: tensor(3.7958)\n",
      "1739 Traning Loss: tensor(3.7956)\n",
      "1740 Traning Loss: tensor(3.7954)\n",
      "1741 Traning Loss: tensor(3.7951)\n",
      "1742 Traning Loss: tensor(3.7949)\n",
      "1743 Traning Loss: tensor(3.7947)\n",
      "1744 Traning Loss: tensor(3.7945)\n",
      "1745 Traning Loss: tensor(3.7943)\n",
      "1746 Traning Loss: tensor(3.7941)\n",
      "1747 Traning Loss: tensor(3.7939)\n",
      "1748 Traning Loss: tensor(3.7937)\n",
      "1749 Traning Loss: tensor(3.7935)\n",
      "1750 Traning Loss: tensor(3.7933)\n",
      "1751 Traning Loss: tensor(3.7931)\n",
      "1752 Traning Loss: tensor(3.7929)\n",
      "1753 Traning Loss: tensor(3.7927)\n",
      "1754 Traning Loss: tensor(3.7925)\n",
      "1755 Traning Loss: tensor(3.7923)\n",
      "1756 Traning Loss: tensor(3.7920)\n",
      "1757 Traning Loss: tensor(3.7918)\n",
      "1758 Traning Loss: tensor(3.7916)\n",
      "1759 Traning Loss: tensor(3.7914)\n",
      "1760 Traning Loss: tensor(3.7912)\n",
      "1761 Traning Loss: tensor(3.7910)\n",
      "1762 Traning Loss: tensor(3.7908)\n",
      "1763 Traning Loss: tensor(3.7906)\n",
      "1764 Traning Loss: tensor(3.7904)\n",
      "1765 Traning Loss: tensor(3.7902)\n",
      "1766 Traning Loss: tensor(3.7900)\n",
      "1767 Traning Loss: tensor(3.7898)\n",
      "1768 Traning Loss: tensor(3.7896)\n",
      "1769 Traning Loss: tensor(3.7894)\n",
      "1770 Traning Loss: tensor(3.7892)\n",
      "1771 Traning Loss: tensor(3.7890)\n",
      "1772 Traning Loss: tensor(3.7888)\n",
      "1773 Traning Loss: tensor(3.7886)\n",
      "1774 Traning Loss: tensor(3.7884)\n",
      "1775 Traning Loss: tensor(3.7882)\n",
      "1776 Traning Loss: tensor(3.7880)\n",
      "1777 Traning Loss: tensor(3.7877)\n",
      "1778 Traning Loss: tensor(3.7875)\n",
      "1779 Traning Loss: tensor(3.7873)\n",
      "1780 Traning Loss: tensor(3.7871)\n",
      "1781 Traning Loss: tensor(3.7869)\n",
      "1782 Traning Loss: tensor(3.7867)\n",
      "1783 Traning Loss: tensor(3.7865)\n",
      "1784 Traning Loss: tensor(3.7863)\n",
      "1785 Traning Loss: tensor(3.7861)\n",
      "1786 Traning Loss: tensor(3.7859)\n",
      "1787 Traning Loss: tensor(3.7857)\n",
      "1788 Traning Loss: tensor(3.7855)\n",
      "1789 Traning Loss: tensor(3.7853)\n",
      "1790 Traning Loss: tensor(3.7851)\n",
      "1791 Traning Loss: tensor(3.7849)\n",
      "1792 Traning Loss: tensor(3.7847)\n",
      "1793 Traning Loss: tensor(3.7845)\n",
      "1794 Traning Loss: tensor(3.7843)\n",
      "1795 Traning Loss: tensor(3.7841)\n",
      "1796 Traning Loss: tensor(3.7839)\n",
      "1797 Traning Loss: tensor(3.7837)\n",
      "1798 Traning Loss: tensor(3.7835)\n",
      "1799 Traning Loss: tensor(3.7832)\n",
      "1800 Traning Loss: tensor(3.7830)\n",
      "1801 Traning Loss: tensor(3.7828)\n",
      "1802 Traning Loss: tensor(3.7826)\n",
      "1803 Traning Loss: tensor(3.7824)\n",
      "1804 Traning Loss: tensor(3.7822)\n",
      "1805 Traning Loss: tensor(3.7820)\n",
      "1806 Traning Loss: tensor(3.7818)\n",
      "1807 Traning Loss: tensor(3.7816)\n",
      "1808 Traning Loss: tensor(3.7814)\n",
      "1809 Traning Loss: tensor(3.7812)\n",
      "1810 Traning Loss: tensor(3.7810)\n",
      "1811 Traning Loss: tensor(3.7808)\n",
      "1812 Traning Loss: tensor(3.7806)\n",
      "1813 Traning Loss: tensor(3.7804)\n",
      "1814 Traning Loss: tensor(3.7802)\n",
      "1815 Traning Loss: tensor(3.7799)\n",
      "1816 Traning Loss: tensor(3.7797)\n",
      "1817 Traning Loss: tensor(3.7795)\n",
      "1818 Traning Loss: tensor(3.7793)\n",
      "1819 Traning Loss: tensor(3.7791)\n",
      "1820 Traning Loss: tensor(3.7789)\n",
      "1821 Traning Loss: tensor(3.7787)\n",
      "1822 Traning Loss: tensor(3.7785)\n",
      "1823 Traning Loss: tensor(3.7783)\n",
      "1824 Traning Loss: tensor(3.7781)\n",
      "1825 Traning Loss: tensor(3.7779)\n",
      "1826 Traning Loss: tensor(3.7777)\n",
      "1827 Traning Loss: tensor(3.7774)\n",
      "1828 Traning Loss: tensor(3.7772)\n",
      "1829 Traning Loss: tensor(3.7770)\n",
      "1830 Traning Loss: tensor(3.7768)\n",
      "1831 Traning Loss: tensor(3.7766)\n",
      "1832 Traning Loss: tensor(3.7764)\n",
      "1833 Traning Loss: tensor(3.7762)\n",
      "1834 Traning Loss: tensor(3.7760)\n",
      "1835 Traning Loss: tensor(3.7758)\n",
      "1836 Traning Loss: tensor(3.7756)\n",
      "1837 Traning Loss: tensor(3.7753)\n",
      "1838 Traning Loss: tensor(3.7751)\n",
      "1839 Traning Loss: tensor(3.7749)\n",
      "1840 Traning Loss: tensor(3.7747)\n",
      "1841 Traning Loss: tensor(3.7745)\n",
      "1842 Traning Loss: tensor(3.7743)\n",
      "1843 Traning Loss: tensor(3.7741)\n",
      "1844 Traning Loss: tensor(3.7739)\n",
      "1845 Traning Loss: tensor(3.7737)\n",
      "1846 Traning Loss: tensor(3.7734)\n",
      "1847 Traning Loss: tensor(3.7732)\n",
      "1848 Traning Loss: tensor(3.7730)\n",
      "1849 Traning Loss: tensor(3.7728)\n",
      "1850 Traning Loss: tensor(3.7726)\n",
      "1851 Traning Loss: tensor(3.7724)\n",
      "1852 Traning Loss: tensor(3.7722)\n",
      "1853 Traning Loss: tensor(3.7719)\n",
      "1854 Traning Loss: tensor(3.7717)\n",
      "1855 Traning Loss: tensor(3.7715)\n",
      "1856 Traning Loss: tensor(3.7713)\n",
      "1857 Traning Loss: tensor(3.7711)\n",
      "1858 Traning Loss: tensor(3.7709)\n",
      "1859 Traning Loss: tensor(3.7707)\n",
      "1860 Traning Loss: tensor(3.7704)\n",
      "1861 Traning Loss: tensor(3.7702)\n",
      "1862 Traning Loss: tensor(3.7700)\n",
      "1863 Traning Loss: tensor(3.7698)\n",
      "1864 Traning Loss: tensor(3.7696)\n",
      "1865 Traning Loss: tensor(3.7694)\n",
      "1866 Traning Loss: tensor(3.7691)\n",
      "1867 Traning Loss: tensor(3.7689)\n",
      "1868 Traning Loss: tensor(3.7687)\n",
      "1869 Traning Loss: tensor(3.7685)\n",
      "1870 Traning Loss: tensor(3.7683)\n",
      "1871 Traning Loss: tensor(3.7680)\n",
      "1872 Traning Loss: tensor(3.7678)\n",
      "1873 Traning Loss: tensor(3.7676)\n",
      "1874 Traning Loss: tensor(3.7674)\n",
      "1875 Traning Loss: tensor(3.7672)\n",
      "1876 Traning Loss: tensor(3.7669)\n",
      "1877 Traning Loss: tensor(3.7667)\n",
      "1878 Traning Loss: tensor(3.7665)\n",
      "1879 Traning Loss: tensor(3.7663)\n",
      "1880 Traning Loss: tensor(3.7661)\n",
      "1881 Traning Loss: tensor(3.7658)\n",
      "1882 Traning Loss: tensor(3.7656)\n",
      "1883 Traning Loss: tensor(3.7654)\n",
      "1884 Traning Loss: tensor(3.7652)\n",
      "1885 Traning Loss: tensor(3.7650)\n",
      "1886 Traning Loss: tensor(3.7647)\n",
      "1887 Traning Loss: tensor(3.7645)\n",
      "1888 Traning Loss: tensor(3.7643)\n",
      "1889 Traning Loss: tensor(3.7641)\n",
      "1890 Traning Loss: tensor(3.7638)\n",
      "1891 Traning Loss: tensor(3.7636)\n",
      "1892 Traning Loss: tensor(3.7634)\n",
      "1893 Traning Loss: tensor(3.7632)\n",
      "1894 Traning Loss: tensor(3.7629)\n",
      "1895 Traning Loss: tensor(3.7627)\n",
      "1896 Traning Loss: tensor(3.7625)\n",
      "1897 Traning Loss: tensor(3.7623)\n",
      "1898 Traning Loss: tensor(3.7620)\n",
      "1899 Traning Loss: tensor(3.7618)\n",
      "1900 Traning Loss: tensor(3.7616)\n",
      "1901 Traning Loss: tensor(3.7614)\n",
      "1902 Traning Loss: tensor(3.7611)\n",
      "1903 Traning Loss: tensor(3.7609)\n",
      "1904 Traning Loss: tensor(3.7607)\n",
      "1905 Traning Loss: tensor(3.7605)\n",
      "1906 Traning Loss: tensor(3.7602)\n",
      "1907 Traning Loss: tensor(3.7600)\n",
      "1908 Traning Loss: tensor(3.7598)\n",
      "1909 Traning Loss: tensor(3.7596)\n",
      "1910 Traning Loss: tensor(3.7593)\n",
      "1911 Traning Loss: tensor(3.7591)\n",
      "1912 Traning Loss: tensor(3.7589)\n",
      "1913 Traning Loss: tensor(3.7586)\n",
      "1914 Traning Loss: tensor(3.7584)\n",
      "1915 Traning Loss: tensor(3.7582)\n",
      "1916 Traning Loss: tensor(3.7579)\n",
      "1917 Traning Loss: tensor(3.7577)\n",
      "1918 Traning Loss: tensor(3.7575)\n",
      "1919 Traning Loss: tensor(3.7573)\n",
      "1920 Traning Loss: tensor(3.7570)\n",
      "1921 Traning Loss: tensor(3.7568)\n",
      "1922 Traning Loss: tensor(3.7566)\n",
      "1923 Traning Loss: tensor(3.7563)\n",
      "1924 Traning Loss: tensor(3.7561)\n",
      "1925 Traning Loss: tensor(3.7559)\n",
      "1926 Traning Loss: tensor(3.7556)\n",
      "1927 Traning Loss: tensor(3.7554)\n",
      "1928 Traning Loss: tensor(3.7552)\n",
      "1929 Traning Loss: tensor(3.7549)\n",
      "1930 Traning Loss: tensor(3.7547)\n",
      "1931 Traning Loss: tensor(3.7545)\n",
      "1932 Traning Loss: tensor(3.7542)\n",
      "1933 Traning Loss: tensor(3.7540)\n",
      "1934 Traning Loss: tensor(3.7538)\n",
      "1935 Traning Loss: tensor(3.7535)\n",
      "1936 Traning Loss: tensor(3.7533)\n",
      "1937 Traning Loss: tensor(3.7531)\n",
      "1938 Traning Loss: tensor(3.7528)\n",
      "1939 Traning Loss: tensor(3.7526)\n",
      "1940 Traning Loss: tensor(3.7524)\n",
      "1941 Traning Loss: tensor(3.7521)\n",
      "1942 Traning Loss: tensor(3.7519)\n",
      "1943 Traning Loss: tensor(3.7517)\n",
      "1944 Traning Loss: tensor(3.7514)\n",
      "1945 Traning Loss: tensor(3.7512)\n",
      "1946 Traning Loss: tensor(3.7510)\n",
      "1947 Traning Loss: tensor(3.7507)\n",
      "1948 Traning Loss: tensor(3.7505)\n",
      "1949 Traning Loss: tensor(3.7503)\n",
      "1950 Traning Loss: tensor(3.7500)\n",
      "1951 Traning Loss: tensor(3.7498)\n",
      "1952 Traning Loss: tensor(3.7495)\n",
      "1953 Traning Loss: tensor(3.7493)\n",
      "1954 Traning Loss: tensor(3.7491)\n",
      "1955 Traning Loss: tensor(3.7488)\n",
      "1956 Traning Loss: tensor(3.7486)\n",
      "1957 Traning Loss: tensor(3.7484)\n",
      "1958 Traning Loss: tensor(3.7481)\n",
      "1959 Traning Loss: tensor(3.7479)\n",
      "1960 Traning Loss: tensor(3.7476)\n",
      "1961 Traning Loss: tensor(3.7474)\n",
      "1962 Traning Loss: tensor(3.7472)\n",
      "1963 Traning Loss: tensor(3.7469)\n",
      "1964 Traning Loss: tensor(3.7467)\n",
      "1965 Traning Loss: tensor(3.7464)\n",
      "1966 Traning Loss: tensor(3.7462)\n",
      "1967 Traning Loss: tensor(3.7460)\n",
      "1968 Traning Loss: tensor(3.7457)\n",
      "1969 Traning Loss: tensor(3.7455)\n",
      "1970 Traning Loss: tensor(3.7452)\n",
      "1971 Traning Loss: tensor(3.7450)\n",
      "1972 Traning Loss: tensor(3.7448)\n",
      "1973 Traning Loss: tensor(3.7445)\n",
      "1974 Traning Loss: tensor(3.7443)\n",
      "1975 Traning Loss: tensor(3.7440)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976 Traning Loss: tensor(3.7438)\n",
      "1977 Traning Loss: tensor(3.7436)\n",
      "1978 Traning Loss: tensor(3.7433)\n",
      "1979 Traning Loss: tensor(3.7431)\n",
      "1980 Traning Loss: tensor(3.7428)\n",
      "1981 Traning Loss: tensor(3.7426)\n",
      "1982 Traning Loss: tensor(3.7424)\n",
      "1983 Traning Loss: tensor(3.7421)\n",
      "1984 Traning Loss: tensor(3.7419)\n",
      "1985 Traning Loss: tensor(3.7416)\n",
      "1986 Traning Loss: tensor(3.7414)\n",
      "1987 Traning Loss: tensor(3.7411)\n",
      "1988 Traning Loss: tensor(3.7409)\n",
      "1989 Traning Loss: tensor(3.7407)\n",
      "1990 Traning Loss: tensor(3.7404)\n",
      "1991 Traning Loss: tensor(3.7402)\n",
      "1992 Traning Loss: tensor(3.7399)\n",
      "1993 Traning Loss: tensor(3.7397)\n",
      "1994 Traning Loss: tensor(3.7395)\n",
      "1995 Traning Loss: tensor(3.7392)\n",
      "1996 Traning Loss: tensor(3.7390)\n",
      "1997 Traning Loss: tensor(3.7387)\n",
      "1998 Traning Loss: tensor(3.7385)\n",
      "1999 Traning Loss: tensor(3.7382)\n",
      "2000 Traning Loss: tensor(3.7380)\n",
      "2001 Traning Loss: tensor(3.7378)\n",
      "2002 Traning Loss: tensor(3.7375)\n",
      "2003 Traning Loss: tensor(3.7373)\n",
      "2004 Traning Loss: tensor(3.7370)\n",
      "2005 Traning Loss: tensor(3.7368)\n",
      "2006 Traning Loss: tensor(3.7365)\n",
      "2007 Traning Loss: tensor(3.7363)\n",
      "2008 Traning Loss: tensor(3.7361)\n",
      "2009 Traning Loss: tensor(3.7358)\n",
      "2010 Traning Loss: tensor(3.7356)\n",
      "2011 Traning Loss: tensor(3.7353)\n",
      "2012 Traning Loss: tensor(3.7351)\n",
      "2013 Traning Loss: tensor(3.7348)\n",
      "2014 Traning Loss: tensor(3.7346)\n",
      "2015 Traning Loss: tensor(3.7343)\n",
      "2016 Traning Loss: tensor(3.7341)\n",
      "2017 Traning Loss: tensor(3.7339)\n",
      "2018 Traning Loss: tensor(3.7336)\n",
      "2019 Traning Loss: tensor(3.7334)\n",
      "2020 Traning Loss: tensor(3.7331)\n",
      "2021 Traning Loss: tensor(3.7329)\n",
      "2022 Traning Loss: tensor(3.7326)\n",
      "2023 Traning Loss: tensor(3.7324)\n",
      "2024 Traning Loss: tensor(3.7322)\n",
      "2025 Traning Loss: tensor(3.7319)\n",
      "2026 Traning Loss: tensor(3.7317)\n",
      "2027 Traning Loss: tensor(3.7314)\n",
      "2028 Traning Loss: tensor(3.7312)\n",
      "2029 Traning Loss: tensor(3.7309)\n",
      "2030 Traning Loss: tensor(3.7307)\n",
      "2031 Traning Loss: tensor(3.7305)\n",
      "2032 Traning Loss: tensor(3.7302)\n",
      "2033 Traning Loss: tensor(3.7300)\n",
      "2034 Traning Loss: tensor(3.7297)\n",
      "2035 Traning Loss: tensor(3.7295)\n",
      "2036 Traning Loss: tensor(3.7292)\n",
      "2037 Traning Loss: tensor(3.7290)\n",
      "2038 Traning Loss: tensor(3.7288)\n",
      "2039 Traning Loss: tensor(3.7285)\n",
      "2040 Traning Loss: tensor(3.7283)\n",
      "2041 Traning Loss: tensor(3.7280)\n",
      "2042 Traning Loss: tensor(3.7278)\n",
      "2043 Traning Loss: tensor(3.7276)\n",
      "2044 Traning Loss: tensor(3.7273)\n",
      "2045 Traning Loss: tensor(3.7271)\n",
      "2046 Traning Loss: tensor(3.7268)\n",
      "2047 Traning Loss: tensor(3.7266)\n",
      "2048 Traning Loss: tensor(3.7263)\n",
      "2049 Traning Loss: tensor(3.7261)\n",
      "2050 Traning Loss: tensor(3.7259)\n",
      "2051 Traning Loss: tensor(3.7256)\n",
      "2052 Traning Loss: tensor(3.7254)\n",
      "2053 Traning Loss: tensor(3.7251)\n",
      "2054 Traning Loss: tensor(3.7249)\n",
      "2055 Traning Loss: tensor(3.7247)\n",
      "2056 Traning Loss: tensor(3.7244)\n",
      "2057 Traning Loss: tensor(3.7242)\n",
      "2058 Traning Loss: tensor(3.7239)\n",
      "2059 Traning Loss: tensor(3.7237)\n",
      "2060 Traning Loss: tensor(3.7235)\n",
      "2061 Traning Loss: tensor(3.7232)\n",
      "2062 Traning Loss: tensor(3.7230)\n",
      "2063 Traning Loss: tensor(3.7227)\n",
      "2064 Traning Loss: tensor(3.7225)\n",
      "2065 Traning Loss: tensor(3.7223)\n",
      "2066 Traning Loss: tensor(3.7220)\n",
      "2067 Traning Loss: tensor(3.7218)\n",
      "2068 Traning Loss: tensor(3.7215)\n",
      "2069 Traning Loss: tensor(3.7213)\n",
      "2070 Traning Loss: tensor(3.7211)\n",
      "2071 Traning Loss: tensor(3.7208)\n",
      "2072 Traning Loss: tensor(3.7206)\n",
      "2073 Traning Loss: tensor(3.7204)\n",
      "2074 Traning Loss: tensor(3.7201)\n",
      "2075 Traning Loss: tensor(3.7199)\n",
      "2076 Traning Loss: tensor(3.7196)\n",
      "2077 Traning Loss: tensor(3.7194)\n",
      "2078 Traning Loss: tensor(3.7192)\n",
      "2079 Traning Loss: tensor(3.7189)\n",
      "2080 Traning Loss: tensor(3.7187)\n",
      "2081 Traning Loss: tensor(3.7185)\n",
      "2082 Traning Loss: tensor(3.7182)\n",
      "2083 Traning Loss: tensor(3.7180)\n",
      "2084 Traning Loss: tensor(3.7178)\n",
      "2085 Traning Loss: tensor(3.7175)\n",
      "2086 Traning Loss: tensor(3.7173)\n",
      "2087 Traning Loss: tensor(3.7170)\n",
      "2088 Traning Loss: tensor(3.7168)\n",
      "2089 Traning Loss: tensor(3.7166)\n",
      "2090 Traning Loss: tensor(3.7163)\n",
      "2091 Traning Loss: tensor(3.7161)\n",
      "2092 Traning Loss: tensor(3.7159)\n",
      "2093 Traning Loss: tensor(3.7156)\n",
      "2094 Traning Loss: tensor(3.7154)\n",
      "2095 Traning Loss: tensor(3.7152)\n",
      "2096 Traning Loss: tensor(3.7149)\n",
      "2097 Traning Loss: tensor(3.7147)\n",
      "2098 Traning Loss: tensor(3.7145)\n",
      "2099 Traning Loss: tensor(3.7143)\n",
      "2100 Traning Loss: tensor(3.7140)\n",
      "2101 Traning Loss: tensor(3.7138)\n",
      "2102 Traning Loss: tensor(3.7136)\n",
      "2103 Traning Loss: tensor(3.7133)\n",
      "2104 Traning Loss: tensor(3.7131)\n",
      "2105 Traning Loss: tensor(3.7129)\n",
      "2106 Traning Loss: tensor(3.7126)\n",
      "2107 Traning Loss: tensor(3.7124)\n",
      "2108 Traning Loss: tensor(3.7122)\n",
      "2109 Traning Loss: tensor(3.7120)\n",
      "2110 Traning Loss: tensor(3.7117)\n",
      "2111 Traning Loss: tensor(3.7115)\n",
      "2112 Traning Loss: tensor(3.7113)\n",
      "2113 Traning Loss: tensor(3.7110)\n",
      "2114 Traning Loss: tensor(3.7108)\n",
      "2115 Traning Loss: tensor(3.7106)\n",
      "2116 Traning Loss: tensor(3.7104)\n",
      "2117 Traning Loss: tensor(3.7101)\n",
      "2118 Traning Loss: tensor(3.7099)\n",
      "2119 Traning Loss: tensor(3.7097)\n",
      "2120 Traning Loss: tensor(3.7095)\n",
      "2121 Traning Loss: tensor(3.7092)\n",
      "2122 Traning Loss: tensor(3.7090)\n",
      "2123 Traning Loss: tensor(3.7088)\n",
      "2124 Traning Loss: tensor(3.7086)\n",
      "2125 Traning Loss: tensor(3.7084)\n",
      "2126 Traning Loss: tensor(3.7081)\n",
      "2127 Traning Loss: tensor(3.7079)\n",
      "2128 Traning Loss: tensor(3.7077)\n",
      "2129 Traning Loss: tensor(3.7075)\n",
      "2130 Traning Loss: tensor(3.7072)\n",
      "2131 Traning Loss: tensor(3.7070)\n",
      "2132 Traning Loss: tensor(3.7068)\n",
      "2133 Traning Loss: tensor(3.7066)\n",
      "2134 Traning Loss: tensor(3.7064)\n",
      "2135 Traning Loss: tensor(3.7061)\n",
      "2136 Traning Loss: tensor(3.7059)\n",
      "2137 Traning Loss: tensor(3.7057)\n",
      "2138 Traning Loss: tensor(3.7055)\n",
      "2139 Traning Loss: tensor(3.7053)\n",
      "2140 Traning Loss: tensor(3.7051)\n",
      "2141 Traning Loss: tensor(3.7048)\n",
      "2142 Traning Loss: tensor(3.7046)\n",
      "2143 Traning Loss: tensor(3.7044)\n",
      "2144 Traning Loss: tensor(3.7042)\n",
      "2145 Traning Loss: tensor(3.7040)\n",
      "2146 Traning Loss: tensor(3.7038)\n",
      "2147 Traning Loss: tensor(3.7035)\n",
      "2148 Traning Loss: tensor(3.7033)\n",
      "2149 Traning Loss: tensor(3.7031)\n",
      "2150 Traning Loss: tensor(3.7029)\n",
      "2151 Traning Loss: tensor(3.7027)\n",
      "2152 Traning Loss: tensor(3.7025)\n",
      "2153 Traning Loss: tensor(3.7023)\n",
      "2154 Traning Loss: tensor(3.7021)\n",
      "2155 Traning Loss: tensor(3.7019)\n",
      "2156 Traning Loss: tensor(3.7016)\n",
      "2157 Traning Loss: tensor(3.7014)\n",
      "2158 Traning Loss: tensor(3.7012)\n",
      "2159 Traning Loss: tensor(3.7010)\n",
      "2160 Traning Loss: tensor(3.7008)\n",
      "2161 Traning Loss: tensor(3.7006)\n",
      "2162 Traning Loss: tensor(3.7004)\n",
      "2163 Traning Loss: tensor(3.7002)\n",
      "2164 Traning Loss: tensor(3.7000)\n",
      "2165 Traning Loss: tensor(3.6998)\n",
      "2166 Traning Loss: tensor(3.6996)\n",
      "2167 Traning Loss: tensor(3.6994)\n",
      "2168 Traning Loss: tensor(3.6992)\n",
      "2169 Traning Loss: tensor(3.6990)\n",
      "2170 Traning Loss: tensor(3.6987)\n",
      "2171 Traning Loss: tensor(3.6985)\n",
      "2172 Traning Loss: tensor(3.6983)\n",
      "2173 Traning Loss: tensor(3.6981)\n",
      "2174 Traning Loss: tensor(3.6979)\n",
      "2175 Traning Loss: tensor(3.6977)\n",
      "2176 Traning Loss: tensor(3.6975)\n",
      "2177 Traning Loss: tensor(3.6973)\n",
      "2178 Traning Loss: tensor(3.6971)\n",
      "2179 Traning Loss: tensor(3.6969)\n",
      "2180 Traning Loss: tensor(3.6967)\n",
      "2181 Traning Loss: tensor(3.6965)\n",
      "2182 Traning Loss: tensor(3.6963)\n",
      "2183 Traning Loss: tensor(3.6961)\n",
      "2184 Traning Loss: tensor(3.6959)\n",
      "2185 Traning Loss: tensor(3.6957)\n",
      "2186 Traning Loss: tensor(3.6955)\n",
      "2187 Traning Loss: tensor(3.6954)\n",
      "2188 Traning Loss: tensor(3.6952)\n",
      "2189 Traning Loss: tensor(3.6950)\n",
      "2190 Traning Loss: tensor(3.6948)\n",
      "2191 Traning Loss: tensor(3.6946)\n",
      "2192 Traning Loss: tensor(3.6944)\n",
      "2193 Traning Loss: tensor(3.6942)\n",
      "2194 Traning Loss: tensor(3.6940)\n",
      "2195 Traning Loss: tensor(3.6938)\n",
      "2196 Traning Loss: tensor(3.6936)\n",
      "2197 Traning Loss: tensor(3.6934)\n",
      "2198 Traning Loss: tensor(3.6932)\n",
      "2199 Traning Loss: tensor(3.6930)\n",
      "2200 Traning Loss: tensor(3.6928)\n",
      "2201 Traning Loss: tensor(3.6927)\n",
      "2202 Traning Loss: tensor(3.6925)\n",
      "2203 Traning Loss: tensor(3.6923)\n",
      "2204 Traning Loss: tensor(3.6921)\n",
      "2205 Traning Loss: tensor(3.6919)\n",
      "2206 Traning Loss: tensor(3.6917)\n",
      "2207 Traning Loss: tensor(3.6915)\n",
      "2208 Traning Loss: tensor(3.6913)\n",
      "2209 Traning Loss: tensor(3.6912)\n",
      "2210 Traning Loss: tensor(3.6910)\n",
      "2211 Traning Loss: tensor(3.6908)\n",
      "2212 Traning Loss: tensor(3.6906)\n",
      "2213 Traning Loss: tensor(3.6904)\n",
      "2214 Traning Loss: tensor(3.6902)\n",
      "2215 Traning Loss: tensor(3.6901)\n",
      "2216 Traning Loss: tensor(3.6899)\n",
      "2217 Traning Loss: tensor(3.6897)\n",
      "2218 Traning Loss: tensor(3.6895)\n",
      "2219 Traning Loss: tensor(3.6893)\n",
      "2220 Traning Loss: tensor(3.6891)\n",
      "2221 Traning Loss: tensor(3.6890)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222 Traning Loss: tensor(3.6888)\n",
      "2223 Traning Loss: tensor(3.6886)\n",
      "2224 Traning Loss: tensor(3.6884)\n",
      "2225 Traning Loss: tensor(3.6883)\n",
      "2226 Traning Loss: tensor(3.6881)\n",
      "2227 Traning Loss: tensor(3.6879)\n",
      "2228 Traning Loss: tensor(3.6877)\n",
      "2229 Traning Loss: tensor(3.6875)\n",
      "2230 Traning Loss: tensor(3.6874)\n",
      "2231 Traning Loss: tensor(3.6872)\n",
      "2232 Traning Loss: tensor(3.6870)\n",
      "2233 Traning Loss: tensor(3.6868)\n",
      "2234 Traning Loss: tensor(3.6867)\n",
      "2235 Traning Loss: tensor(3.6865)\n",
      "2236 Traning Loss: tensor(3.6863)\n",
      "2237 Traning Loss: tensor(3.6862)\n",
      "2238 Traning Loss: tensor(3.6860)\n",
      "2239 Traning Loss: tensor(3.6858)\n",
      "2240 Traning Loss: tensor(3.6856)\n",
      "2241 Traning Loss: tensor(3.6855)\n",
      "2242 Traning Loss: tensor(3.6853)\n",
      "2243 Traning Loss: tensor(3.6851)\n",
      "2244 Traning Loss: tensor(3.6850)\n",
      "2245 Traning Loss: tensor(3.6848)\n",
      "2246 Traning Loss: tensor(3.6846)\n",
      "2247 Traning Loss: tensor(3.6845)\n",
      "2248 Traning Loss: tensor(3.6843)\n",
      "2249 Traning Loss: tensor(3.6841)\n",
      "2250 Traning Loss: tensor(3.6840)\n",
      "2251 Traning Loss: tensor(3.6838)\n",
      "2252 Traning Loss: tensor(3.6836)\n",
      "2253 Traning Loss: tensor(3.6835)\n",
      "2254 Traning Loss: tensor(3.6833)\n",
      "2255 Traning Loss: tensor(3.6831)\n",
      "2256 Traning Loss: tensor(3.6830)\n",
      "2257 Traning Loss: tensor(3.6828)\n",
      "2258 Traning Loss: tensor(3.6826)\n",
      "2259 Traning Loss: tensor(3.6825)\n",
      "2260 Traning Loss: tensor(3.6823)\n",
      "2261 Traning Loss: tensor(3.6822)\n",
      "2262 Traning Loss: tensor(3.6820)\n",
      "2263 Traning Loss: tensor(3.6818)\n",
      "2264 Traning Loss: tensor(3.6817)\n",
      "2265 Traning Loss: tensor(3.6815)\n",
      "2266 Traning Loss: tensor(3.6814)\n",
      "2267 Traning Loss: tensor(3.6812)\n",
      "2268 Traning Loss: tensor(3.6810)\n",
      "2269 Traning Loss: tensor(3.6809)\n",
      "2270 Traning Loss: tensor(3.6807)\n",
      "2271 Traning Loss: tensor(3.6806)\n",
      "2272 Traning Loss: tensor(3.6804)\n",
      "2273 Traning Loss: tensor(3.6802)\n",
      "2274 Traning Loss: tensor(3.6801)\n",
      "2275 Traning Loss: tensor(3.6799)\n",
      "2276 Traning Loss: tensor(3.6798)\n",
      "2277 Traning Loss: tensor(3.6796)\n",
      "2278 Traning Loss: tensor(3.6795)\n",
      "2279 Traning Loss: tensor(3.6793)\n",
      "2280 Traning Loss: tensor(3.6792)\n",
      "2281 Traning Loss: tensor(3.6790)\n",
      "2282 Traning Loss: tensor(3.6789)\n",
      "2283 Traning Loss: tensor(3.6787)\n",
      "2284 Traning Loss: tensor(3.6786)\n",
      "2285 Traning Loss: tensor(3.6784)\n",
      "2286 Traning Loss: tensor(3.6783)\n",
      "2287 Traning Loss: tensor(3.6781)\n",
      "2288 Traning Loss: tensor(3.6780)\n",
      "2289 Traning Loss: tensor(3.6778)\n",
      "2290 Traning Loss: tensor(3.6777)\n",
      "2291 Traning Loss: tensor(3.6775)\n",
      "2292 Traning Loss: tensor(3.6774)\n",
      "2293 Traning Loss: tensor(3.6772)\n",
      "2294 Traning Loss: tensor(3.6771)\n",
      "2295 Traning Loss: tensor(3.6769)\n",
      "2296 Traning Loss: tensor(3.6768)\n",
      "2297 Traning Loss: tensor(3.6766)\n",
      "2298 Traning Loss: tensor(3.6765)\n",
      "2299 Traning Loss: tensor(3.6763)\n",
      "2300 Traning Loss: tensor(3.6762)\n",
      "2301 Traning Loss: tensor(3.6760)\n",
      "2302 Traning Loss: tensor(3.6759)\n",
      "2303 Traning Loss: tensor(3.6758)\n",
      "2304 Traning Loss: tensor(3.6756)\n",
      "2305 Traning Loss: tensor(3.6755)\n",
      "2306 Traning Loss: tensor(3.6753)\n",
      "2307 Traning Loss: tensor(3.6752)\n",
      "2308 Traning Loss: tensor(3.6750)\n",
      "2309 Traning Loss: tensor(3.6749)\n",
      "2310 Traning Loss: tensor(3.6748)\n",
      "2311 Traning Loss: tensor(3.6746)\n",
      "2312 Traning Loss: tensor(3.6745)\n",
      "2313 Traning Loss: tensor(3.6743)\n",
      "2314 Traning Loss: tensor(3.6742)\n",
      "2315 Traning Loss: tensor(3.6741)\n",
      "2316 Traning Loss: tensor(3.6739)\n",
      "2317 Traning Loss: tensor(3.6738)\n",
      "2318 Traning Loss: tensor(3.6736)\n",
      "2319 Traning Loss: tensor(3.6735)\n",
      "2320 Traning Loss: tensor(3.6734)\n",
      "2321 Traning Loss: tensor(3.6732)\n",
      "2322 Traning Loss: tensor(3.6731)\n",
      "2323 Traning Loss: tensor(3.6729)\n",
      "2324 Traning Loss: tensor(3.6728)\n",
      "2325 Traning Loss: tensor(3.6727)\n",
      "2326 Traning Loss: tensor(3.6725)\n",
      "2327 Traning Loss: tensor(3.6724)\n",
      "2328 Traning Loss: tensor(3.6723)\n",
      "2329 Traning Loss: tensor(3.6721)\n",
      "2330 Traning Loss: tensor(3.6720)\n",
      "2331 Traning Loss: tensor(3.6719)\n",
      "2332 Traning Loss: tensor(3.6717)\n",
      "2333 Traning Loss: tensor(3.6716)\n",
      "2334 Traning Loss: tensor(3.6715)\n",
      "2335 Traning Loss: tensor(3.6713)\n",
      "2336 Traning Loss: tensor(3.6712)\n",
      "2337 Traning Loss: tensor(3.6711)\n",
      "2338 Traning Loss: tensor(3.6709)\n",
      "2339 Traning Loss: tensor(3.6708)\n",
      "2340 Traning Loss: tensor(3.6707)\n",
      "2341 Traning Loss: tensor(3.6705)\n",
      "2342 Traning Loss: tensor(3.6704)\n",
      "2343 Traning Loss: tensor(3.6703)\n",
      "2344 Traning Loss: tensor(3.6701)\n",
      "2345 Traning Loss: tensor(3.6700)\n",
      "2346 Traning Loss: tensor(3.6699)\n",
      "2347 Traning Loss: tensor(3.6697)\n",
      "2348 Traning Loss: tensor(3.6696)\n",
      "2349 Traning Loss: tensor(3.6695)\n",
      "2350 Traning Loss: tensor(3.6694)\n",
      "2351 Traning Loss: tensor(3.6692)\n",
      "2352 Traning Loss: tensor(3.6691)\n",
      "2353 Traning Loss: tensor(3.6690)\n",
      "2354 Traning Loss: tensor(3.6688)\n",
      "2355 Traning Loss: tensor(3.6687)\n",
      "2356 Traning Loss: tensor(3.6686)\n",
      "2357 Traning Loss: tensor(3.6685)\n",
      "2358 Traning Loss: tensor(3.6683)\n",
      "2359 Traning Loss: tensor(3.6682)\n",
      "2360 Traning Loss: tensor(3.6681)\n",
      "2361 Traning Loss: tensor(3.6679)\n",
      "2362 Traning Loss: tensor(3.6678)\n",
      "2363 Traning Loss: tensor(3.6677)\n",
      "2364 Traning Loss: tensor(3.6676)\n",
      "2365 Traning Loss: tensor(3.6674)\n",
      "2366 Traning Loss: tensor(3.6673)\n",
      "2367 Traning Loss: tensor(3.6672)\n",
      "2368 Traning Loss: tensor(3.6671)\n",
      "2369 Traning Loss: tensor(3.6669)\n",
      "2370 Traning Loss: tensor(3.6668)\n",
      "2371 Traning Loss: tensor(3.6667)\n",
      "2372 Traning Loss: tensor(3.6666)\n",
      "2373 Traning Loss: tensor(3.6664)\n",
      "2374 Traning Loss: tensor(3.6663)\n",
      "2375 Traning Loss: tensor(3.6662)\n",
      "2376 Traning Loss: tensor(3.6661)\n",
      "2377 Traning Loss: tensor(3.6660)\n",
      "2378 Traning Loss: tensor(3.6658)\n",
      "2379 Traning Loss: tensor(3.6657)\n",
      "2380 Traning Loss: tensor(3.6656)\n",
      "2381 Traning Loss: tensor(3.6655)\n",
      "2382 Traning Loss: tensor(3.6653)\n",
      "2383 Traning Loss: tensor(3.6652)\n",
      "2384 Traning Loss: tensor(3.6651)\n",
      "2385 Traning Loss: tensor(3.6650)\n",
      "2386 Traning Loss: tensor(3.6648)\n",
      "2387 Traning Loss: tensor(3.6647)\n",
      "2388 Traning Loss: tensor(3.6646)\n",
      "2389 Traning Loss: tensor(3.6645)\n",
      "2390 Traning Loss: tensor(3.6644)\n",
      "2391 Traning Loss: tensor(3.6642)\n",
      "2392 Traning Loss: tensor(3.6641)\n",
      "2393 Traning Loss: tensor(3.6640)\n",
      "2394 Traning Loss: tensor(3.6639)\n",
      "2395 Traning Loss: tensor(3.6638)\n",
      "2396 Traning Loss: tensor(3.6636)\n",
      "2397 Traning Loss: tensor(3.6635)\n",
      "2398 Traning Loss: tensor(3.6634)\n",
      "2399 Traning Loss: tensor(3.6633)\n",
      "2400 Traning Loss: tensor(3.6632)\n",
      "2401 Traning Loss: tensor(3.6630)\n",
      "2402 Traning Loss: tensor(3.6629)\n",
      "2403 Traning Loss: tensor(3.6628)\n",
      "2404 Traning Loss: tensor(3.6627)\n",
      "2405 Traning Loss: tensor(3.6626)\n",
      "2406 Traning Loss: tensor(3.6624)\n",
      "2407 Traning Loss: tensor(3.6623)\n",
      "2408 Traning Loss: tensor(3.6622)\n",
      "2409 Traning Loss: tensor(3.6621)\n",
      "2410 Traning Loss: tensor(3.6620)\n",
      "2411 Traning Loss: tensor(3.6618)\n",
      "2412 Traning Loss: tensor(3.6617)\n",
      "2413 Traning Loss: tensor(3.6616)\n",
      "2414 Traning Loss: tensor(3.6615)\n",
      "2415 Traning Loss: tensor(3.6614)\n",
      "2416 Traning Loss: tensor(3.6613)\n",
      "2417 Traning Loss: tensor(3.6611)\n",
      "2418 Traning Loss: tensor(3.6610)\n",
      "2419 Traning Loss: tensor(3.6609)\n",
      "2420 Traning Loss: tensor(3.6608)\n",
      "2421 Traning Loss: tensor(3.6607)\n",
      "2422 Traning Loss: tensor(3.6605)\n",
      "2423 Traning Loss: tensor(3.6604)\n",
      "2424 Traning Loss: tensor(3.6603)\n",
      "2425 Traning Loss: tensor(3.6602)\n",
      "2426 Traning Loss: tensor(3.6601)\n",
      "2427 Traning Loss: tensor(3.6600)\n",
      "2428 Traning Loss: tensor(3.6598)\n",
      "2429 Traning Loss: tensor(3.6597)\n",
      "2430 Traning Loss: tensor(3.6596)\n",
      "2431 Traning Loss: tensor(3.6595)\n",
      "2432 Traning Loss: tensor(3.6594)\n",
      "2433 Traning Loss: tensor(3.6592)\n",
      "2434 Traning Loss: tensor(3.6591)\n",
      "2435 Traning Loss: tensor(3.6590)\n",
      "2436 Traning Loss: tensor(3.6589)\n",
      "2437 Traning Loss: tensor(3.6588)\n",
      "2438 Traning Loss: tensor(3.6587)\n",
      "2439 Traning Loss: tensor(3.6585)\n",
      "2440 Traning Loss: tensor(3.6584)\n",
      "2441 Traning Loss: tensor(3.6583)\n",
      "2442 Traning Loss: tensor(3.6582)\n",
      "2443 Traning Loss: tensor(3.6581)\n",
      "2444 Traning Loss: tensor(3.6580)\n",
      "2445 Traning Loss: tensor(3.6578)\n",
      "2446 Traning Loss: tensor(3.6577)\n",
      "2447 Traning Loss: tensor(3.6576)\n",
      "2448 Traning Loss: tensor(3.6575)\n",
      "2449 Traning Loss: tensor(3.6574)\n",
      "2450 Traning Loss: tensor(3.6572)\n",
      "2451 Traning Loss: tensor(3.6571)\n",
      "2452 Traning Loss: tensor(3.6570)\n",
      "2453 Traning Loss: tensor(3.6569)\n",
      "2454 Traning Loss: tensor(3.6568)\n",
      "2455 Traning Loss: tensor(3.6567)\n",
      "2456 Traning Loss: tensor(3.6565)\n",
      "2457 Traning Loss: tensor(3.6564)\n",
      "2458 Traning Loss: tensor(3.6563)\n",
      "2459 Traning Loss: tensor(3.6562)\n",
      "2460 Traning Loss: tensor(3.6561)\n",
      "2461 Traning Loss: tensor(3.6559)\n",
      "2462 Traning Loss: tensor(3.6558)\n",
      "2463 Traning Loss: tensor(3.6557)\n",
      "2464 Traning Loss: tensor(3.6556)\n",
      "2465 Traning Loss: tensor(3.6555)\n",
      "2466 Traning Loss: tensor(3.6554)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2467 Traning Loss: tensor(3.6552)\n",
      "2468 Traning Loss: tensor(3.6551)\n",
      "2469 Traning Loss: tensor(3.6550)\n",
      "2470 Traning Loss: tensor(3.6549)\n",
      "2471 Traning Loss: tensor(3.6548)\n",
      "2472 Traning Loss: tensor(3.6546)\n",
      "2473 Traning Loss: tensor(3.6545)\n",
      "2474 Traning Loss: tensor(3.6544)\n",
      "2475 Traning Loss: tensor(3.6543)\n",
      "2476 Traning Loss: tensor(3.6542)\n",
      "2477 Traning Loss: tensor(3.6540)\n",
      "2478 Traning Loss: tensor(3.6539)\n",
      "2479 Traning Loss: tensor(3.6538)\n",
      "2480 Traning Loss: tensor(3.6537)\n",
      "2481 Traning Loss: tensor(3.6536)\n",
      "2482 Traning Loss: tensor(3.6534)\n",
      "2483 Traning Loss: tensor(3.6533)\n",
      "2484 Traning Loss: tensor(3.6532)\n",
      "2485 Traning Loss: tensor(3.6531)\n",
      "2486 Traning Loss: tensor(3.6529)\n",
      "2487 Traning Loss: tensor(3.6528)\n",
      "2488 Traning Loss: tensor(3.6527)\n",
      "2489 Traning Loss: tensor(3.6526)\n",
      "2490 Traning Loss: tensor(3.6525)\n",
      "2491 Traning Loss: tensor(3.6523)\n",
      "2492 Traning Loss: tensor(3.6522)\n",
      "2493 Traning Loss: tensor(3.6521)\n",
      "2494 Traning Loss: tensor(3.6520)\n",
      "2495 Traning Loss: tensor(3.6518)\n",
      "2496 Traning Loss: tensor(3.6517)\n",
      "2497 Traning Loss: tensor(3.6516)\n",
      "2498 Traning Loss: tensor(3.6515)\n",
      "2499 Traning Loss: tensor(3.6514)\n",
      "2500 Traning Loss: tensor(3.6512)\n",
      "2501 Traning Loss: tensor(3.6511)\n",
      "2502 Traning Loss: tensor(3.6510)\n",
      "2503 Traning Loss: tensor(3.6509)\n",
      "2504 Traning Loss: tensor(3.6507)\n",
      "2505 Traning Loss: tensor(3.6506)\n",
      "2506 Traning Loss: tensor(3.6505)\n",
      "2507 Traning Loss: tensor(3.6504)\n",
      "2508 Traning Loss: tensor(3.6502)\n",
      "2509 Traning Loss: tensor(3.6501)\n",
      "2510 Traning Loss: tensor(3.6500)\n",
      "2511 Traning Loss: tensor(3.6498)\n",
      "2512 Traning Loss: tensor(3.6497)\n",
      "2513 Traning Loss: tensor(3.6496)\n",
      "2514 Traning Loss: tensor(3.6495)\n",
      "2515 Traning Loss: tensor(3.6493)\n",
      "2516 Traning Loss: tensor(3.6492)\n",
      "2517 Traning Loss: tensor(3.6491)\n",
      "2518 Traning Loss: tensor(3.6489)\n",
      "2519 Traning Loss: tensor(3.6488)\n",
      "2520 Traning Loss: tensor(3.6487)\n",
      "2521 Traning Loss: tensor(3.6486)\n",
      "2522 Traning Loss: tensor(3.6484)\n",
      "2523 Traning Loss: tensor(3.6483)\n",
      "2524 Traning Loss: tensor(3.6482)\n",
      "2525 Traning Loss: tensor(3.6480)\n",
      "2526 Traning Loss: tensor(3.6479)\n",
      "2527 Traning Loss: tensor(3.6478)\n",
      "2528 Traning Loss: tensor(3.6476)\n",
      "2529 Traning Loss: tensor(3.6475)\n",
      "2530 Traning Loss: tensor(3.6474)\n",
      "2531 Traning Loss: tensor(3.6472)\n",
      "2532 Traning Loss: tensor(3.6471)\n",
      "2533 Traning Loss: tensor(3.6470)\n",
      "2534 Traning Loss: tensor(3.6468)\n",
      "2535 Traning Loss: tensor(3.6467)\n",
      "2536 Traning Loss: tensor(3.6466)\n",
      "2537 Traning Loss: tensor(3.6464)\n",
      "2538 Traning Loss: tensor(3.6463)\n",
      "2539 Traning Loss: tensor(3.6461)\n",
      "2540 Traning Loss: tensor(3.6460)\n",
      "2541 Traning Loss: tensor(3.6459)\n",
      "2542 Traning Loss: tensor(3.6457)\n",
      "2543 Traning Loss: tensor(3.6456)\n",
      "2544 Traning Loss: tensor(3.6455)\n",
      "2545 Traning Loss: tensor(3.6453)\n",
      "2546 Traning Loss: tensor(3.6452)\n",
      "2547 Traning Loss: tensor(3.6450)\n",
      "2548 Traning Loss: tensor(3.6449)\n",
      "2549 Traning Loss: tensor(3.6448)\n",
      "2550 Traning Loss: tensor(3.6446)\n",
      "2551 Traning Loss: tensor(3.6445)\n",
      "2552 Traning Loss: tensor(3.6443)\n",
      "2553 Traning Loss: tensor(3.6442)\n",
      "2554 Traning Loss: tensor(3.6440)\n",
      "2555 Traning Loss: tensor(3.6439)\n",
      "2556 Traning Loss: tensor(3.6437)\n",
      "2557 Traning Loss: tensor(3.6436)\n",
      "2558 Traning Loss: tensor(3.6434)\n",
      "2559 Traning Loss: tensor(3.6433)\n",
      "2560 Traning Loss: tensor(3.6432)\n",
      "2561 Traning Loss: tensor(3.6430)\n",
      "2562 Traning Loss: tensor(3.6429)\n",
      "2563 Traning Loss: tensor(3.6427)\n",
      "2564 Traning Loss: tensor(3.6426)\n",
      "2565 Traning Loss: tensor(3.6424)\n",
      "2566 Traning Loss: tensor(3.6423)\n",
      "2567 Traning Loss: tensor(3.6421)\n",
      "2568 Traning Loss: tensor(3.6419)\n",
      "2569 Traning Loss: tensor(3.6418)\n",
      "2570 Traning Loss: tensor(3.6416)\n",
      "2571 Traning Loss: tensor(3.6415)\n",
      "2572 Traning Loss: tensor(3.6413)\n",
      "2573 Traning Loss: tensor(3.6412)\n",
      "2574 Traning Loss: tensor(3.6410)\n",
      "2575 Traning Loss: tensor(3.6409)\n",
      "2576 Traning Loss: tensor(3.6407)\n",
      "2577 Traning Loss: tensor(3.6405)\n",
      "2578 Traning Loss: tensor(3.6404)\n",
      "2579 Traning Loss: tensor(3.6402)\n",
      "2580 Traning Loss: tensor(3.6401)\n",
      "2581 Traning Loss: tensor(3.6399)\n",
      "2582 Traning Loss: tensor(3.6397)\n",
      "2583 Traning Loss: tensor(3.6396)\n",
      "2584 Traning Loss: tensor(3.6394)\n",
      "2585 Traning Loss: tensor(3.6392)\n",
      "2586 Traning Loss: tensor(3.6391)\n",
      "2587 Traning Loss: tensor(3.6389)\n",
      "2588 Traning Loss: tensor(3.6387)\n",
      "2589 Traning Loss: tensor(3.6386)\n",
      "2590 Traning Loss: tensor(3.6384)\n",
      "2591 Traning Loss: tensor(3.6382)\n",
      "2592 Traning Loss: tensor(3.6381)\n",
      "2593 Traning Loss: tensor(3.6379)\n",
      "2594 Traning Loss: tensor(3.6377)\n",
      "2595 Traning Loss: tensor(3.6375)\n",
      "2596 Traning Loss: tensor(3.6374)\n",
      "2597 Traning Loss: tensor(3.6372)\n",
      "2598 Traning Loss: tensor(3.6370)\n",
      "2599 Traning Loss: tensor(3.6368)\n",
      "2600 Traning Loss: tensor(3.6367)\n",
      "2601 Traning Loss: tensor(3.6365)\n",
      "2602 Traning Loss: tensor(3.6363)\n",
      "2603 Traning Loss: tensor(3.6361)\n",
      "2604 Traning Loss: tensor(3.6360)\n",
      "2605 Traning Loss: tensor(3.6358)\n",
      "2606 Traning Loss: tensor(3.6356)\n",
      "2607 Traning Loss: tensor(3.6354)\n",
      "2608 Traning Loss: tensor(3.6352)\n",
      "2609 Traning Loss: tensor(3.6350)\n",
      "2610 Traning Loss: tensor(3.6348)\n",
      "2611 Traning Loss: tensor(3.6347)\n",
      "2612 Traning Loss: tensor(3.6345)\n",
      "2613 Traning Loss: tensor(3.6343)\n",
      "2614 Traning Loss: tensor(3.6341)\n",
      "2615 Traning Loss: tensor(3.6339)\n",
      "2616 Traning Loss: tensor(3.6337)\n",
      "2617 Traning Loss: tensor(3.6335)\n",
      "2618 Traning Loss: tensor(3.6333)\n",
      "2619 Traning Loss: tensor(3.6331)\n",
      "2620 Traning Loss: tensor(3.6329)\n",
      "2621 Traning Loss: tensor(3.6327)\n",
      "2622 Traning Loss: tensor(3.6325)\n",
      "2623 Traning Loss: tensor(3.6323)\n",
      "2624 Traning Loss: tensor(3.6321)\n",
      "2625 Traning Loss: tensor(3.6319)\n",
      "2626 Traning Loss: tensor(3.6317)\n",
      "2627 Traning Loss: tensor(3.6315)\n",
      "2628 Traning Loss: tensor(3.6313)\n",
      "2629 Traning Loss: tensor(3.6311)\n",
      "2630 Traning Loss: tensor(3.6309)\n",
      "2631 Traning Loss: tensor(3.6307)\n",
      "2632 Traning Loss: tensor(3.6304)\n",
      "2633 Traning Loss: tensor(3.6302)\n",
      "2634 Traning Loss: tensor(3.6300)\n",
      "2635 Traning Loss: tensor(3.6298)\n",
      "2636 Traning Loss: tensor(3.6296)\n",
      "2637 Traning Loss: tensor(3.6294)\n",
      "2638 Traning Loss: tensor(3.6291)\n",
      "2639 Traning Loss: tensor(3.6289)\n",
      "2640 Traning Loss: tensor(3.6287)\n",
      "2641 Traning Loss: tensor(3.6285)\n",
      "2642 Traning Loss: tensor(3.6283)\n",
      "2643 Traning Loss: tensor(3.6280)\n",
      "2644 Traning Loss: tensor(3.6278)\n",
      "2645 Traning Loss: tensor(3.6276)\n",
      "2646 Traning Loss: tensor(3.6273)\n",
      "2647 Traning Loss: tensor(3.6271)\n",
      "2648 Traning Loss: tensor(3.6269)\n",
      "2649 Traning Loss: tensor(3.6266)\n",
      "2650 Traning Loss: tensor(3.6264)\n",
      "2651 Traning Loss: tensor(3.6262)\n",
      "2652 Traning Loss: tensor(3.6259)\n",
      "2653 Traning Loss: tensor(3.6257)\n",
      "2654 Traning Loss: tensor(3.6254)\n",
      "2655 Traning Loss: tensor(3.6252)\n",
      "2656 Traning Loss: tensor(3.6249)\n",
      "2657 Traning Loss: tensor(3.6247)\n",
      "2658 Traning Loss: tensor(3.6244)\n",
      "2659 Traning Loss: tensor(3.6242)\n",
      "2660 Traning Loss: tensor(3.6239)\n",
      "2661 Traning Loss: tensor(3.6237)\n",
      "2662 Traning Loss: tensor(3.6234)\n",
      "2663 Traning Loss: tensor(3.6232)\n",
      "2664 Traning Loss: tensor(3.6229)\n",
      "2665 Traning Loss: tensor(3.6226)\n",
      "2666 Traning Loss: tensor(3.6224)\n",
      "2667 Traning Loss: tensor(3.6221)\n",
      "2668 Traning Loss: tensor(3.6219)\n",
      "2669 Traning Loss: tensor(3.6216)\n",
      "2670 Traning Loss: tensor(3.6213)\n",
      "2671 Traning Loss: tensor(3.6210)\n",
      "2672 Traning Loss: tensor(3.6208)\n",
      "2673 Traning Loss: tensor(3.6205)\n",
      "2674 Traning Loss: tensor(3.6202)\n",
      "2675 Traning Loss: tensor(3.6199)\n",
      "2676 Traning Loss: tensor(3.6196)\n",
      "2677 Traning Loss: tensor(3.6194)\n",
      "2678 Traning Loss: tensor(3.6191)\n",
      "2679 Traning Loss: tensor(3.6188)\n",
      "2680 Traning Loss: tensor(3.6185)\n",
      "2681 Traning Loss: tensor(3.6182)\n",
      "2682 Traning Loss: tensor(3.6179)\n",
      "2683 Traning Loss: tensor(3.6176)\n",
      "2684 Traning Loss: tensor(3.6173)\n",
      "2685 Traning Loss: tensor(3.6170)\n",
      "2686 Traning Loss: tensor(3.6167)\n",
      "2687 Traning Loss: tensor(3.6164)\n",
      "2688 Traning Loss: tensor(3.6161)\n",
      "2689 Traning Loss: tensor(3.6158)\n",
      "2690 Traning Loss: tensor(3.6155)\n",
      "2691 Traning Loss: tensor(3.6152)\n",
      "2692 Traning Loss: tensor(3.6149)\n",
      "2693 Traning Loss: tensor(3.6145)\n",
      "2694 Traning Loss: tensor(3.6142)\n",
      "2695 Traning Loss: tensor(3.6139)\n",
      "2696 Traning Loss: tensor(3.6136)\n",
      "2697 Traning Loss: tensor(3.6133)\n",
      "2698 Traning Loss: tensor(3.6129)\n",
      "2699 Traning Loss: tensor(3.6126)\n",
      "2700 Traning Loss: tensor(3.6123)\n",
      "2701 Traning Loss: tensor(3.6119)\n",
      "2702 Traning Loss: tensor(3.6116)\n",
      "2703 Traning Loss: tensor(3.6112)\n",
      "2704 Traning Loss: tensor(3.6109)\n",
      "2705 Traning Loss: tensor(3.6106)\n",
      "2706 Traning Loss: tensor(3.6102)\n",
      "2707 Traning Loss: tensor(3.6099)\n",
      "2708 Traning Loss: tensor(3.6095)\n",
      "2709 Traning Loss: tensor(3.6091)\n",
      "2710 Traning Loss: tensor(3.6088)\n",
      "2711 Traning Loss: tensor(3.6084)\n",
      "2712 Traning Loss: tensor(3.6081)\n",
      "2713 Traning Loss: tensor(3.6077)\n",
      "2714 Traning Loss: tensor(3.6073)\n",
      "2715 Traning Loss: tensor(3.6070)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2716 Traning Loss: tensor(3.6066)\n",
      "2717 Traning Loss: tensor(3.6062)\n",
      "2718 Traning Loss: tensor(3.6058)\n",
      "2719 Traning Loss: tensor(3.6054)\n",
      "2720 Traning Loss: tensor(3.6051)\n",
      "2721 Traning Loss: tensor(3.6047)\n",
      "2722 Traning Loss: tensor(3.6043)\n",
      "2723 Traning Loss: tensor(3.6039)\n",
      "2724 Traning Loss: tensor(3.6035)\n",
      "2725 Traning Loss: tensor(3.6031)\n",
      "2726 Traning Loss: tensor(3.6027)\n",
      "2727 Traning Loss: tensor(3.6023)\n",
      "2728 Traning Loss: tensor(3.6019)\n",
      "2729 Traning Loss: tensor(3.6014)\n",
      "2730 Traning Loss: tensor(3.6010)\n",
      "2731 Traning Loss: tensor(3.6006)\n",
      "2732 Traning Loss: tensor(3.6002)\n",
      "2733 Traning Loss: tensor(3.5998)\n",
      "2734 Traning Loss: tensor(3.5993)\n",
      "2735 Traning Loss: tensor(3.5989)\n",
      "2736 Traning Loss: tensor(3.5985)\n",
      "2737 Traning Loss: tensor(3.5980)\n",
      "2738 Traning Loss: tensor(3.5976)\n",
      "2739 Traning Loss: tensor(3.5971)\n",
      "2740 Traning Loss: tensor(3.5967)\n",
      "2741 Traning Loss: tensor(3.5962)\n",
      "2742 Traning Loss: tensor(3.5958)\n",
      "2743 Traning Loss: tensor(3.5953)\n",
      "2744 Traning Loss: tensor(3.5949)\n",
      "2745 Traning Loss: tensor(3.5944)\n",
      "2746 Traning Loss: tensor(3.5939)\n",
      "2747 Traning Loss: tensor(3.5935)\n",
      "2748 Traning Loss: tensor(3.5930)\n",
      "2749 Traning Loss: tensor(3.5925)\n",
      "2750 Traning Loss: tensor(3.5920)\n",
      "2751 Traning Loss: tensor(3.5915)\n",
      "2752 Traning Loss: tensor(3.5910)\n",
      "2753 Traning Loss: tensor(3.5906)\n",
      "2754 Traning Loss: tensor(3.5901)\n",
      "2755 Traning Loss: tensor(3.5896)\n",
      "2756 Traning Loss: tensor(3.5890)\n",
      "2757 Traning Loss: tensor(3.5885)\n",
      "2758 Traning Loss: tensor(3.5880)\n",
      "2759 Traning Loss: tensor(3.5875)\n",
      "2760 Traning Loss: tensor(3.5870)\n",
      "2761 Traning Loss: tensor(3.5865)\n",
      "2762 Traning Loss: tensor(3.5859)\n",
      "2763 Traning Loss: tensor(3.5854)\n",
      "2764 Traning Loss: tensor(3.5849)\n",
      "2765 Traning Loss: tensor(3.5843)\n",
      "2766 Traning Loss: tensor(3.5838)\n",
      "2767 Traning Loss: tensor(3.5832)\n",
      "2768 Traning Loss: tensor(3.5827)\n",
      "2769 Traning Loss: tensor(3.5821)\n",
      "2770 Traning Loss: tensor(3.5815)\n",
      "2771 Traning Loss: tensor(3.5810)\n",
      "2772 Traning Loss: tensor(3.5804)\n",
      "2773 Traning Loss: tensor(3.5798)\n",
      "2774 Traning Loss: tensor(3.5792)\n",
      "2775 Traning Loss: tensor(3.5786)\n",
      "2776 Traning Loss: tensor(3.5781)\n",
      "2777 Traning Loss: tensor(3.5775)\n",
      "2778 Traning Loss: tensor(3.5769)\n",
      "2779 Traning Loss: tensor(3.5763)\n",
      "2780 Traning Loss: tensor(3.5757)\n",
      "2781 Traning Loss: tensor(3.5750)\n",
      "2782 Traning Loss: tensor(3.5744)\n",
      "2783 Traning Loss: tensor(3.5738)\n",
      "2784 Traning Loss: tensor(3.5732)\n",
      "2785 Traning Loss: tensor(3.5725)\n",
      "2786 Traning Loss: tensor(3.5719)\n",
      "2787 Traning Loss: tensor(3.5713)\n",
      "2788 Traning Loss: tensor(3.5706)\n",
      "2789 Traning Loss: tensor(3.5700)\n",
      "2790 Traning Loss: tensor(3.5693)\n",
      "2791 Traning Loss: tensor(3.5686)\n",
      "2792 Traning Loss: tensor(3.5680)\n",
      "2793 Traning Loss: tensor(3.5673)\n",
      "2794 Traning Loss: tensor(3.5666)\n",
      "2795 Traning Loss: tensor(3.5659)\n",
      "2796 Traning Loss: tensor(3.5652)\n",
      "2797 Traning Loss: tensor(3.5645)\n",
      "2798 Traning Loss: tensor(3.5638)\n",
      "2799 Traning Loss: tensor(3.5631)\n",
      "2800 Traning Loss: tensor(3.5624)\n",
      "2801 Traning Loss: tensor(3.5617)\n",
      "2802 Traning Loss: tensor(3.5610)\n",
      "2803 Traning Loss: tensor(3.5603)\n",
      "2804 Traning Loss: tensor(3.5595)\n",
      "2805 Traning Loss: tensor(3.5588)\n",
      "2806 Traning Loss: tensor(3.5580)\n",
      "2807 Traning Loss: tensor(3.5573)\n",
      "2808 Traning Loss: tensor(3.5565)\n",
      "2809 Traning Loss: tensor(3.5558)\n",
      "2810 Traning Loss: tensor(3.5550)\n",
      "2811 Traning Loss: tensor(3.5542)\n",
      "2812 Traning Loss: tensor(3.5534)\n",
      "2813 Traning Loss: tensor(3.5526)\n",
      "2814 Traning Loss: tensor(3.5519)\n",
      "2815 Traning Loss: tensor(3.5510)\n",
      "2816 Traning Loss: tensor(3.5502)\n",
      "2817 Traning Loss: tensor(3.5494)\n",
      "2818 Traning Loss: tensor(3.5486)\n",
      "2819 Traning Loss: tensor(3.5478)\n",
      "2820 Traning Loss: tensor(3.5470)\n",
      "2821 Traning Loss: tensor(3.5461)\n",
      "2822 Traning Loss: tensor(3.5453)\n",
      "2823 Traning Loss: tensor(3.5444)\n",
      "2824 Traning Loss: tensor(3.5436)\n",
      "2825 Traning Loss: tensor(3.5427)\n",
      "2826 Traning Loss: tensor(3.5418)\n",
      "2827 Traning Loss: tensor(3.5409)\n",
      "2828 Traning Loss: tensor(3.5401)\n",
      "2829 Traning Loss: tensor(3.5392)\n",
      "2830 Traning Loss: tensor(3.5383)\n",
      "2831 Traning Loss: tensor(3.5373)\n",
      "2832 Traning Loss: tensor(3.5364)\n",
      "2833 Traning Loss: tensor(3.5355)\n",
      "2834 Traning Loss: tensor(3.5346)\n",
      "2835 Traning Loss: tensor(3.5336)\n",
      "2836 Traning Loss: tensor(3.5327)\n",
      "2837 Traning Loss: tensor(3.5317)\n",
      "2838 Traning Loss: tensor(3.5308)\n",
      "2839 Traning Loss: tensor(3.5298)\n",
      "2840 Traning Loss: tensor(3.5288)\n",
      "2841 Traning Loss: tensor(3.5279)\n",
      "2842 Traning Loss: tensor(3.5269)\n",
      "2843 Traning Loss: tensor(3.5259)\n",
      "2844 Traning Loss: tensor(3.5249)\n",
      "2845 Traning Loss: tensor(3.5238)\n",
      "2846 Traning Loss: tensor(3.5228)\n",
      "2847 Traning Loss: tensor(3.5218)\n",
      "2848 Traning Loss: tensor(3.5207)\n",
      "2849 Traning Loss: tensor(3.5197)\n",
      "2850 Traning Loss: tensor(3.5186)\n",
      "2851 Traning Loss: tensor(3.5176)\n",
      "2852 Traning Loss: tensor(3.5165)\n",
      "2853 Traning Loss: tensor(3.5154)\n",
      "2854 Traning Loss: tensor(3.5143)\n",
      "2855 Traning Loss: tensor(3.5132)\n",
      "2856 Traning Loss: tensor(3.5121)\n",
      "2857 Traning Loss: tensor(3.5110)\n",
      "2858 Traning Loss: tensor(3.5099)\n",
      "2859 Traning Loss: tensor(3.5087)\n",
      "2860 Traning Loss: tensor(3.5076)\n",
      "2861 Traning Loss: tensor(3.5064)\n",
      "2862 Traning Loss: tensor(3.5053)\n",
      "2863 Traning Loss: tensor(3.5041)\n",
      "2864 Traning Loss: tensor(3.5029)\n",
      "2865 Traning Loss: tensor(3.5017)\n",
      "2866 Traning Loss: tensor(3.5005)\n",
      "2867 Traning Loss: tensor(3.4993)\n",
      "2868 Traning Loss: tensor(3.4981)\n",
      "2869 Traning Loss: tensor(3.4968)\n",
      "2870 Traning Loss: tensor(3.4956)\n",
      "2871 Traning Loss: tensor(3.4943)\n",
      "2872 Traning Loss: tensor(3.4931)\n",
      "2873 Traning Loss: tensor(3.4918)\n",
      "2874 Traning Loss: tensor(3.4905)\n",
      "2875 Traning Loss: tensor(3.4892)\n",
      "2876 Traning Loss: tensor(3.4879)\n",
      "2877 Traning Loss: tensor(3.4866)\n",
      "2878 Traning Loss: tensor(3.4853)\n",
      "2879 Traning Loss: tensor(3.4839)\n",
      "2880 Traning Loss: tensor(3.4826)\n",
      "2881 Traning Loss: tensor(3.4812)\n",
      "2882 Traning Loss: tensor(3.4798)\n",
      "2883 Traning Loss: tensor(3.4784)\n",
      "2884 Traning Loss: tensor(3.4770)\n",
      "2885 Traning Loss: tensor(3.4756)\n",
      "2886 Traning Loss: tensor(3.4742)\n",
      "2887 Traning Loss: tensor(3.4728)\n",
      "2888 Traning Loss: tensor(3.4713)\n",
      "2889 Traning Loss: tensor(3.4698)\n",
      "2890 Traning Loss: tensor(3.4684)\n",
      "2891 Traning Loss: tensor(3.4669)\n",
      "2892 Traning Loss: tensor(3.4654)\n",
      "2893 Traning Loss: tensor(3.4639)\n",
      "2894 Traning Loss: tensor(3.4623)\n",
      "2895 Traning Loss: tensor(3.4608)\n",
      "2896 Traning Loss: tensor(3.4593)\n",
      "2897 Traning Loss: tensor(3.4577)\n",
      "2898 Traning Loss: tensor(3.4561)\n",
      "2899 Traning Loss: tensor(3.4545)\n",
      "2900 Traning Loss: tensor(3.4529)\n",
      "2901 Traning Loss: tensor(3.4513)\n",
      "2902 Traning Loss: tensor(3.4496)\n",
      "2903 Traning Loss: tensor(3.4480)\n",
      "2904 Traning Loss: tensor(3.4463)\n",
      "2905 Traning Loss: tensor(3.4446)\n",
      "2906 Traning Loss: tensor(3.4429)\n",
      "2907 Traning Loss: tensor(3.4412)\n",
      "2908 Traning Loss: tensor(3.4395)\n",
      "2909 Traning Loss: tensor(3.4378)\n",
      "2910 Traning Loss: tensor(3.4360)\n",
      "2911 Traning Loss: tensor(3.4342)\n",
      "2912 Traning Loss: tensor(3.4324)\n",
      "2913 Traning Loss: tensor(3.4306)\n",
      "2914 Traning Loss: tensor(3.4288)\n",
      "2915 Traning Loss: tensor(3.4269)\n",
      "2916 Traning Loss: tensor(3.4251)\n",
      "2917 Traning Loss: tensor(3.4232)\n",
      "2918 Traning Loss: tensor(3.4213)\n",
      "2919 Traning Loss: tensor(3.4194)\n",
      "2920 Traning Loss: tensor(3.4175)\n",
      "2921 Traning Loss: tensor(3.4155)\n",
      "2922 Traning Loss: tensor(3.4135)\n",
      "2923 Traning Loss: tensor(3.4115)\n",
      "2924 Traning Loss: tensor(3.4095)\n",
      "2925 Traning Loss: tensor(3.4075)\n",
      "2926 Traning Loss: tensor(3.4055)\n",
      "2927 Traning Loss: tensor(3.4034)\n",
      "2928 Traning Loss: tensor(3.4013)\n",
      "2929 Traning Loss: tensor(3.3992)\n",
      "2930 Traning Loss: tensor(3.3971)\n",
      "2931 Traning Loss: tensor(3.3949)\n",
      "2932 Traning Loss: tensor(3.3927)\n",
      "2933 Traning Loss: tensor(3.3905)\n",
      "2934 Traning Loss: tensor(3.3883)\n",
      "2935 Traning Loss: tensor(3.3861)\n",
      "2936 Traning Loss: tensor(3.3838)\n",
      "2937 Traning Loss: tensor(3.3815)\n",
      "2938 Traning Loss: tensor(3.3792)\n",
      "2939 Traning Loss: tensor(3.3769)\n",
      "2940 Traning Loss: tensor(3.3745)\n",
      "2941 Traning Loss: tensor(3.3721)\n",
      "2942 Traning Loss: tensor(3.3697)\n",
      "2943 Traning Loss: tensor(3.3673)\n",
      "2944 Traning Loss: tensor(3.3648)\n",
      "2945 Traning Loss: tensor(3.3623)\n",
      "2946 Traning Loss: tensor(3.3598)\n",
      "2947 Traning Loss: tensor(3.3572)\n",
      "2948 Traning Loss: tensor(3.3547)\n",
      "2949 Traning Loss: tensor(3.3521)\n",
      "2950 Traning Loss: tensor(3.3494)\n",
      "2951 Traning Loss: tensor(3.3468)\n",
      "2952 Traning Loss: tensor(3.3441)\n",
      "2953 Traning Loss: tensor(3.3414)\n",
      "2954 Traning Loss: tensor(3.3386)\n",
      "2955 Traning Loss: tensor(3.3359)\n",
      "2956 Traning Loss: tensor(3.3330)\n",
      "2957 Traning Loss: tensor(3.3302)\n",
      "2958 Traning Loss: tensor(3.3273)\n",
      "2959 Traning Loss: tensor(3.3244)\n",
      "2960 Traning Loss: tensor(3.3215)\n",
      "2961 Traning Loss: tensor(3.3185)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2962 Traning Loss: tensor(3.3155)\n",
      "2963 Traning Loss: tensor(3.3124)\n",
      "2964 Traning Loss: tensor(3.3094)\n",
      "2965 Traning Loss: tensor(3.3062)\n",
      "2966 Traning Loss: tensor(3.3031)\n",
      "2967 Traning Loss: tensor(3.2999)\n",
      "2968 Traning Loss: tensor(3.2967)\n",
      "2969 Traning Loss: tensor(3.2934)\n",
      "2970 Traning Loss: tensor(3.2901)\n",
      "2971 Traning Loss: tensor(3.2867)\n",
      "2972 Traning Loss: tensor(3.2833)\n",
      "2973 Traning Loss: tensor(3.2799)\n",
      "2974 Traning Loss: tensor(3.2764)\n",
      "2975 Traning Loss: tensor(3.2729)\n",
      "2976 Traning Loss: tensor(3.2694)\n",
      "2977 Traning Loss: tensor(3.2658)\n",
      "2978 Traning Loss: tensor(3.2621)\n",
      "2979 Traning Loss: tensor(3.2584)\n",
      "2980 Traning Loss: tensor(3.2547)\n",
      "2981 Traning Loss: tensor(3.2509)\n",
      "2982 Traning Loss: tensor(3.2471)\n",
      "2983 Traning Loss: tensor(3.2432)\n",
      "2984 Traning Loss: tensor(3.2393)\n",
      "2985 Traning Loss: tensor(3.2353)\n",
      "2986 Traning Loss: tensor(3.2313)\n",
      "2987 Traning Loss: tensor(3.2273)\n",
      "2988 Traning Loss: tensor(3.2231)\n",
      "2989 Traning Loss: tensor(3.2190)\n",
      "2990 Traning Loss: tensor(3.2147)\n",
      "2991 Traning Loss: tensor(3.2105)\n",
      "2992 Traning Loss: tensor(3.2061)\n",
      "2993 Traning Loss: tensor(3.2017)\n",
      "2994 Traning Loss: tensor(3.1973)\n",
      "2995 Traning Loss: tensor(3.1928)\n",
      "2996 Traning Loss: tensor(3.1883)\n",
      "2997 Traning Loss: tensor(3.1836)\n",
      "2998 Traning Loss: tensor(3.1790)\n",
      "2999 Traning Loss: tensor(3.1742)\n",
      "3000 Traning Loss: tensor(3.1695)\n",
      "3001 Traning Loss: tensor(3.1646)\n",
      "3002 Traning Loss: tensor(3.1597)\n",
      "3003 Traning Loss: tensor(3.1547)\n",
      "3004 Traning Loss: tensor(3.1497)\n",
      "3005 Traning Loss: tensor(3.1446)\n",
      "3006 Traning Loss: tensor(3.1394)\n",
      "3007 Traning Loss: tensor(3.1342)\n",
      "3008 Traning Loss: tensor(3.1289)\n",
      "3009 Traning Loss: tensor(3.1236)\n",
      "3010 Traning Loss: tensor(3.1182)\n",
      "3011 Traning Loss: tensor(3.1127)\n",
      "3012 Traning Loss: tensor(3.1071)\n",
      "3013 Traning Loss: tensor(3.1015)\n",
      "3014 Traning Loss: tensor(3.0958)\n",
      "3015 Traning Loss: tensor(3.0900)\n",
      "3016 Traning Loss: tensor(3.0842)\n",
      "3017 Traning Loss: tensor(3.0783)\n",
      "3018 Traning Loss: tensor(3.0723)\n",
      "3019 Traning Loss: tensor(3.0662)\n",
      "3020 Traning Loss: tensor(3.0601)\n",
      "3021 Traning Loss: tensor(3.0539)\n",
      "3022 Traning Loss: tensor(3.0476)\n",
      "3023 Traning Loss: tensor(3.0412)\n",
      "3024 Traning Loss: tensor(3.0348)\n",
      "3025 Traning Loss: tensor(3.0283)\n",
      "3026 Traning Loss: tensor(3.0217)\n",
      "3027 Traning Loss: tensor(3.0150)\n",
      "3028 Traning Loss: tensor(3.0083)\n",
      "3029 Traning Loss: tensor(3.0015)\n",
      "3030 Traning Loss: tensor(2.9946)\n",
      "3031 Traning Loss: tensor(2.9876)\n",
      "3032 Traning Loss: tensor(2.9805)\n",
      "3033 Traning Loss: tensor(2.9734)\n",
      "3034 Traning Loss: tensor(2.9662)\n",
      "3035 Traning Loss: tensor(2.9589)\n",
      "3036 Traning Loss: tensor(2.9515)\n",
      "3037 Traning Loss: tensor(2.9441)\n",
      "3038 Traning Loss: tensor(2.9365)\n",
      "3039 Traning Loss: tensor(2.9289)\n",
      "3040 Traning Loss: tensor(2.9212)\n",
      "3041 Traning Loss: tensor(2.9134)\n",
      "3042 Traning Loss: tensor(2.9056)\n",
      "3043 Traning Loss: tensor(2.8976)\n",
      "3044 Traning Loss: tensor(2.8896)\n",
      "3045 Traning Loss: tensor(2.8815)\n",
      "3046 Traning Loss: tensor(2.8733)\n",
      "3047 Traning Loss: tensor(2.8651)\n",
      "3048 Traning Loss: tensor(2.8567)\n",
      "3049 Traning Loss: tensor(2.8483)\n",
      "3050 Traning Loss: tensor(2.8398)\n",
      "3051 Traning Loss: tensor(2.8313)\n",
      "3052 Traning Loss: tensor(2.8226)\n",
      "3053 Traning Loss: tensor(2.8139)\n",
      "3054 Traning Loss: tensor(2.8051)\n",
      "3055 Traning Loss: tensor(2.7963)\n",
      "3056 Traning Loss: tensor(2.7873)\n",
      "3057 Traning Loss: tensor(2.7783)\n",
      "3058 Traning Loss: tensor(2.7693)\n",
      "3059 Traning Loss: tensor(2.7601)\n",
      "3060 Traning Loss: tensor(2.7509)\n",
      "3061 Traning Loss: tensor(2.7417)\n",
      "3062 Traning Loss: tensor(2.7323)\n",
      "3063 Traning Loss: tensor(2.7229)\n",
      "3064 Traning Loss: tensor(2.7135)\n",
      "3065 Traning Loss: tensor(2.7040)\n",
      "3066 Traning Loss: tensor(2.6944)\n",
      "3067 Traning Loss: tensor(2.6848)\n",
      "3068 Traning Loss: tensor(2.6751)\n",
      "3069 Traning Loss: tensor(2.6654)\n",
      "3070 Traning Loss: tensor(2.6556)\n",
      "3071 Traning Loss: tensor(2.6458)\n",
      "3072 Traning Loss: tensor(2.6359)\n",
      "3073 Traning Loss: tensor(2.6260)\n",
      "3074 Traning Loss: tensor(2.6161)\n",
      "3075 Traning Loss: tensor(2.6061)\n",
      "3076 Traning Loss: tensor(2.5961)\n",
      "3077 Traning Loss: tensor(2.5860)\n",
      "3078 Traning Loss: tensor(2.5760)\n",
      "3079 Traning Loss: tensor(2.5659)\n",
      "3080 Traning Loss: tensor(2.5558)\n",
      "3081 Traning Loss: tensor(2.5456)\n",
      "3082 Traning Loss: tensor(2.5355)\n",
      "3083 Traning Loss: tensor(2.5253)\n",
      "3084 Traning Loss: tensor(2.5151)\n",
      "3085 Traning Loss: tensor(2.5050)\n",
      "3086 Traning Loss: tensor(2.4948)\n",
      "3087 Traning Loss: tensor(2.4846)\n",
      "3088 Traning Loss: tensor(2.4744)\n",
      "3089 Traning Loss: tensor(2.4643)\n",
      "3090 Traning Loss: tensor(2.4541)\n",
      "3091 Traning Loss: tensor(2.4439)\n",
      "3092 Traning Loss: tensor(2.4338)\n",
      "3093 Traning Loss: tensor(2.4237)\n",
      "3094 Traning Loss: tensor(2.4136)\n",
      "3095 Traning Loss: tensor(2.4035)\n",
      "3096 Traning Loss: tensor(2.3935)\n",
      "3097 Traning Loss: tensor(2.3834)\n",
      "3098 Traning Loss: tensor(2.3735)\n",
      "3099 Traning Loss: tensor(2.3635)\n",
      "3100 Traning Loss: tensor(2.3536)\n",
      "3101 Traning Loss: tensor(2.3437)\n",
      "3102 Traning Loss: tensor(2.3339)\n",
      "3103 Traning Loss: tensor(2.3241)\n",
      "3104 Traning Loss: tensor(2.3144)\n",
      "3105 Traning Loss: tensor(2.3047)\n",
      "3106 Traning Loss: tensor(2.2951)\n",
      "3107 Traning Loss: tensor(2.2855)\n",
      "3108 Traning Loss: tensor(2.2759)\n",
      "3109 Traning Loss: tensor(2.2665)\n",
      "3110 Traning Loss: tensor(2.2571)\n",
      "3111 Traning Loss: tensor(2.2477)\n",
      "3112 Traning Loss: tensor(2.2384)\n",
      "3113 Traning Loss: tensor(2.2292)\n",
      "3114 Traning Loss: tensor(2.2201)\n",
      "3115 Traning Loss: tensor(2.2110)\n",
      "3116 Traning Loss: tensor(2.2019)\n",
      "3117 Traning Loss: tensor(2.1930)\n",
      "3118 Traning Loss: tensor(2.1841)\n",
      "3119 Traning Loss: tensor(2.1753)\n",
      "3120 Traning Loss: tensor(2.1666)\n",
      "3121 Traning Loss: tensor(2.1579)\n",
      "3122 Traning Loss: tensor(2.1493)\n",
      "3123 Traning Loss: tensor(2.1408)\n",
      "3124 Traning Loss: tensor(2.1323)\n",
      "3125 Traning Loss: tensor(2.1240)\n",
      "3126 Traning Loss: tensor(2.1157)\n",
      "3127 Traning Loss: tensor(2.1075)\n",
      "3128 Traning Loss: tensor(2.0993)\n",
      "3129 Traning Loss: tensor(2.0913)\n",
      "3130 Traning Loss: tensor(2.0833)\n",
      "3131 Traning Loss: tensor(2.0754)\n",
      "3132 Traning Loss: tensor(2.0676)\n",
      "3133 Traning Loss: tensor(2.0598)\n",
      "3134 Traning Loss: tensor(2.0521)\n",
      "3135 Traning Loss: tensor(2.0446)\n",
      "3136 Traning Loss: tensor(2.0371)\n",
      "3137 Traning Loss: tensor(2.0296)\n",
      "3138 Traning Loss: tensor(2.0223)\n",
      "3139 Traning Loss: tensor(2.0150)\n",
      "3140 Traning Loss: tensor(2.0079)\n",
      "3141 Traning Loss: tensor(2.0008)\n",
      "3142 Traning Loss: tensor(1.9937)\n",
      "3143 Traning Loss: tensor(1.9868)\n",
      "3144 Traning Loss: tensor(1.9800)\n",
      "3145 Traning Loss: tensor(1.9732)\n",
      "3146 Traning Loss: tensor(1.9665)\n",
      "3147 Traning Loss: tensor(1.9599)\n",
      "3148 Traning Loss: tensor(1.9534)\n",
      "3149 Traning Loss: tensor(1.9470)\n",
      "3150 Traning Loss: tensor(1.9407)\n",
      "3151 Traning Loss: tensor(1.9344)\n",
      "3152 Traning Loss: tensor(1.9282)\n",
      "3153 Traning Loss: tensor(1.9221)\n",
      "3154 Traning Loss: tensor(1.9162)\n",
      "3155 Traning Loss: tensor(1.9102)\n",
      "3156 Traning Loss: tensor(1.9044)\n",
      "3157 Traning Loss: tensor(1.8987)\n",
      "3158 Traning Loss: tensor(1.8930)\n",
      "3159 Traning Loss: tensor(1.8875)\n",
      "3160 Traning Loss: tensor(1.8820)\n",
      "3161 Traning Loss: tensor(1.8766)\n",
      "3162 Traning Loss: tensor(1.8713)\n",
      "3163 Traning Loss: tensor(1.8661)\n",
      "3164 Traning Loss: tensor(1.8610)\n",
      "3165 Traning Loss: tensor(1.8559)\n",
      "3166 Traning Loss: tensor(1.8510)\n",
      "3167 Traning Loss: tensor(1.8461)\n",
      "3168 Traning Loss: tensor(1.8413)\n",
      "3169 Traning Loss: tensor(1.8366)\n",
      "3170 Traning Loss: tensor(1.8320)\n",
      "3171 Traning Loss: tensor(1.8275)\n",
      "3172 Traning Loss: tensor(1.8231)\n",
      "3173 Traning Loss: tensor(1.8187)\n",
      "3174 Traning Loss: tensor(1.8145)\n",
      "3175 Traning Loss: tensor(1.8103)\n",
      "3176 Traning Loss: tensor(1.8062)\n",
      "3177 Traning Loss: tensor(1.8022)\n",
      "3178 Traning Loss: tensor(1.7982)\n",
      "3179 Traning Loss: tensor(1.7944)\n",
      "3180 Traning Loss: tensor(1.7906)\n",
      "3181 Traning Loss: tensor(1.7869)\n",
      "3182 Traning Loss: tensor(1.7833)\n",
      "3183 Traning Loss: tensor(1.7798)\n",
      "3184 Traning Loss: tensor(1.7764)\n",
      "3185 Traning Loss: tensor(1.7730)\n",
      "3186 Traning Loss: tensor(1.7697)\n",
      "3187 Traning Loss: tensor(1.7665)\n",
      "3188 Traning Loss: tensor(1.7633)\n",
      "3189 Traning Loss: tensor(1.7603)\n",
      "3190 Traning Loss: tensor(1.7573)\n",
      "3191 Traning Loss: tensor(1.7543)\n",
      "3192 Traning Loss: tensor(1.7515)\n",
      "3193 Traning Loss: tensor(1.7487)\n",
      "3194 Traning Loss: tensor(1.7459)\n",
      "3195 Traning Loss: tensor(1.7433)\n",
      "3196 Traning Loss: tensor(1.7407)\n",
      "3197 Traning Loss: tensor(1.7381)\n",
      "3198 Traning Loss: tensor(1.7357)\n",
      "3199 Traning Loss: tensor(1.7333)\n",
      "3200 Traning Loss: tensor(1.7309)\n",
      "3201 Traning Loss: tensor(1.7286)\n",
      "3202 Traning Loss: tensor(1.7263)\n",
      "3203 Traning Loss: tensor(1.7242)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3204 Traning Loss: tensor(1.7220)\n",
      "3205 Traning Loss: tensor(1.7199)\n",
      "3206 Traning Loss: tensor(1.7179)\n",
      "3207 Traning Loss: tensor(1.7159)\n",
      "3208 Traning Loss: tensor(1.7140)\n",
      "3209 Traning Loss: tensor(1.7121)\n",
      "3210 Traning Loss: tensor(1.7102)\n",
      "3211 Traning Loss: tensor(1.7084)\n",
      "3212 Traning Loss: tensor(1.7066)\n",
      "3213 Traning Loss: tensor(1.7049)\n",
      "3214 Traning Loss: tensor(1.7032)\n",
      "3215 Traning Loss: tensor(1.7015)\n",
      "3216 Traning Loss: tensor(1.6999)\n",
      "3217 Traning Loss: tensor(1.6983)\n",
      "3218 Traning Loss: tensor(1.6968)\n",
      "3219 Traning Loss: tensor(1.6952)\n",
      "3220 Traning Loss: tensor(1.6937)\n",
      "3221 Traning Loss: tensor(1.6923)\n",
      "3222 Traning Loss: tensor(1.6908)\n",
      "3223 Traning Loss: tensor(1.6894)\n",
      "3224 Traning Loss: tensor(1.6880)\n",
      "3225 Traning Loss: tensor(1.6866)\n",
      "3226 Traning Loss: tensor(1.6853)\n",
      "3227 Traning Loss: tensor(1.6840)\n",
      "3228 Traning Loss: tensor(1.6826)\n",
      "3229 Traning Loss: tensor(1.6814)\n",
      "3230 Traning Loss: tensor(1.6801)\n",
      "3231 Traning Loss: tensor(1.6788)\n",
      "3232 Traning Loss: tensor(1.6776)\n",
      "3233 Traning Loss: tensor(1.6764)\n",
      "3234 Traning Loss: tensor(1.6752)\n",
      "3235 Traning Loss: tensor(1.6740)\n",
      "3236 Traning Loss: tensor(1.6728)\n",
      "3237 Traning Loss: tensor(1.6716)\n",
      "3238 Traning Loss: tensor(1.6704)\n",
      "3239 Traning Loss: tensor(1.6693)\n",
      "3240 Traning Loss: tensor(1.6682)\n",
      "3241 Traning Loss: tensor(1.6670)\n",
      "3242 Traning Loss: tensor(1.6659)\n",
      "3243 Traning Loss: tensor(1.6648)\n",
      "3244 Traning Loss: tensor(1.6637)\n",
      "3245 Traning Loss: tensor(1.6626)\n",
      "3246 Traning Loss: tensor(1.6615)\n",
      "3247 Traning Loss: tensor(1.6604)\n",
      "3248 Traning Loss: tensor(1.6593)\n",
      "3249 Traning Loss: tensor(1.6582)\n",
      "3250 Traning Loss: tensor(1.6571)\n",
      "3251 Traning Loss: tensor(1.6560)\n",
      "3252 Traning Loss: tensor(1.6549)\n",
      "3253 Traning Loss: tensor(1.6539)\n",
      "3254 Traning Loss: tensor(1.6528)\n",
      "3255 Traning Loss: tensor(1.6517)\n",
      "3256 Traning Loss: tensor(1.6506)\n",
      "3257 Traning Loss: tensor(1.6496)\n",
      "3258 Traning Loss: tensor(1.6485)\n",
      "3259 Traning Loss: tensor(1.6474)\n",
      "3260 Traning Loss: tensor(1.6463)\n",
      "3261 Traning Loss: tensor(1.6453)\n",
      "3262 Traning Loss: tensor(1.6442)\n",
      "3263 Traning Loss: tensor(1.6431)\n",
      "3264 Traning Loss: tensor(1.6420)\n",
      "3265 Traning Loss: tensor(1.6410)\n",
      "3266 Traning Loss: tensor(1.6399)\n",
      "3267 Traning Loss: tensor(1.6388)\n",
      "3268 Traning Loss: tensor(1.6377)\n",
      "3269 Traning Loss: tensor(1.6366)\n",
      "3270 Traning Loss: tensor(1.6355)\n",
      "3271 Traning Loss: tensor(1.6345)\n",
      "3272 Traning Loss: tensor(1.6334)\n",
      "3273 Traning Loss: tensor(1.6323)\n",
      "3274 Traning Loss: tensor(1.6312)\n",
      "3275 Traning Loss: tensor(1.6301)\n",
      "3276 Traning Loss: tensor(1.6289)\n",
      "3277 Traning Loss: tensor(1.6278)\n",
      "3278 Traning Loss: tensor(1.6267)\n",
      "3279 Traning Loss: tensor(1.6256)\n",
      "3280 Traning Loss: tensor(1.6245)\n",
      "3281 Traning Loss: tensor(1.6233)\n",
      "3282 Traning Loss: tensor(1.6222)\n",
      "3283 Traning Loss: tensor(1.6211)\n",
      "3284 Traning Loss: tensor(1.6199)\n",
      "3285 Traning Loss: tensor(1.6188)\n",
      "3286 Traning Loss: tensor(1.6176)\n",
      "3287 Traning Loss: tensor(1.6164)\n",
      "3288 Traning Loss: tensor(1.6153)\n",
      "3289 Traning Loss: tensor(1.6141)\n",
      "3290 Traning Loss: tensor(1.6129)\n",
      "3291 Traning Loss: tensor(1.6117)\n",
      "3292 Traning Loss: tensor(1.6105)\n",
      "3293 Traning Loss: tensor(1.6093)\n",
      "3294 Traning Loss: tensor(1.6081)\n",
      "3295 Traning Loss: tensor(1.6069)\n",
      "3296 Traning Loss: tensor(1.6057)\n",
      "3297 Traning Loss: tensor(1.6045)\n",
      "3298 Traning Loss: tensor(1.6032)\n",
      "3299 Traning Loss: tensor(1.6020)\n",
      "3300 Traning Loss: tensor(1.6007)\n",
      "3301 Traning Loss: tensor(1.5995)\n",
      "3302 Traning Loss: tensor(1.5982)\n",
      "3303 Traning Loss: tensor(1.5969)\n",
      "3304 Traning Loss: tensor(1.5957)\n",
      "3305 Traning Loss: tensor(1.5944)\n",
      "3306 Traning Loss: tensor(1.5931)\n",
      "3307 Traning Loss: tensor(1.5918)\n",
      "3308 Traning Loss: tensor(1.5905)\n",
      "3309 Traning Loss: tensor(1.5891)\n",
      "3310 Traning Loss: tensor(1.5878)\n",
      "3311 Traning Loss: tensor(1.5865)\n",
      "3312 Traning Loss: tensor(1.5851)\n",
      "3313 Traning Loss: tensor(1.5838)\n",
      "3314 Traning Loss: tensor(1.5824)\n",
      "3315 Traning Loss: tensor(1.5810)\n",
      "3316 Traning Loss: tensor(1.5797)\n",
      "3317 Traning Loss: tensor(1.5783)\n",
      "3318 Traning Loss: tensor(1.5769)\n",
      "3319 Traning Loss: tensor(1.5755)\n",
      "3320 Traning Loss: tensor(1.5740)\n",
      "3321 Traning Loss: tensor(1.5726)\n",
      "3322 Traning Loss: tensor(1.5712)\n",
      "3323 Traning Loss: tensor(1.5697)\n",
      "3324 Traning Loss: tensor(1.5683)\n",
      "3325 Traning Loss: tensor(1.5668)\n",
      "3326 Traning Loss: tensor(1.5653)\n",
      "3327 Traning Loss: tensor(1.5638)\n",
      "3328 Traning Loss: tensor(1.5623)\n",
      "3329 Traning Loss: tensor(1.5608)\n",
      "3330 Traning Loss: tensor(1.5593)\n",
      "3331 Traning Loss: tensor(1.5578)\n",
      "3332 Traning Loss: tensor(1.5563)\n",
      "3333 Traning Loss: tensor(1.5547)\n",
      "3334 Traning Loss: tensor(1.5532)\n",
      "3335 Traning Loss: tensor(1.5516)\n",
      "3336 Traning Loss: tensor(1.5500)\n",
      "3337 Traning Loss: tensor(1.5485)\n",
      "3338 Traning Loss: tensor(1.5469)\n",
      "3339 Traning Loss: tensor(1.5453)\n",
      "3340 Traning Loss: tensor(1.5437)\n",
      "3341 Traning Loss: tensor(1.5420)\n",
      "3342 Traning Loss: tensor(1.5404)\n",
      "3343 Traning Loss: tensor(1.5388)\n",
      "3344 Traning Loss: tensor(1.5371)\n",
      "3345 Traning Loss: tensor(1.5355)\n",
      "3346 Traning Loss: tensor(1.5338)\n",
      "3347 Traning Loss: tensor(1.5321)\n",
      "3348 Traning Loss: tensor(1.5304)\n",
      "3349 Traning Loss: tensor(1.5287)\n",
      "3350 Traning Loss: tensor(1.5270)\n",
      "3351 Traning Loss: tensor(1.5253)\n",
      "3352 Traning Loss: tensor(1.5236)\n",
      "3353 Traning Loss: tensor(1.5219)\n",
      "3354 Traning Loss: tensor(1.5201)\n",
      "3355 Traning Loss: tensor(1.5184)\n",
      "3356 Traning Loss: tensor(1.5166)\n",
      "3357 Traning Loss: tensor(1.5149)\n",
      "3358 Traning Loss: tensor(1.5131)\n",
      "3359 Traning Loss: tensor(1.5113)\n",
      "3360 Traning Loss: tensor(1.5096)\n",
      "3361 Traning Loss: tensor(1.5078)\n",
      "3362 Traning Loss: tensor(1.5060)\n",
      "3363 Traning Loss: tensor(1.5042)\n",
      "3364 Traning Loss: tensor(1.5024)\n",
      "3365 Traning Loss: tensor(1.5006)\n",
      "3366 Traning Loss: tensor(1.4988)\n",
      "3367 Traning Loss: tensor(1.4969)\n",
      "3368 Traning Loss: tensor(1.4951)\n",
      "3369 Traning Loss: tensor(1.4933)\n",
      "3370 Traning Loss: tensor(1.4915)\n",
      "3371 Traning Loss: tensor(1.4896)\n",
      "3372 Traning Loss: tensor(1.4878)\n",
      "3373 Traning Loss: tensor(1.4859)\n",
      "3374 Traning Loss: tensor(1.4841)\n",
      "3375 Traning Loss: tensor(1.4823)\n",
      "3376 Traning Loss: tensor(1.4804)\n",
      "3377 Traning Loss: tensor(1.4786)\n",
      "3378 Traning Loss: tensor(1.4767)\n",
      "3379 Traning Loss: tensor(1.4749)\n",
      "3380 Traning Loss: tensor(1.4730)\n",
      "3381 Traning Loss: tensor(1.4712)\n",
      "3382 Traning Loss: tensor(1.4693)\n",
      "3383 Traning Loss: tensor(1.4675)\n",
      "3384 Traning Loss: tensor(1.4656)\n",
      "3385 Traning Loss: tensor(1.4638)\n",
      "3386 Traning Loss: tensor(1.4619)\n",
      "3387 Traning Loss: tensor(1.4601)\n",
      "3388 Traning Loss: tensor(1.4583)\n",
      "3389 Traning Loss: tensor(1.4564)\n",
      "3390 Traning Loss: tensor(1.4546)\n",
      "3391 Traning Loss: tensor(1.4528)\n",
      "3392 Traning Loss: tensor(1.4510)\n",
      "3393 Traning Loss: tensor(1.4492)\n",
      "3394 Traning Loss: tensor(1.4474)\n",
      "3395 Traning Loss: tensor(1.4456)\n",
      "3396 Traning Loss: tensor(1.4438)\n",
      "3397 Traning Loss: tensor(1.4420)\n",
      "3398 Traning Loss: tensor(1.4402)\n",
      "3399 Traning Loss: tensor(1.4384)\n",
      "3400 Traning Loss: tensor(1.4367)\n",
      "3401 Traning Loss: tensor(1.4349)\n",
      "3402 Traning Loss: tensor(1.4332)\n",
      "3403 Traning Loss: tensor(1.4315)\n",
      "3404 Traning Loss: tensor(1.4297)\n",
      "3405 Traning Loss: tensor(1.4280)\n",
      "3406 Traning Loss: tensor(1.4263)\n",
      "3407 Traning Loss: tensor(1.4246)\n",
      "3408 Traning Loss: tensor(1.4229)\n",
      "3409 Traning Loss: tensor(1.4213)\n",
      "3410 Traning Loss: tensor(1.4196)\n",
      "3411 Traning Loss: tensor(1.4180)\n",
      "3412 Traning Loss: tensor(1.4163)\n",
      "3413 Traning Loss: tensor(1.4147)\n",
      "3414 Traning Loss: tensor(1.4131)\n",
      "3415 Traning Loss: tensor(1.4115)\n",
      "3416 Traning Loss: tensor(1.4099)\n",
      "3417 Traning Loss: tensor(1.4083)\n",
      "3418 Traning Loss: tensor(1.4067)\n",
      "3419 Traning Loss: tensor(1.4052)\n",
      "3420 Traning Loss: tensor(1.4036)\n",
      "3421 Traning Loss: tensor(1.4021)\n",
      "3422 Traning Loss: tensor(1.4006)\n",
      "3423 Traning Loss: tensor(1.3990)\n",
      "3424 Traning Loss: tensor(1.3975)\n",
      "3425 Traning Loss: tensor(1.3961)\n",
      "3426 Traning Loss: tensor(1.3946)\n",
      "3427 Traning Loss: tensor(1.3931)\n",
      "3428 Traning Loss: tensor(1.3917)\n",
      "3429 Traning Loss: tensor(1.3902)\n",
      "3430 Traning Loss: tensor(1.3888)\n",
      "3431 Traning Loss: tensor(1.3874)\n",
      "3432 Traning Loss: tensor(1.3860)\n",
      "3433 Traning Loss: tensor(1.3846)\n",
      "3434 Traning Loss: tensor(1.3832)\n",
      "3435 Traning Loss: tensor(1.3818)\n",
      "3436 Traning Loss: tensor(1.3804)\n",
      "3437 Traning Loss: tensor(1.3791)\n",
      "3438 Traning Loss: tensor(1.3777)\n",
      "3439 Traning Loss: tensor(1.3764)\n",
      "3440 Traning Loss: tensor(1.3751)\n",
      "3441 Traning Loss: tensor(1.3738)\n",
      "3442 Traning Loss: tensor(1.3725)\n",
      "3443 Traning Loss: tensor(1.3712)\n",
      "3444 Traning Loss: tensor(1.3699)\n",
      "3445 Traning Loss: tensor(1.3686)\n",
      "3446 Traning Loss: tensor(1.3673)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3447 Traning Loss: tensor(1.3660)\n",
      "3448 Traning Loss: tensor(1.3648)\n",
      "3449 Traning Loss: tensor(1.3635)\n",
      "3450 Traning Loss: tensor(1.3623)\n",
      "3451 Traning Loss: tensor(1.3611)\n",
      "3452 Traning Loss: tensor(1.3598)\n",
      "3453 Traning Loss: tensor(1.3586)\n",
      "3454 Traning Loss: tensor(1.3574)\n",
      "3455 Traning Loss: tensor(1.3562)\n",
      "3456 Traning Loss: tensor(1.3550)\n",
      "3457 Traning Loss: tensor(1.3538)\n",
      "3458 Traning Loss: tensor(1.3526)\n",
      "3459 Traning Loss: tensor(1.3514)\n",
      "3460 Traning Loss: tensor(1.3503)\n",
      "3461 Traning Loss: tensor(1.3491)\n",
      "3462 Traning Loss: tensor(1.3479)\n",
      "3463 Traning Loss: tensor(1.3468)\n",
      "3464 Traning Loss: tensor(1.3456)\n",
      "3465 Traning Loss: tensor(1.3445)\n",
      "3466 Traning Loss: tensor(1.3433)\n",
      "3467 Traning Loss: tensor(1.3422)\n",
      "3468 Traning Loss: tensor(1.3411)\n",
      "3469 Traning Loss: tensor(1.3399)\n",
      "3470 Traning Loss: tensor(1.3388)\n",
      "3471 Traning Loss: tensor(1.3377)\n",
      "3472 Traning Loss: tensor(1.3366)\n",
      "3473 Traning Loss: tensor(1.3355)\n",
      "3474 Traning Loss: tensor(1.3344)\n",
      "3475 Traning Loss: tensor(1.3333)\n",
      "3476 Traning Loss: tensor(1.3322)\n",
      "3477 Traning Loss: tensor(1.3311)\n",
      "3478 Traning Loss: tensor(1.3300)\n",
      "3479 Traning Loss: tensor(1.3289)\n",
      "3480 Traning Loss: tensor(1.3278)\n",
      "3481 Traning Loss: tensor(1.3267)\n",
      "3482 Traning Loss: tensor(1.3256)\n",
      "3483 Traning Loss: tensor(1.3246)\n",
      "3484 Traning Loss: tensor(1.3235)\n",
      "3485 Traning Loss: tensor(1.3224)\n",
      "3486 Traning Loss: tensor(1.3214)\n",
      "3487 Traning Loss: tensor(1.3203)\n",
      "3488 Traning Loss: tensor(1.3193)\n",
      "3489 Traning Loss: tensor(1.3182)\n",
      "3490 Traning Loss: tensor(1.3171)\n",
      "3491 Traning Loss: tensor(1.3161)\n",
      "3492 Traning Loss: tensor(1.3151)\n",
      "3493 Traning Loss: tensor(1.3140)\n",
      "3494 Traning Loss: tensor(1.3130)\n",
      "3495 Traning Loss: tensor(1.3119)\n",
      "3496 Traning Loss: tensor(1.3109)\n",
      "3497 Traning Loss: tensor(1.3099)\n",
      "3498 Traning Loss: tensor(1.3089)\n",
      "3499 Traning Loss: tensor(1.3078)\n",
      "3500 Traning Loss: tensor(1.3068)\n",
      "3501 Traning Loss: tensor(1.3058)\n",
      "3502 Traning Loss: tensor(1.3048)\n",
      "3503 Traning Loss: tensor(1.3038)\n",
      "3504 Traning Loss: tensor(1.3028)\n",
      "3505 Traning Loss: tensor(1.3017)\n",
      "3506 Traning Loss: tensor(1.3007)\n",
      "3507 Traning Loss: tensor(1.2997)\n",
      "3508 Traning Loss: tensor(1.2987)\n",
      "3509 Traning Loss: tensor(1.2977)\n",
      "3510 Traning Loss: tensor(1.2967)\n",
      "3511 Traning Loss: tensor(1.2957)\n",
      "3512 Traning Loss: tensor(1.2948)\n",
      "3513 Traning Loss: tensor(1.2938)\n",
      "3514 Traning Loss: tensor(1.2928)\n",
      "3515 Traning Loss: tensor(1.2918)\n",
      "3516 Traning Loss: tensor(1.2908)\n",
      "3517 Traning Loss: tensor(1.2898)\n",
      "3518 Traning Loss: tensor(1.2888)\n",
      "3519 Traning Loss: tensor(1.2879)\n",
      "3520 Traning Loss: tensor(1.2869)\n",
      "3521 Traning Loss: tensor(1.2859)\n",
      "3522 Traning Loss: tensor(1.2849)\n",
      "3523 Traning Loss: tensor(1.2840)\n",
      "3524 Traning Loss: tensor(1.2830)\n",
      "3525 Traning Loss: tensor(1.2820)\n",
      "3526 Traning Loss: tensor(1.2810)\n",
      "3527 Traning Loss: tensor(1.2801)\n",
      "3528 Traning Loss: tensor(1.2791)\n",
      "3529 Traning Loss: tensor(1.2781)\n",
      "3530 Traning Loss: tensor(1.2772)\n",
      "3531 Traning Loss: tensor(1.2762)\n",
      "3532 Traning Loss: tensor(1.2752)\n",
      "3533 Traning Loss: tensor(1.2743)\n",
      "3534 Traning Loss: tensor(1.2733)\n",
      "3535 Traning Loss: tensor(1.2724)\n",
      "3536 Traning Loss: tensor(1.2714)\n",
      "3537 Traning Loss: tensor(1.2704)\n",
      "3538 Traning Loss: tensor(1.2695)\n",
      "3539 Traning Loss: tensor(1.2685)\n",
      "3540 Traning Loss: tensor(1.2676)\n",
      "3541 Traning Loss: tensor(1.2666)\n",
      "3542 Traning Loss: tensor(1.2656)\n",
      "3543 Traning Loss: tensor(1.2647)\n",
      "3544 Traning Loss: tensor(1.2637)\n",
      "3545 Traning Loss: tensor(1.2628)\n",
      "3546 Traning Loss: tensor(1.2618)\n",
      "3547 Traning Loss: tensor(1.2608)\n",
      "3548 Traning Loss: tensor(1.2599)\n",
      "3549 Traning Loss: tensor(1.2589)\n",
      "3550 Traning Loss: tensor(1.2580)\n",
      "3551 Traning Loss: tensor(1.2570)\n",
      "3552 Traning Loss: tensor(1.2560)\n",
      "3553 Traning Loss: tensor(1.2551)\n",
      "3554 Traning Loss: tensor(1.2541)\n",
      "3555 Traning Loss: tensor(1.2531)\n",
      "3556 Traning Loss: tensor(1.2522)\n",
      "3557 Traning Loss: tensor(1.2512)\n",
      "3558 Traning Loss: tensor(1.2502)\n",
      "3559 Traning Loss: tensor(1.2493)\n",
      "3560 Traning Loss: tensor(1.2483)\n",
      "3561 Traning Loss: tensor(1.2473)\n",
      "3562 Traning Loss: tensor(1.2463)\n",
      "3563 Traning Loss: tensor(1.2454)\n",
      "3564 Traning Loss: tensor(1.2444)\n",
      "3565 Traning Loss: tensor(1.2434)\n",
      "3566 Traning Loss: tensor(1.2424)\n",
      "3567 Traning Loss: tensor(1.2414)\n",
      "3568 Traning Loss: tensor(1.2405)\n",
      "3569 Traning Loss: tensor(1.2395)\n",
      "3570 Traning Loss: tensor(1.2385)\n",
      "3571 Traning Loss: tensor(1.2375)\n",
      "3572 Traning Loss: tensor(1.2365)\n",
      "3573 Traning Loss: tensor(1.2355)\n",
      "3574 Traning Loss: tensor(1.2345)\n",
      "3575 Traning Loss: tensor(1.2335)\n",
      "3576 Traning Loss: tensor(1.2325)\n",
      "3577 Traning Loss: tensor(1.2315)\n",
      "3578 Traning Loss: tensor(1.2305)\n",
      "3579 Traning Loss: tensor(1.2294)\n",
      "3580 Traning Loss: tensor(1.2284)\n",
      "3581 Traning Loss: tensor(1.2274)\n",
      "3582 Traning Loss: tensor(1.2264)\n",
      "3583 Traning Loss: tensor(1.2254)\n",
      "3584 Traning Loss: tensor(1.2243)\n",
      "3585 Traning Loss: tensor(1.2233)\n",
      "3586 Traning Loss: tensor(1.2222)\n",
      "3587 Traning Loss: tensor(1.2212)\n",
      "3588 Traning Loss: tensor(1.2202)\n",
      "3589 Traning Loss: tensor(1.2191)\n",
      "3590 Traning Loss: tensor(1.2181)\n",
      "3591 Traning Loss: tensor(1.2170)\n",
      "3592 Traning Loss: tensor(1.2159)\n",
      "3593 Traning Loss: tensor(1.2149)\n",
      "3594 Traning Loss: tensor(1.2138)\n",
      "3595 Traning Loss: tensor(1.2127)\n",
      "3596 Traning Loss: tensor(1.2116)\n",
      "3597 Traning Loss: tensor(1.2105)\n",
      "3598 Traning Loss: tensor(1.2095)\n",
      "3599 Traning Loss: tensor(1.2084)\n",
      "3600 Traning Loss: tensor(1.2073)\n",
      "3601 Traning Loss: tensor(1.2061)\n",
      "3602 Traning Loss: tensor(1.2050)\n",
      "3603 Traning Loss: tensor(1.2039)\n",
      "3604 Traning Loss: tensor(1.2028)\n",
      "3605 Traning Loss: tensor(1.2017)\n",
      "3606 Traning Loss: tensor(1.2005)\n",
      "3607 Traning Loss: tensor(1.1994)\n",
      "3608 Traning Loss: tensor(1.1983)\n",
      "3609 Traning Loss: tensor(1.1971)\n",
      "3610 Traning Loss: tensor(1.1960)\n",
      "3611 Traning Loss: tensor(1.1948)\n",
      "3612 Traning Loss: tensor(1.1936)\n",
      "3613 Traning Loss: tensor(1.1925)\n",
      "3614 Traning Loss: tensor(1.1913)\n",
      "3615 Traning Loss: tensor(1.1901)\n",
      "3616 Traning Loss: tensor(1.1889)\n",
      "3617 Traning Loss: tensor(1.1877)\n",
      "3618 Traning Loss: tensor(1.1865)\n",
      "3619 Traning Loss: tensor(1.1853)\n",
      "3620 Traning Loss: tensor(1.1841)\n",
      "3621 Traning Loss: tensor(1.1828)\n",
      "3622 Traning Loss: tensor(1.1816)\n",
      "3623 Traning Loss: tensor(1.1804)\n",
      "3624 Traning Loss: tensor(1.1791)\n",
      "3625 Traning Loss: tensor(1.1779)\n",
      "3626 Traning Loss: tensor(1.1766)\n",
      "3627 Traning Loss: tensor(1.1754)\n",
      "3628 Traning Loss: tensor(1.1741)\n",
      "3629 Traning Loss: tensor(1.1728)\n",
      "3630 Traning Loss: tensor(1.1715)\n",
      "3631 Traning Loss: tensor(1.1703)\n",
      "3632 Traning Loss: tensor(1.1690)\n",
      "3633 Traning Loss: tensor(1.1677)\n",
      "3634 Traning Loss: tensor(1.1663)\n",
      "3635 Traning Loss: tensor(1.1650)\n",
      "3636 Traning Loss: tensor(1.1637)\n",
      "3637 Traning Loss: tensor(1.1624)\n",
      "3638 Traning Loss: tensor(1.1610)\n",
      "3639 Traning Loss: tensor(1.1597)\n",
      "3640 Traning Loss: tensor(1.1583)\n",
      "3641 Traning Loss: tensor(1.1570)\n",
      "3642 Traning Loss: tensor(1.1556)\n",
      "3643 Traning Loss: tensor(1.1542)\n",
      "3644 Traning Loss: tensor(1.1529)\n",
      "3645 Traning Loss: tensor(1.1515)\n",
      "3646 Traning Loss: tensor(1.1501)\n",
      "3647 Traning Loss: tensor(1.1487)\n",
      "3648 Traning Loss: tensor(1.1473)\n",
      "3649 Traning Loss: tensor(1.1459)\n",
      "3650 Traning Loss: tensor(1.1444)\n",
      "3651 Traning Loss: tensor(1.1430)\n",
      "3652 Traning Loss: tensor(1.1416)\n",
      "3653 Traning Loss: tensor(1.1401)\n",
      "3654 Traning Loss: tensor(1.1387)\n",
      "3655 Traning Loss: tensor(1.1373)\n",
      "3656 Traning Loss: tensor(1.1358)\n",
      "3657 Traning Loss: tensor(1.1343)\n",
      "3658 Traning Loss: tensor(1.1329)\n",
      "3659 Traning Loss: tensor(1.1314)\n",
      "3660 Traning Loss: tensor(1.1299)\n",
      "3661 Traning Loss: tensor(1.1284)\n",
      "3662 Traning Loss: tensor(1.1269)\n",
      "3663 Traning Loss: tensor(1.1254)\n",
      "3664 Traning Loss: tensor(1.1239)\n",
      "3665 Traning Loss: tensor(1.1224)\n",
      "3666 Traning Loss: tensor(1.1209)\n",
      "3667 Traning Loss: tensor(1.1194)\n",
      "3668 Traning Loss: tensor(1.1179)\n",
      "3669 Traning Loss: tensor(1.1163)\n",
      "3670 Traning Loss: tensor(1.1148)\n",
      "3671 Traning Loss: tensor(1.1133)\n",
      "3672 Traning Loss: tensor(1.1117)\n",
      "3673 Traning Loss: tensor(1.1102)\n",
      "3674 Traning Loss: tensor(1.1086)\n",
      "3675 Traning Loss: tensor(1.1071)\n",
      "3676 Traning Loss: tensor(1.1055)\n",
      "3677 Traning Loss: tensor(1.1039)\n",
      "3678 Traning Loss: tensor(1.1024)\n",
      "3679 Traning Loss: tensor(1.1008)\n",
      "3680 Traning Loss: tensor(1.0992)\n",
      "3681 Traning Loss: tensor(1.0976)\n",
      "3682 Traning Loss: tensor(1.0961)\n",
      "3683 Traning Loss: tensor(1.0945)\n",
      "3684 Traning Loss: tensor(1.0929)\n",
      "3685 Traning Loss: tensor(1.0913)\n",
      "3686 Traning Loss: tensor(1.0897)\n",
      "3687 Traning Loss: tensor(1.0881)\n",
      "3688 Traning Loss: tensor(1.0865)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689 Traning Loss: tensor(1.0849)\n",
      "3690 Traning Loss: tensor(1.0833)\n",
      "3691 Traning Loss: tensor(1.0817)\n",
      "3692 Traning Loss: tensor(1.0801)\n",
      "3693 Traning Loss: tensor(1.0785)\n",
      "3694 Traning Loss: tensor(1.0769)\n",
      "3695 Traning Loss: tensor(1.0753)\n",
      "3696 Traning Loss: tensor(1.0737)\n",
      "3697 Traning Loss: tensor(1.0721)\n",
      "3698 Traning Loss: tensor(1.0705)\n",
      "3699 Traning Loss: tensor(1.0689)\n",
      "3700 Traning Loss: tensor(1.0672)\n",
      "3701 Traning Loss: tensor(1.0656)\n",
      "3702 Traning Loss: tensor(1.0640)\n",
      "3703 Traning Loss: tensor(1.0624)\n",
      "3704 Traning Loss: tensor(1.0608)\n",
      "3705 Traning Loss: tensor(1.0592)\n",
      "3706 Traning Loss: tensor(1.0576)\n",
      "3707 Traning Loss: tensor(1.0559)\n",
      "3708 Traning Loss: tensor(1.0543)\n",
      "3709 Traning Loss: tensor(1.0527)\n",
      "3710 Traning Loss: tensor(1.0511)\n",
      "3711 Traning Loss: tensor(1.0495)\n",
      "3712 Traning Loss: tensor(1.0479)\n",
      "3713 Traning Loss: tensor(1.0463)\n",
      "3714 Traning Loss: tensor(1.0447)\n",
      "3715 Traning Loss: tensor(1.0431)\n",
      "3716 Traning Loss: tensor(1.0415)\n",
      "3717 Traning Loss: tensor(1.0399)\n",
      "3718 Traning Loss: tensor(1.0383)\n",
      "3719 Traning Loss: tensor(1.0367)\n",
      "3720 Traning Loss: tensor(1.0351)\n",
      "3721 Traning Loss: tensor(1.0335)\n",
      "3722 Traning Loss: tensor(1.0319)\n",
      "3723 Traning Loss: tensor(1.0303)\n",
      "3724 Traning Loss: tensor(1.0287)\n",
      "3725 Traning Loss: tensor(1.0271)\n",
      "3726 Traning Loss: tensor(1.0255)\n",
      "3727 Traning Loss: tensor(1.0239)\n",
      "3728 Traning Loss: tensor(1.0224)\n",
      "3729 Traning Loss: tensor(1.0208)\n",
      "3730 Traning Loss: tensor(1.0192)\n",
      "3731 Traning Loss: tensor(1.0176)\n",
      "3732 Traning Loss: tensor(1.0160)\n",
      "3733 Traning Loss: tensor(1.0145)\n",
      "3734 Traning Loss: tensor(1.0129)\n",
      "3735 Traning Loss: tensor(1.0113)\n",
      "3736 Traning Loss: tensor(1.0098)\n",
      "3737 Traning Loss: tensor(1.0082)\n",
      "3738 Traning Loss: tensor(1.0067)\n",
      "3739 Traning Loss: tensor(1.0051)\n",
      "3740 Traning Loss: tensor(1.0035)\n",
      "3741 Traning Loss: tensor(1.0020)\n",
      "3742 Traning Loss: tensor(1.0004)\n",
      "3743 Traning Loss: tensor(0.9989)\n",
      "3744 Traning Loss: tensor(0.9973)\n",
      "3745 Traning Loss: tensor(0.9958)\n",
      "3746 Traning Loss: tensor(0.9943)\n",
      "3747 Traning Loss: tensor(0.9927)\n",
      "3748 Traning Loss: tensor(0.9912)\n",
      "3749 Traning Loss: tensor(0.9897)\n",
      "3750 Traning Loss: tensor(0.9881)\n",
      "3751 Traning Loss: tensor(0.9866)\n",
      "3752 Traning Loss: tensor(0.9851)\n",
      "3753 Traning Loss: tensor(0.9836)\n",
      "3754 Traning Loss: tensor(0.9820)\n",
      "3755 Traning Loss: tensor(0.9805)\n",
      "3756 Traning Loss: tensor(0.9790)\n",
      "3757 Traning Loss: tensor(0.9775)\n",
      "3758 Traning Loss: tensor(0.9760)\n",
      "3759 Traning Loss: tensor(0.9745)\n",
      "3760 Traning Loss: tensor(0.9730)\n",
      "3761 Traning Loss: tensor(0.9715)\n",
      "3762 Traning Loss: tensor(0.9700)\n",
      "3763 Traning Loss: tensor(0.9685)\n",
      "3764 Traning Loss: tensor(0.9670)\n",
      "3765 Traning Loss: tensor(0.9655)\n",
      "3766 Traning Loss: tensor(0.9640)\n",
      "3767 Traning Loss: tensor(0.9625)\n",
      "3768 Traning Loss: tensor(0.9610)\n",
      "3769 Traning Loss: tensor(0.9595)\n",
      "3770 Traning Loss: tensor(0.9581)\n",
      "3771 Traning Loss: tensor(0.9566)\n",
      "3772 Traning Loss: tensor(0.9551)\n",
      "3773 Traning Loss: tensor(0.9536)\n",
      "3774 Traning Loss: tensor(0.9522)\n",
      "3775 Traning Loss: tensor(0.9507)\n",
      "3776 Traning Loss: tensor(0.9493)\n",
      "3777 Traning Loss: tensor(0.9478)\n",
      "3778 Traning Loss: tensor(0.9463)\n",
      "3779 Traning Loss: tensor(0.9449)\n",
      "3780 Traning Loss: tensor(0.9434)\n",
      "3781 Traning Loss: tensor(0.9420)\n",
      "3782 Traning Loss: tensor(0.9405)\n",
      "3783 Traning Loss: tensor(0.9391)\n",
      "3784 Traning Loss: tensor(0.9377)\n",
      "3785 Traning Loss: tensor(0.9362)\n",
      "3786 Traning Loss: tensor(0.9348)\n",
      "3787 Traning Loss: tensor(0.9334)\n",
      "3788 Traning Loss: tensor(0.9319)\n",
      "3789 Traning Loss: tensor(0.9305)\n",
      "3790 Traning Loss: tensor(0.9291)\n",
      "3791 Traning Loss: tensor(0.9277)\n",
      "3792 Traning Loss: tensor(0.9263)\n",
      "3793 Traning Loss: tensor(0.9248)\n",
      "3794 Traning Loss: tensor(0.9234)\n",
      "3795 Traning Loss: tensor(0.9220)\n",
      "3796 Traning Loss: tensor(0.9206)\n",
      "3797 Traning Loss: tensor(0.9192)\n",
      "3798 Traning Loss: tensor(0.9178)\n",
      "3799 Traning Loss: tensor(0.9165)\n",
      "3800 Traning Loss: tensor(0.9151)\n",
      "3801 Traning Loss: tensor(0.9137)\n",
      "3802 Traning Loss: tensor(0.9123)\n",
      "3803 Traning Loss: tensor(0.9109)\n",
      "3804 Traning Loss: tensor(0.9096)\n",
      "3805 Traning Loss: tensor(0.9082)\n",
      "3806 Traning Loss: tensor(0.9068)\n",
      "3807 Traning Loss: tensor(0.9055)\n",
      "3808 Traning Loss: tensor(0.9041)\n",
      "3809 Traning Loss: tensor(0.9028)\n",
      "3810 Traning Loss: tensor(0.9014)\n",
      "3811 Traning Loss: tensor(0.9001)\n",
      "3812 Traning Loss: tensor(0.8987)\n",
      "3813 Traning Loss: tensor(0.8974)\n",
      "3814 Traning Loss: tensor(0.8960)\n",
      "3815 Traning Loss: tensor(0.8947)\n",
      "3816 Traning Loss: tensor(0.8934)\n",
      "3817 Traning Loss: tensor(0.8921)\n",
      "3818 Traning Loss: tensor(0.8908)\n",
      "3819 Traning Loss: tensor(0.8894)\n",
      "3820 Traning Loss: tensor(0.8881)\n",
      "3821 Traning Loss: tensor(0.8868)\n",
      "3822 Traning Loss: tensor(0.8855)\n",
      "3823 Traning Loss: tensor(0.8842)\n",
      "3824 Traning Loss: tensor(0.8829)\n",
      "3825 Traning Loss: tensor(0.8816)\n",
      "3826 Traning Loss: tensor(0.8804)\n",
      "3827 Traning Loss: tensor(0.8791)\n",
      "3828 Traning Loss: tensor(0.8778)\n",
      "3829 Traning Loss: tensor(0.8765)\n",
      "3830 Traning Loss: tensor(0.8753)\n",
      "3831 Traning Loss: tensor(0.8740)\n",
      "3832 Traning Loss: tensor(0.8728)\n",
      "3833 Traning Loss: tensor(0.8715)\n",
      "3834 Traning Loss: tensor(0.8702)\n",
      "3835 Traning Loss: tensor(0.8690)\n",
      "3836 Traning Loss: tensor(0.8678)\n",
      "3837 Traning Loss: tensor(0.8665)\n",
      "3838 Traning Loss: tensor(0.8653)\n",
      "3839 Traning Loss: tensor(0.8641)\n",
      "3840 Traning Loss: tensor(0.8628)\n",
      "3841 Traning Loss: tensor(0.8616)\n",
      "3842 Traning Loss: tensor(0.8604)\n",
      "3843 Traning Loss: tensor(0.8592)\n",
      "3844 Traning Loss: tensor(0.8580)\n",
      "3845 Traning Loss: tensor(0.8568)\n",
      "3846 Traning Loss: tensor(0.8556)\n",
      "3847 Traning Loss: tensor(0.8544)\n",
      "3848 Traning Loss: tensor(0.8532)\n",
      "3849 Traning Loss: tensor(0.8520)\n",
      "3850 Traning Loss: tensor(0.8508)\n",
      "3851 Traning Loss: tensor(0.8497)\n",
      "3852 Traning Loss: tensor(0.8485)\n",
      "3853 Traning Loss: tensor(0.8473)\n",
      "3854 Traning Loss: tensor(0.8462)\n",
      "3855 Traning Loss: tensor(0.8450)\n",
      "3856 Traning Loss: tensor(0.8439)\n",
      "3857 Traning Loss: tensor(0.8427)\n",
      "3858 Traning Loss: tensor(0.8416)\n",
      "3859 Traning Loss: tensor(0.8404)\n",
      "3860 Traning Loss: tensor(0.8393)\n",
      "3861 Traning Loss: tensor(0.8382)\n",
      "3862 Traning Loss: tensor(0.8370)\n",
      "3863 Traning Loss: tensor(0.8359)\n",
      "3864 Traning Loss: tensor(0.8348)\n",
      "3865 Traning Loss: tensor(0.8337)\n",
      "3866 Traning Loss: tensor(0.8326)\n",
      "3867 Traning Loss: tensor(0.8314)\n",
      "3868 Traning Loss: tensor(0.8303)\n",
      "3869 Traning Loss: tensor(0.8292)\n",
      "3870 Traning Loss: tensor(0.8282)\n",
      "3871 Traning Loss: tensor(0.8271)\n",
      "3872 Traning Loss: tensor(0.8260)\n",
      "3873 Traning Loss: tensor(0.8249)\n",
      "3874 Traning Loss: tensor(0.8238)\n",
      "3875 Traning Loss: tensor(0.8227)\n",
      "3876 Traning Loss: tensor(0.8217)\n",
      "3877 Traning Loss: tensor(0.8206)\n",
      "3878 Traning Loss: tensor(0.8195)\n",
      "3879 Traning Loss: tensor(0.8185)\n",
      "3880 Traning Loss: tensor(0.8174)\n",
      "3881 Traning Loss: tensor(0.8164)\n",
      "3882 Traning Loss: tensor(0.8153)\n",
      "3883 Traning Loss: tensor(0.8143)\n",
      "3884 Traning Loss: tensor(0.8132)\n",
      "3885 Traning Loss: tensor(0.8122)\n",
      "3886 Traning Loss: tensor(0.8112)\n",
      "3887 Traning Loss: tensor(0.8101)\n",
      "3888 Traning Loss: tensor(0.8091)\n",
      "3889 Traning Loss: tensor(0.8081)\n",
      "3890 Traning Loss: tensor(0.8071)\n",
      "3891 Traning Loss: tensor(0.8061)\n",
      "3892 Traning Loss: tensor(0.8051)\n",
      "3893 Traning Loss: tensor(0.8040)\n",
      "3894 Traning Loss: tensor(0.8030)\n",
      "3895 Traning Loss: tensor(0.8020)\n",
      "3896 Traning Loss: tensor(0.8010)\n",
      "3897 Traning Loss: tensor(0.8001)\n",
      "3898 Traning Loss: tensor(0.7991)\n",
      "3899 Traning Loss: tensor(0.7981)\n",
      "3900 Traning Loss: tensor(0.7971)\n",
      "3901 Traning Loss: tensor(0.7961)\n",
      "3902 Traning Loss: tensor(0.7951)\n",
      "3903 Traning Loss: tensor(0.7942)\n",
      "3904 Traning Loss: tensor(0.7932)\n",
      "3905 Traning Loss: tensor(0.7922)\n",
      "3906 Traning Loss: tensor(0.7913)\n",
      "3907 Traning Loss: tensor(0.7903)\n",
      "3908 Traning Loss: tensor(0.7893)\n",
      "3909 Traning Loss: tensor(0.7884)\n",
      "3910 Traning Loss: tensor(0.7874)\n",
      "3911 Traning Loss: tensor(0.7865)\n",
      "3912 Traning Loss: tensor(0.7855)\n",
      "3913 Traning Loss: tensor(0.7846)\n",
      "3914 Traning Loss: tensor(0.7837)\n",
      "3915 Traning Loss: tensor(0.7827)\n",
      "3916 Traning Loss: tensor(0.7818)\n",
      "3917 Traning Loss: tensor(0.7809)\n",
      "3918 Traning Loss: tensor(0.7799)\n",
      "3919 Traning Loss: tensor(0.7790)\n",
      "3920 Traning Loss: tensor(0.7781)\n",
      "3921 Traning Loss: tensor(0.7772)\n",
      "3922 Traning Loss: tensor(0.7763)\n",
      "3923 Traning Loss: tensor(0.7754)\n",
      "3924 Traning Loss: tensor(0.7744)\n",
      "3925 Traning Loss: tensor(0.7735)\n",
      "3926 Traning Loss: tensor(0.7726)\n",
      "3927 Traning Loss: tensor(0.7717)\n",
      "3928 Traning Loss: tensor(0.7708)\n",
      "3929 Traning Loss: tensor(0.7699)\n",
      "3930 Traning Loss: tensor(0.7690)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931 Traning Loss: tensor(0.7681)\n",
      "3932 Traning Loss: tensor(0.7672)\n",
      "3933 Traning Loss: tensor(0.7663)\n",
      "3934 Traning Loss: tensor(0.7654)\n",
      "3935 Traning Loss: tensor(0.7645)\n",
      "3936 Traning Loss: tensor(0.7637)\n",
      "3937 Traning Loss: tensor(0.7628)\n",
      "3938 Traning Loss: tensor(0.7619)\n",
      "3939 Traning Loss: tensor(0.7610)\n",
      "3940 Traning Loss: tensor(0.7601)\n",
      "3941 Traning Loss: tensor(0.7593)\n",
      "3942 Traning Loss: tensor(0.7584)\n",
      "3943 Traning Loss: tensor(0.7575)\n",
      "3944 Traning Loss: tensor(0.7566)\n",
      "3945 Traning Loss: tensor(0.7558)\n",
      "3946 Traning Loss: tensor(0.7549)\n",
      "3947 Traning Loss: tensor(0.7541)\n",
      "3948 Traning Loss: tensor(0.7532)\n",
      "3949 Traning Loss: tensor(0.7523)\n",
      "3950 Traning Loss: tensor(0.7515)\n",
      "3951 Traning Loss: tensor(0.7506)\n",
      "3952 Traning Loss: tensor(0.7498)\n",
      "3953 Traning Loss: tensor(0.7489)\n",
      "3954 Traning Loss: tensor(0.7481)\n",
      "3955 Traning Loss: tensor(0.7472)\n",
      "3956 Traning Loss: tensor(0.7464)\n",
      "3957 Traning Loss: tensor(0.7455)\n",
      "3958 Traning Loss: tensor(0.7447)\n",
      "3959 Traning Loss: tensor(0.7438)\n",
      "3960 Traning Loss: tensor(0.7430)\n",
      "3961 Traning Loss: tensor(0.7421)\n",
      "3962 Traning Loss: tensor(0.7413)\n",
      "3963 Traning Loss: tensor(0.7404)\n",
      "3964 Traning Loss: tensor(0.7396)\n",
      "3965 Traning Loss: tensor(0.7388)\n",
      "3966 Traning Loss: tensor(0.7379)\n",
      "3967 Traning Loss: tensor(0.7371)\n",
      "3968 Traning Loss: tensor(0.7363)\n",
      "3969 Traning Loss: tensor(0.7354)\n",
      "3970 Traning Loss: tensor(0.7346)\n",
      "3971 Traning Loss: tensor(0.7338)\n",
      "3972 Traning Loss: tensor(0.7329)\n",
      "3973 Traning Loss: tensor(0.7321)\n",
      "3974 Traning Loss: tensor(0.7313)\n",
      "3975 Traning Loss: tensor(0.7305)\n",
      "3976 Traning Loss: tensor(0.7296)\n",
      "3977 Traning Loss: tensor(0.7288)\n",
      "3978 Traning Loss: tensor(0.7280)\n",
      "3979 Traning Loss: tensor(0.7272)\n",
      "3980 Traning Loss: tensor(0.7263)\n",
      "3981 Traning Loss: tensor(0.7255)\n",
      "3982 Traning Loss: tensor(0.7247)\n",
      "3983 Traning Loss: tensor(0.7239)\n",
      "3984 Traning Loss: tensor(0.7231)\n",
      "3985 Traning Loss: tensor(0.7223)\n",
      "3986 Traning Loss: tensor(0.7214)\n",
      "3987 Traning Loss: tensor(0.7206)\n",
      "3988 Traning Loss: tensor(0.7198)\n",
      "3989 Traning Loss: tensor(0.7190)\n",
      "3990 Traning Loss: tensor(0.7182)\n",
      "3991 Traning Loss: tensor(0.7174)\n",
      "3992 Traning Loss: tensor(0.7166)\n",
      "3993 Traning Loss: tensor(0.7158)\n",
      "3994 Traning Loss: tensor(0.7150)\n",
      "3995 Traning Loss: tensor(0.7142)\n",
      "3996 Traning Loss: tensor(0.7133)\n",
      "3997 Traning Loss: tensor(0.7125)\n",
      "3998 Traning Loss: tensor(0.7117)\n",
      "3999 Traning Loss: tensor(0.7109)\n",
      "4000 Traning Loss: tensor(0.7101)\n",
      "4001 Traning Loss: tensor(0.7093)\n",
      "4002 Traning Loss: tensor(0.7085)\n",
      "4003 Traning Loss: tensor(0.7077)\n",
      "4004 Traning Loss: tensor(0.7069)\n",
      "4005 Traning Loss: tensor(0.7061)\n",
      "4006 Traning Loss: tensor(0.7054)\n",
      "4007 Traning Loss: tensor(0.7046)\n",
      "4008 Traning Loss: tensor(0.7038)\n",
      "4009 Traning Loss: tensor(0.7030)\n",
      "4010 Traning Loss: tensor(0.7022)\n",
      "4011 Traning Loss: tensor(0.7014)\n",
      "4012 Traning Loss: tensor(0.7006)\n",
      "4013 Traning Loss: tensor(0.6998)\n",
      "4014 Traning Loss: tensor(0.6990)\n",
      "4015 Traning Loss: tensor(0.6983)\n",
      "4016 Traning Loss: tensor(0.6975)\n",
      "4017 Traning Loss: tensor(0.6967)\n",
      "4018 Traning Loss: tensor(0.6959)\n",
      "4019 Traning Loss: tensor(0.6951)\n",
      "4020 Traning Loss: tensor(0.6943)\n",
      "4021 Traning Loss: tensor(0.6936)\n",
      "4022 Traning Loss: tensor(0.6928)\n",
      "4023 Traning Loss: tensor(0.6920)\n",
      "4024 Traning Loss: tensor(0.6913)\n",
      "4025 Traning Loss: tensor(0.6905)\n",
      "4026 Traning Loss: tensor(0.6897)\n",
      "4027 Traning Loss: tensor(0.6889)\n",
      "4028 Traning Loss: tensor(0.6882)\n",
      "4029 Traning Loss: tensor(0.6874)\n",
      "4030 Traning Loss: tensor(0.6866)\n",
      "4031 Traning Loss: tensor(0.6859)\n",
      "4032 Traning Loss: tensor(0.6851)\n",
      "4033 Traning Loss: tensor(0.6844)\n",
      "4034 Traning Loss: tensor(0.6836)\n",
      "4035 Traning Loss: tensor(0.6829)\n",
      "4036 Traning Loss: tensor(0.6821)\n",
      "4037 Traning Loss: tensor(0.6814)\n",
      "4038 Traning Loss: tensor(0.6807)\n",
      "4039 Traning Loss: tensor(0.6800)\n",
      "4040 Traning Loss: tensor(0.6792)\n",
      "4041 Traning Loss: tensor(0.6784)\n",
      "4042 Traning Loss: tensor(0.6776)\n",
      "4043 Traning Loss: tensor(0.6770)\n",
      "4044 Traning Loss: tensor(0.6762)\n",
      "4045 Traning Loss: tensor(0.6754)\n",
      "4046 Traning Loss: tensor(0.6747)\n",
      "4047 Traning Loss: tensor(0.6740)\n",
      "4048 Traning Loss: tensor(0.6733)\n",
      "4049 Traning Loss: tensor(0.6725)\n",
      "4050 Traning Loss: tensor(0.6718)\n",
      "4051 Traning Loss: tensor(0.6711)\n",
      "4052 Traning Loss: tensor(0.6704)\n",
      "4053 Traning Loss: tensor(0.6697)\n",
      "4054 Traning Loss: tensor(0.6689)\n",
      "4055 Traning Loss: tensor(0.6682)\n",
      "4056 Traning Loss: tensor(0.6675)\n",
      "4057 Traning Loss: tensor(0.6668)\n",
      "4058 Traning Loss: tensor(0.6661)\n",
      "4059 Traning Loss: tensor(0.6654)\n",
      "4060 Traning Loss: tensor(0.6647)\n",
      "4061 Traning Loss: tensor(0.6640)\n",
      "4062 Traning Loss: tensor(0.6633)\n",
      "4063 Traning Loss: tensor(0.6626)\n",
      "4064 Traning Loss: tensor(0.6620)\n",
      "4065 Traning Loss: tensor(0.6613)\n",
      "4066 Traning Loss: tensor(0.6606)\n",
      "4067 Traning Loss: tensor(0.6599)\n",
      "4068 Traning Loss: tensor(0.6592)\n",
      "4069 Traning Loss: tensor(0.6585)\n",
      "4070 Traning Loss: tensor(0.6579)\n",
      "4071 Traning Loss: tensor(0.6572)\n",
      "4072 Traning Loss: tensor(0.6565)\n",
      "4073 Traning Loss: tensor(0.6559)\n",
      "4074 Traning Loss: tensor(0.6552)\n",
      "4075 Traning Loss: tensor(0.6545)\n",
      "4076 Traning Loss: tensor(0.6539)\n",
      "4077 Traning Loss: tensor(0.6532)\n",
      "4078 Traning Loss: tensor(0.6526)\n",
      "4079 Traning Loss: tensor(0.6519)\n",
      "4080 Traning Loss: tensor(0.6512)\n",
      "4081 Traning Loss: tensor(0.6506)\n",
      "4082 Traning Loss: tensor(0.6500)\n",
      "4083 Traning Loss: tensor(0.6493)\n",
      "4084 Traning Loss: tensor(0.6487)\n",
      "4085 Traning Loss: tensor(0.6480)\n",
      "4086 Traning Loss: tensor(0.6474)\n",
      "4087 Traning Loss: tensor(0.6468)\n",
      "4088 Traning Loss: tensor(0.6461)\n",
      "4089 Traning Loss: tensor(0.6455)\n",
      "4090 Traning Loss: tensor(0.6449)\n",
      "4091 Traning Loss: tensor(0.6443)\n",
      "4092 Traning Loss: tensor(0.6436)\n",
      "4093 Traning Loss: tensor(0.6430)\n",
      "4094 Traning Loss: tensor(0.6424)\n",
      "4095 Traning Loss: tensor(0.6418)\n",
      "4096 Traning Loss: tensor(0.6412)\n",
      "4097 Traning Loss: tensor(0.6406)\n",
      "4098 Traning Loss: tensor(0.6400)\n",
      "4099 Traning Loss: tensor(0.6394)\n",
      "4100 Traning Loss: tensor(0.6388)\n",
      "4101 Traning Loss: tensor(0.6382)\n",
      "4102 Traning Loss: tensor(0.6376)\n",
      "4103 Traning Loss: tensor(0.6370)\n",
      "4104 Traning Loss: tensor(0.6364)\n",
      "4105 Traning Loss: tensor(0.6358)\n",
      "4106 Traning Loss: tensor(0.6352)\n",
      "4107 Traning Loss: tensor(0.6347)\n",
      "4108 Traning Loss: tensor(0.6341)\n",
      "4109 Traning Loss: tensor(0.6335)\n",
      "4110 Traning Loss: tensor(0.6329)\n",
      "4111 Traning Loss: tensor(0.6323)\n",
      "4112 Traning Loss: tensor(0.6318)\n",
      "4113 Traning Loss: tensor(0.6312)\n",
      "4114 Traning Loss: tensor(0.6306)\n",
      "4115 Traning Loss: tensor(0.6301)\n",
      "4116 Traning Loss: tensor(0.6295)\n",
      "4117 Traning Loss: tensor(0.6290)\n",
      "4118 Traning Loss: tensor(0.6284)\n",
      "4119 Traning Loss: tensor(0.6279)\n",
      "4120 Traning Loss: tensor(0.6273)\n",
      "4121 Traning Loss: tensor(0.6268)\n",
      "4122 Traning Loss: tensor(0.6262)\n",
      "4123 Traning Loss: tensor(0.6257)\n",
      "4124 Traning Loss: tensor(0.6251)\n",
      "4125 Traning Loss: tensor(0.6246)\n",
      "4126 Traning Loss: tensor(0.6240)\n",
      "4127 Traning Loss: tensor(0.6235)\n",
      "4128 Traning Loss: tensor(0.6230)\n",
      "4129 Traning Loss: tensor(0.6224)\n",
      "4130 Traning Loss: tensor(0.6219)\n",
      "4131 Traning Loss: tensor(0.6214)\n",
      "4132 Traning Loss: tensor(0.6209)\n",
      "4133 Traning Loss: tensor(0.6203)\n",
      "4134 Traning Loss: tensor(0.6198)\n",
      "4135 Traning Loss: tensor(0.6193)\n",
      "4136 Traning Loss: tensor(0.6188)\n",
      "4137 Traning Loss: tensor(0.6183)\n",
      "4138 Traning Loss: tensor(0.6178)\n",
      "4139 Traning Loss: tensor(0.6173)\n",
      "4140 Traning Loss: tensor(0.6167)\n",
      "4141 Traning Loss: tensor(0.6162)\n",
      "4142 Traning Loss: tensor(0.6157)\n",
      "4143 Traning Loss: tensor(0.6152)\n",
      "4144 Traning Loss: tensor(0.6147)\n",
      "4145 Traning Loss: tensor(0.6142)\n",
      "4146 Traning Loss: tensor(0.6137)\n",
      "4147 Traning Loss: tensor(0.6133)\n",
      "4148 Traning Loss: tensor(0.6128)\n",
      "4149 Traning Loss: tensor(0.6123)\n",
      "4150 Traning Loss: tensor(0.6118)\n",
      "4151 Traning Loss: tensor(0.6113)\n",
      "4152 Traning Loss: tensor(0.6108)\n",
      "4153 Traning Loss: tensor(0.6103)\n",
      "4154 Traning Loss: tensor(0.6099)\n",
      "4155 Traning Loss: tensor(0.6094)\n",
      "4156 Traning Loss: tensor(0.6089)\n",
      "4157 Traning Loss: tensor(0.6085)\n",
      "4158 Traning Loss: tensor(0.6080)\n",
      "4159 Traning Loss: tensor(0.6076)\n",
      "4160 Traning Loss: tensor(0.6071)\n",
      "4161 Traning Loss: tensor(0.6066)\n",
      "4162 Traning Loss: tensor(0.6061)\n",
      "4163 Traning Loss: tensor(0.6056)\n",
      "4164 Traning Loss: tensor(0.6052)\n",
      "4165 Traning Loss: tensor(0.6047)\n",
      "4166 Traning Loss: tensor(0.6043)\n",
      "4167 Traning Loss: tensor(0.6038)\n",
      "4168 Traning Loss: tensor(0.6033)\n",
      "4169 Traning Loss: tensor(0.6029)\n",
      "4170 Traning Loss: tensor(0.6024)\n",
      "4171 Traning Loss: tensor(0.6020)\n",
      "4172 Traning Loss: tensor(0.6016)\n",
      "4173 Traning Loss: tensor(0.6011)\n",
      "4174 Traning Loss: tensor(0.6006)\n",
      "4175 Traning Loss: tensor(0.6002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4176 Traning Loss: tensor(0.5998)\n",
      "4177 Traning Loss: tensor(0.5993)\n",
      "4178 Traning Loss: tensor(0.5989)\n",
      "4179 Traning Loss: tensor(0.5985)\n",
      "4180 Traning Loss: tensor(0.5980)\n",
      "4181 Traning Loss: tensor(0.5976)\n",
      "4182 Traning Loss: tensor(0.5972)\n",
      "4183 Traning Loss: tensor(0.5967)\n",
      "4184 Traning Loss: tensor(0.5963)\n",
      "4185 Traning Loss: tensor(0.5959)\n",
      "4186 Traning Loss: tensor(0.5954)\n",
      "4187 Traning Loss: tensor(0.5950)\n",
      "4188 Traning Loss: tensor(0.5946)\n",
      "4189 Traning Loss: tensor(0.5942)\n",
      "4190 Traning Loss: tensor(0.5937)\n",
      "4191 Traning Loss: tensor(0.5933)\n",
      "4192 Traning Loss: tensor(0.5929)\n",
      "4193 Traning Loss: tensor(0.5925)\n",
      "4194 Traning Loss: tensor(0.5921)\n",
      "4195 Traning Loss: tensor(0.5917)\n",
      "4196 Traning Loss: tensor(0.5912)\n",
      "4197 Traning Loss: tensor(0.5908)\n",
      "4198 Traning Loss: tensor(0.5904)\n",
      "4199 Traning Loss: tensor(0.5900)\n",
      "4200 Traning Loss: tensor(0.5896)\n",
      "4201 Traning Loss: tensor(0.5892)\n",
      "4202 Traning Loss: tensor(0.5888)\n",
      "4203 Traning Loss: tensor(0.5884)\n",
      "4204 Traning Loss: tensor(0.5880)\n",
      "4205 Traning Loss: tensor(0.5876)\n",
      "4206 Traning Loss: tensor(0.5872)\n",
      "4207 Traning Loss: tensor(0.5868)\n",
      "4208 Traning Loss: tensor(0.5864)\n",
      "4209 Traning Loss: tensor(0.5860)\n",
      "4210 Traning Loss: tensor(0.5856)\n",
      "4211 Traning Loss: tensor(0.5852)\n",
      "4212 Traning Loss: tensor(0.5848)\n",
      "4213 Traning Loss: tensor(0.5844)\n",
      "4214 Traning Loss: tensor(0.5840)\n",
      "4215 Traning Loss: tensor(0.5836)\n",
      "4216 Traning Loss: tensor(0.5832)\n",
      "4217 Traning Loss: tensor(0.5828)\n",
      "4218 Traning Loss: tensor(0.5824)\n",
      "4219 Traning Loss: tensor(0.5820)\n",
      "4220 Traning Loss: tensor(0.5817)\n",
      "4221 Traning Loss: tensor(0.5813)\n",
      "4222 Traning Loss: tensor(0.5809)\n",
      "4223 Traning Loss: tensor(0.5805)\n",
      "4224 Traning Loss: tensor(0.5801)\n",
      "4225 Traning Loss: tensor(0.5797)\n",
      "4226 Traning Loss: tensor(0.5794)\n",
      "4227 Traning Loss: tensor(0.5790)\n",
      "4228 Traning Loss: tensor(0.5786)\n",
      "4229 Traning Loss: tensor(0.5782)\n",
      "4230 Traning Loss: tensor(0.5778)\n",
      "4231 Traning Loss: tensor(0.5775)\n",
      "4232 Traning Loss: tensor(0.5771)\n",
      "4233 Traning Loss: tensor(0.5767)\n",
      "4234 Traning Loss: tensor(0.5763)\n",
      "4235 Traning Loss: tensor(0.5759)\n",
      "4236 Traning Loss: tensor(0.5756)\n",
      "4237 Traning Loss: tensor(0.5752)\n",
      "4238 Traning Loss: tensor(0.5748)\n",
      "4239 Traning Loss: tensor(0.5745)\n",
      "4240 Traning Loss: tensor(0.5741)\n",
      "4241 Traning Loss: tensor(0.5737)\n",
      "4242 Traning Loss: tensor(0.5733)\n",
      "4243 Traning Loss: tensor(0.5730)\n",
      "4244 Traning Loss: tensor(0.5726)\n",
      "4245 Traning Loss: tensor(0.5722)\n",
      "4246 Traning Loss: tensor(0.5719)\n",
      "4247 Traning Loss: tensor(0.5715)\n",
      "4248 Traning Loss: tensor(0.5711)\n",
      "4249 Traning Loss: tensor(0.5708)\n",
      "4250 Traning Loss: tensor(0.5704)\n",
      "4251 Traning Loss: tensor(0.5700)\n",
      "4252 Traning Loss: tensor(0.5697)\n",
      "4253 Traning Loss: tensor(0.5693)\n",
      "4254 Traning Loss: tensor(0.5690)\n",
      "4255 Traning Loss: tensor(0.5686)\n",
      "4256 Traning Loss: tensor(0.5682)\n",
      "4257 Traning Loss: tensor(0.5679)\n",
      "4258 Traning Loss: tensor(0.5675)\n",
      "4259 Traning Loss: tensor(0.5672)\n",
      "4260 Traning Loss: tensor(0.5668)\n",
      "4261 Traning Loss: tensor(0.5664)\n",
      "4262 Traning Loss: tensor(0.5661)\n",
      "4263 Traning Loss: tensor(0.5657)\n",
      "4264 Traning Loss: tensor(0.5654)\n",
      "4265 Traning Loss: tensor(0.5650)\n",
      "4266 Traning Loss: tensor(0.5647)\n",
      "4267 Traning Loss: tensor(0.5643)\n",
      "4268 Traning Loss: tensor(0.5639)\n",
      "4269 Traning Loss: tensor(0.5636)\n",
      "4270 Traning Loss: tensor(0.5632)\n",
      "4271 Traning Loss: tensor(0.5629)\n",
      "4272 Traning Loss: tensor(0.5625)\n",
      "4273 Traning Loss: tensor(0.5622)\n",
      "4274 Traning Loss: tensor(0.5618)\n",
      "4275 Traning Loss: tensor(0.5615)\n",
      "4276 Traning Loss: tensor(0.5611)\n",
      "4277 Traning Loss: tensor(0.5608)\n",
      "4278 Traning Loss: tensor(0.5604)\n",
      "4279 Traning Loss: tensor(0.5601)\n",
      "4280 Traning Loss: tensor(0.5598)\n",
      "4281 Traning Loss: tensor(0.5594)\n",
      "4282 Traning Loss: tensor(0.5591)\n",
      "4283 Traning Loss: tensor(0.5587)\n",
      "4284 Traning Loss: tensor(0.5584)\n",
      "4285 Traning Loss: tensor(0.5580)\n",
      "4286 Traning Loss: tensor(0.5577)\n",
      "4287 Traning Loss: tensor(0.5574)\n",
      "4288 Traning Loss: tensor(0.5570)\n",
      "4289 Traning Loss: tensor(0.5567)\n",
      "4290 Traning Loss: tensor(0.5563)\n",
      "4291 Traning Loss: tensor(0.5560)\n",
      "4292 Traning Loss: tensor(0.5557)\n",
      "4293 Traning Loss: tensor(0.5553)\n",
      "4294 Traning Loss: tensor(0.5550)\n",
      "4295 Traning Loss: tensor(0.5546)\n",
      "4296 Traning Loss: tensor(0.5543)\n",
      "4297 Traning Loss: tensor(0.5540)\n",
      "4298 Traning Loss: tensor(0.5536)\n",
      "4299 Traning Loss: tensor(0.5533)\n",
      "4300 Traning Loss: tensor(0.5530)\n",
      "4301 Traning Loss: tensor(0.5527)\n",
      "4302 Traning Loss: tensor(0.5524)\n",
      "4303 Traning Loss: tensor(0.5521)\n",
      "4304 Traning Loss: tensor(0.5518)\n",
      "4305 Traning Loss: tensor(0.5514)\n",
      "4306 Traning Loss: tensor(0.5511)\n",
      "4307 Traning Loss: tensor(0.5507)\n",
      "4308 Traning Loss: tensor(0.5504)\n",
      "4309 Traning Loss: tensor(0.5500)\n",
      "4310 Traning Loss: tensor(0.5497)\n",
      "4311 Traning Loss: tensor(0.5494)\n",
      "4312 Traning Loss: tensor(0.5491)\n",
      "4313 Traning Loss: tensor(0.5488)\n",
      "4314 Traning Loss: tensor(0.5484)\n",
      "4315 Traning Loss: tensor(0.5481)\n",
      "4316 Traning Loss: tensor(0.5478)\n",
      "4317 Traning Loss: tensor(0.5475)\n",
      "4318 Traning Loss: tensor(0.5472)\n",
      "4319 Traning Loss: tensor(0.5469)\n",
      "4320 Traning Loss: tensor(0.5466)\n",
      "4321 Traning Loss: tensor(0.5462)\n",
      "4322 Traning Loss: tensor(0.5459)\n",
      "4323 Traning Loss: tensor(0.5456)\n",
      "4324 Traning Loss: tensor(0.5453)\n",
      "4325 Traning Loss: tensor(0.5450)\n",
      "4326 Traning Loss: tensor(0.5447)\n",
      "4327 Traning Loss: tensor(0.5444)\n",
      "4328 Traning Loss: tensor(0.5441)\n",
      "4329 Traning Loss: tensor(0.5438)\n",
      "4330 Traning Loss: tensor(0.5435)\n",
      "4331 Traning Loss: tensor(0.5432)\n",
      "4332 Traning Loss: tensor(0.5429)\n",
      "4333 Traning Loss: tensor(0.5426)\n",
      "4334 Traning Loss: tensor(0.5423)\n",
      "4335 Traning Loss: tensor(0.5420)\n",
      "4336 Traning Loss: tensor(0.5417)\n",
      "4337 Traning Loss: tensor(0.5414)\n",
      "4338 Traning Loss: tensor(0.5411)\n",
      "4339 Traning Loss: tensor(0.5408)\n",
      "4340 Traning Loss: tensor(0.5405)\n",
      "4341 Traning Loss: tensor(0.5402)\n",
      "4342 Traning Loss: tensor(0.5399)\n",
      "4343 Traning Loss: tensor(0.5397)\n",
      "4344 Traning Loss: tensor(0.5394)\n",
      "4345 Traning Loss: tensor(0.5391)\n",
      "4346 Traning Loss: tensor(0.5388)\n",
      "4347 Traning Loss: tensor(0.5385)\n",
      "4348 Traning Loss: tensor(0.5382)\n",
      "4349 Traning Loss: tensor(0.5379)\n",
      "4350 Traning Loss: tensor(0.5377)\n",
      "4351 Traning Loss: tensor(0.5374)\n",
      "4352 Traning Loss: tensor(0.5371)\n",
      "4353 Traning Loss: tensor(0.5368)\n",
      "4354 Traning Loss: tensor(0.5365)\n",
      "4355 Traning Loss: tensor(0.5363)\n",
      "4356 Traning Loss: tensor(0.5360)\n",
      "4357 Traning Loss: tensor(0.5357)\n",
      "4358 Traning Loss: tensor(0.5354)\n",
      "4359 Traning Loss: tensor(0.5352)\n",
      "4360 Traning Loss: tensor(0.5349)\n",
      "4361 Traning Loss: tensor(0.5346)\n",
      "4362 Traning Loss: tensor(0.5343)\n",
      "4363 Traning Loss: tensor(0.5341)\n",
      "4364 Traning Loss: tensor(0.5338)\n",
      "4365 Traning Loss: tensor(0.5335)\n",
      "4366 Traning Loss: tensor(0.5333)\n",
      "4367 Traning Loss: tensor(0.5330)\n",
      "4368 Traning Loss: tensor(0.5327)\n",
      "4369 Traning Loss: tensor(0.5325)\n",
      "4370 Traning Loss: tensor(0.5322)\n",
      "4371 Traning Loss: tensor(0.5319)\n",
      "4372 Traning Loss: tensor(0.5317)\n",
      "4373 Traning Loss: tensor(0.5314)\n",
      "4374 Traning Loss: tensor(0.5311)\n",
      "4375 Traning Loss: tensor(0.5309)\n",
      "4376 Traning Loss: tensor(0.5306)\n",
      "4377 Traning Loss: tensor(0.5303)\n",
      "4378 Traning Loss: tensor(0.5301)\n",
      "4379 Traning Loss: tensor(0.5298)\n",
      "4380 Traning Loss: tensor(0.5296)\n",
      "4381 Traning Loss: tensor(0.5293)\n",
      "4382 Traning Loss: tensor(0.5291)\n",
      "4383 Traning Loss: tensor(0.5288)\n",
      "4384 Traning Loss: tensor(0.5285)\n",
      "4385 Traning Loss: tensor(0.5283)\n",
      "4386 Traning Loss: tensor(0.5280)\n",
      "4387 Traning Loss: tensor(0.5278)\n",
      "4388 Traning Loss: tensor(0.5275)\n",
      "4389 Traning Loss: tensor(0.5273)\n",
      "4390 Traning Loss: tensor(0.5270)\n",
      "4391 Traning Loss: tensor(0.5268)\n",
      "4392 Traning Loss: tensor(0.5265)\n",
      "4393 Traning Loss: tensor(0.5263)\n",
      "4394 Traning Loss: tensor(0.5260)\n",
      "4395 Traning Loss: tensor(0.5258)\n",
      "4396 Traning Loss: tensor(0.5255)\n",
      "4397 Traning Loss: tensor(0.5253)\n",
      "4398 Traning Loss: tensor(0.5250)\n",
      "4399 Traning Loss: tensor(0.5248)\n",
      "4400 Traning Loss: tensor(0.5245)\n",
      "4401 Traning Loss: tensor(0.5243)\n",
      "4402 Traning Loss: tensor(0.5240)\n",
      "4403 Traning Loss: tensor(0.5238)\n",
      "4404 Traning Loss: tensor(0.5236)\n",
      "4405 Traning Loss: tensor(0.5233)\n",
      "4406 Traning Loss: tensor(0.5231)\n",
      "4407 Traning Loss: tensor(0.5228)\n",
      "4408 Traning Loss: tensor(0.5226)\n",
      "4409 Traning Loss: tensor(0.5224)\n",
      "4410 Traning Loss: tensor(0.5221)\n",
      "4411 Traning Loss: tensor(0.5219)\n",
      "4412 Traning Loss: tensor(0.5216)\n",
      "4413 Traning Loss: tensor(0.5214)\n",
      "4414 Traning Loss: tensor(0.5212)\n",
      "4415 Traning Loss: tensor(0.5209)\n",
      "4416 Traning Loss: tensor(0.5207)\n",
      "4417 Traning Loss: tensor(0.5205)\n",
      "4418 Traning Loss: tensor(0.5202)\n",
      "4419 Traning Loss: tensor(0.5200)\n",
      "4420 Traning Loss: tensor(0.5197)\n",
      "4421 Traning Loss: tensor(0.5195)\n",
      "4422 Traning Loss: tensor(0.5193)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4423 Traning Loss: tensor(0.5190)\n",
      "4424 Traning Loss: tensor(0.5188)\n",
      "4425 Traning Loss: tensor(0.5186)\n",
      "4426 Traning Loss: tensor(0.5184)\n",
      "4427 Traning Loss: tensor(0.5181)\n",
      "4428 Traning Loss: tensor(0.5179)\n",
      "4429 Traning Loss: tensor(0.5177)\n",
      "4430 Traning Loss: tensor(0.5174)\n",
      "4431 Traning Loss: tensor(0.5172)\n",
      "4432 Traning Loss: tensor(0.5170)\n",
      "4433 Traning Loss: tensor(0.5167)\n",
      "4434 Traning Loss: tensor(0.5165)\n",
      "4435 Traning Loss: tensor(0.5163)\n",
      "4436 Traning Loss: tensor(0.5161)\n",
      "4437 Traning Loss: tensor(0.5158)\n",
      "4438 Traning Loss: tensor(0.5156)\n",
      "4439 Traning Loss: tensor(0.5154)\n",
      "4440 Traning Loss: tensor(0.5152)\n",
      "4441 Traning Loss: tensor(0.5149)\n",
      "4442 Traning Loss: tensor(0.5147)\n",
      "4443 Traning Loss: tensor(0.5145)\n",
      "4444 Traning Loss: tensor(0.5143)\n",
      "4445 Traning Loss: tensor(0.5141)\n",
      "4446 Traning Loss: tensor(0.5138)\n",
      "4447 Traning Loss: tensor(0.5136)\n",
      "4448 Traning Loss: tensor(0.5134)\n",
      "4449 Traning Loss: tensor(0.5132)\n",
      "4450 Traning Loss: tensor(0.5130)\n",
      "4451 Traning Loss: tensor(0.5127)\n",
      "4452 Traning Loss: tensor(0.5125)\n",
      "4453 Traning Loss: tensor(0.5123)\n",
      "4454 Traning Loss: tensor(0.5121)\n",
      "4455 Traning Loss: tensor(0.5119)\n",
      "4456 Traning Loss: tensor(0.5117)\n",
      "4457 Traning Loss: tensor(0.5115)\n",
      "4458 Traning Loss: tensor(0.5113)\n",
      "4459 Traning Loss: tensor(0.5111)\n",
      "4460 Traning Loss: tensor(0.5109)\n",
      "4461 Traning Loss: tensor(0.5106)\n",
      "4462 Traning Loss: tensor(0.5104)\n",
      "4463 Traning Loss: tensor(0.5101)\n",
      "4464 Traning Loss: tensor(0.5099)\n",
      "4465 Traning Loss: tensor(0.5097)\n",
      "4466 Traning Loss: tensor(0.5095)\n",
      "4467 Traning Loss: tensor(0.5093)\n",
      "4468 Traning Loss: tensor(0.5091)\n",
      "4469 Traning Loss: tensor(0.5089)\n",
      "4470 Traning Loss: tensor(0.5087)\n",
      "4471 Traning Loss: tensor(0.5085)\n",
      "4472 Traning Loss: tensor(0.5083)\n",
      "4473 Traning Loss: tensor(0.5081)\n",
      "4474 Traning Loss: tensor(0.5078)\n",
      "4475 Traning Loss: tensor(0.5076)\n",
      "4476 Traning Loss: tensor(0.5074)\n",
      "4477 Traning Loss: tensor(0.5072)\n",
      "4478 Traning Loss: tensor(0.5070)\n",
      "4479 Traning Loss: tensor(0.5068)\n",
      "4480 Traning Loss: tensor(0.5066)\n",
      "4481 Traning Loss: tensor(0.5064)\n",
      "4482 Traning Loss: tensor(0.5062)\n",
      "4483 Traning Loss: tensor(0.5060)\n",
      "4484 Traning Loss: tensor(0.5058)\n",
      "4485 Traning Loss: tensor(0.5056)\n",
      "4486 Traning Loss: tensor(0.5054)\n",
      "4487 Traning Loss: tensor(0.5051)\n",
      "4488 Traning Loss: tensor(0.5049)\n",
      "4489 Traning Loss: tensor(0.5047)\n",
      "4490 Traning Loss: tensor(0.5045)\n",
      "4491 Traning Loss: tensor(0.5043)\n",
      "4492 Traning Loss: tensor(0.5041)\n",
      "4493 Traning Loss: tensor(0.5039)\n",
      "4494 Traning Loss: tensor(0.5037)\n",
      "4495 Traning Loss: tensor(0.5035)\n",
      "4496 Traning Loss: tensor(0.5033)\n",
      "4497 Traning Loss: tensor(0.5031)\n",
      "4498 Traning Loss: tensor(0.5029)\n",
      "4499 Traning Loss: tensor(0.5027)\n",
      "4500 Traning Loss: tensor(0.5025)\n",
      "4501 Traning Loss: tensor(0.5023)\n",
      "4502 Traning Loss: tensor(0.5021)\n",
      "4503 Traning Loss: tensor(0.5019)\n",
      "4504 Traning Loss: tensor(0.5017)\n",
      "4505 Traning Loss: tensor(0.5015)\n",
      "4506 Traning Loss: tensor(0.5013)\n",
      "4507 Traning Loss: tensor(0.5011)\n",
      "4508 Traning Loss: tensor(0.5009)\n",
      "4509 Traning Loss: tensor(0.5007)\n",
      "4510 Traning Loss: tensor(0.5005)\n",
      "4511 Traning Loss: tensor(0.5003)\n",
      "4512 Traning Loss: tensor(0.5002)\n",
      "4513 Traning Loss: tensor(0.5000)\n",
      "4514 Traning Loss: tensor(0.4998)\n",
      "4515 Traning Loss: tensor(0.4996)\n",
      "4516 Traning Loss: tensor(0.4994)\n",
      "4517 Traning Loss: tensor(0.4992)\n",
      "4518 Traning Loss: tensor(0.4990)\n",
      "4519 Traning Loss: tensor(0.4988)\n",
      "4520 Traning Loss: tensor(0.4986)\n",
      "4521 Traning Loss: tensor(0.4984)\n",
      "4522 Traning Loss: tensor(0.4982)\n",
      "4523 Traning Loss: tensor(0.4980)\n",
      "4524 Traning Loss: tensor(0.4978)\n",
      "4525 Traning Loss: tensor(0.4976)\n",
      "4526 Traning Loss: tensor(0.4974)\n",
      "4527 Traning Loss: tensor(0.4972)\n",
      "4528 Traning Loss: tensor(0.4971)\n",
      "4529 Traning Loss: tensor(0.4969)\n",
      "4530 Traning Loss: tensor(0.4967)\n",
      "4531 Traning Loss: tensor(0.4965)\n",
      "4532 Traning Loss: tensor(0.4963)\n",
      "4533 Traning Loss: tensor(0.4961)\n",
      "4534 Traning Loss: tensor(0.4959)\n",
      "4535 Traning Loss: tensor(0.4957)\n",
      "4536 Traning Loss: tensor(0.4955)\n",
      "4537 Traning Loss: tensor(0.4953)\n",
      "4538 Traning Loss: tensor(0.4951)\n",
      "4539 Traning Loss: tensor(0.4950)\n",
      "4540 Traning Loss: tensor(0.4948)\n",
      "4541 Traning Loss: tensor(0.4946)\n",
      "4542 Traning Loss: tensor(0.4944)\n",
      "4543 Traning Loss: tensor(0.4942)\n",
      "4544 Traning Loss: tensor(0.4940)\n",
      "4545 Traning Loss: tensor(0.4938)\n",
      "4546 Traning Loss: tensor(0.4936)\n",
      "4547 Traning Loss: tensor(0.4935)\n",
      "4548 Traning Loss: tensor(0.4933)\n",
      "4549 Traning Loss: tensor(0.4931)\n",
      "4550 Traning Loss: tensor(0.4929)\n",
      "4551 Traning Loss: tensor(0.4927)\n",
      "4552 Traning Loss: tensor(0.4925)\n",
      "4553 Traning Loss: tensor(0.4923)\n",
      "4554 Traning Loss: tensor(0.4922)\n",
      "4555 Traning Loss: tensor(0.4920)\n",
      "4556 Traning Loss: tensor(0.4918)\n",
      "4557 Traning Loss: tensor(0.4916)\n",
      "4558 Traning Loss: tensor(0.4914)\n",
      "4559 Traning Loss: tensor(0.4912)\n",
      "4560 Traning Loss: tensor(0.4911)\n",
      "4561 Traning Loss: tensor(0.4909)\n",
      "4562 Traning Loss: tensor(0.4907)\n",
      "4563 Traning Loss: tensor(0.4905)\n",
      "4564 Traning Loss: tensor(0.4903)\n",
      "4565 Traning Loss: tensor(0.4901)\n",
      "4566 Traning Loss: tensor(0.4900)\n",
      "4567 Traning Loss: tensor(0.4898)\n",
      "4568 Traning Loss: tensor(0.4896)\n",
      "4569 Traning Loss: tensor(0.4894)\n",
      "4570 Traning Loss: tensor(0.4892)\n",
      "4571 Traning Loss: tensor(0.4890)\n",
      "4572 Traning Loss: tensor(0.4889)\n",
      "4573 Traning Loss: tensor(0.4887)\n",
      "4574 Traning Loss: tensor(0.4885)\n",
      "4575 Traning Loss: tensor(0.4883)\n",
      "4576 Traning Loss: tensor(0.4881)\n",
      "4577 Traning Loss: tensor(0.4880)\n",
      "4578 Traning Loss: tensor(0.4878)\n",
      "4579 Traning Loss: tensor(0.4876)\n",
      "4580 Traning Loss: tensor(0.4874)\n",
      "4581 Traning Loss: tensor(0.4872)\n",
      "4582 Traning Loss: tensor(0.4871)\n",
      "4583 Traning Loss: tensor(0.4869)\n",
      "4584 Traning Loss: tensor(0.4867)\n",
      "4585 Traning Loss: tensor(0.4865)\n",
      "4586 Traning Loss: tensor(0.4864)\n",
      "4587 Traning Loss: tensor(0.4862)\n",
      "4588 Traning Loss: tensor(0.4860)\n",
      "4589 Traning Loss: tensor(0.4858)\n",
      "4590 Traning Loss: tensor(0.4856)\n",
      "4591 Traning Loss: tensor(0.4855)\n",
      "4592 Traning Loss: tensor(0.4853)\n",
      "4593 Traning Loss: tensor(0.4851)\n",
      "4594 Traning Loss: tensor(0.4849)\n",
      "4595 Traning Loss: tensor(0.4848)\n",
      "4596 Traning Loss: tensor(0.4846)\n",
      "4597 Traning Loss: tensor(0.4844)\n",
      "4598 Traning Loss: tensor(0.4842)\n",
      "4599 Traning Loss: tensor(0.4841)\n",
      "4600 Traning Loss: tensor(0.4839)\n",
      "4601 Traning Loss: tensor(0.4837)\n",
      "4602 Traning Loss: tensor(0.4835)\n",
      "4603 Traning Loss: tensor(0.4834)\n",
      "4604 Traning Loss: tensor(0.4832)\n",
      "4605 Traning Loss: tensor(0.4830)\n",
      "4606 Traning Loss: tensor(0.4828)\n",
      "4607 Traning Loss: tensor(0.4827)\n",
      "4608 Traning Loss: tensor(0.4825)\n",
      "4609 Traning Loss: tensor(0.4823)\n",
      "4610 Traning Loss: tensor(0.4822)\n",
      "4611 Traning Loss: tensor(0.4820)\n",
      "4612 Traning Loss: tensor(0.4818)\n",
      "4613 Traning Loss: tensor(0.4816)\n",
      "4614 Traning Loss: tensor(0.4815)\n",
      "4615 Traning Loss: tensor(0.4813)\n",
      "4616 Traning Loss: tensor(0.4811)\n",
      "4617 Traning Loss: tensor(0.4809)\n",
      "4618 Traning Loss: tensor(0.4808)\n",
      "4619 Traning Loss: tensor(0.4806)\n",
      "4620 Traning Loss: tensor(0.4804)\n",
      "4621 Traning Loss: tensor(0.4803)\n",
      "4622 Traning Loss: tensor(0.4801)\n",
      "4623 Traning Loss: tensor(0.4799)\n",
      "4624 Traning Loss: tensor(0.4798)\n",
      "4625 Traning Loss: tensor(0.4796)\n",
      "4626 Traning Loss: tensor(0.4794)\n",
      "4627 Traning Loss: tensor(0.4793)\n",
      "4628 Traning Loss: tensor(0.4791)\n",
      "4629 Traning Loss: tensor(0.4789)\n",
      "4630 Traning Loss: tensor(0.4788)\n",
      "4631 Traning Loss: tensor(0.4786)\n",
      "4632 Traning Loss: tensor(0.4785)\n",
      "4633 Traning Loss: tensor(0.4783)\n",
      "4634 Traning Loss: tensor(0.4782)\n",
      "4635 Traning Loss: tensor(0.4780)\n",
      "4636 Traning Loss: tensor(0.4778)\n",
      "4637 Traning Loss: tensor(0.4776)\n",
      "4638 Traning Loss: tensor(0.4774)\n",
      "4639 Traning Loss: tensor(0.4772)\n",
      "4640 Traning Loss: tensor(0.4771)\n",
      "4641 Traning Loss: tensor(0.4769)\n",
      "4642 Traning Loss: tensor(0.4768)\n",
      "4643 Traning Loss: tensor(0.4766)\n",
      "4644 Traning Loss: tensor(0.4764)\n",
      "4645 Traning Loss: tensor(0.4763)\n",
      "4646 Traning Loss: tensor(0.4761)\n",
      "4647 Traning Loss: tensor(0.4759)\n",
      "4648 Traning Loss: tensor(0.4758)\n",
      "4649 Traning Loss: tensor(0.4756)\n",
      "4650 Traning Loss: tensor(0.4755)\n",
      "4651 Traning Loss: tensor(0.4753)\n",
      "4652 Traning Loss: tensor(0.4751)\n",
      "4653 Traning Loss: tensor(0.4750)\n",
      "4654 Traning Loss: tensor(0.4748)\n",
      "4655 Traning Loss: tensor(0.4746)\n",
      "4656 Traning Loss: tensor(0.4745)\n",
      "4657 Traning Loss: tensor(0.4743)\n",
      "4658 Traning Loss: tensor(0.4741)\n",
      "4659 Traning Loss: tensor(0.4740)\n",
      "4660 Traning Loss: tensor(0.4738)\n",
      "4661 Traning Loss: tensor(0.4737)\n",
      "4662 Traning Loss: tensor(0.4735)\n",
      "4663 Traning Loss: tensor(0.4733)\n",
      "4664 Traning Loss: tensor(0.4732)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4665 Traning Loss: tensor(0.4730)\n",
      "4666 Traning Loss: tensor(0.4729)\n",
      "4667 Traning Loss: tensor(0.4727)\n",
      "4668 Traning Loss: tensor(0.4725)\n",
      "4669 Traning Loss: tensor(0.4724)\n",
      "4670 Traning Loss: tensor(0.4722)\n",
      "4671 Traning Loss: tensor(0.4721)\n",
      "4672 Traning Loss: tensor(0.4719)\n",
      "4673 Traning Loss: tensor(0.4717)\n",
      "4674 Traning Loss: tensor(0.4716)\n",
      "4675 Traning Loss: tensor(0.4714)\n",
      "4676 Traning Loss: tensor(0.4713)\n",
      "4677 Traning Loss: tensor(0.4711)\n",
      "4678 Traning Loss: tensor(0.4710)\n",
      "4679 Traning Loss: tensor(0.4708)\n",
      "4680 Traning Loss: tensor(0.4706)\n",
      "4681 Traning Loss: tensor(0.4705)\n",
      "4682 Traning Loss: tensor(0.4703)\n",
      "4683 Traning Loss: tensor(0.4702)\n",
      "4684 Traning Loss: tensor(0.4700)\n",
      "4685 Traning Loss: tensor(0.4699)\n",
      "4686 Traning Loss: tensor(0.4697)\n",
      "4687 Traning Loss: tensor(0.4695)\n",
      "4688 Traning Loss: tensor(0.4694)\n",
      "4689 Traning Loss: tensor(0.4692)\n",
      "4690 Traning Loss: tensor(0.4691)\n",
      "4691 Traning Loss: tensor(0.4689)\n",
      "4692 Traning Loss: tensor(0.4688)\n",
      "4693 Traning Loss: tensor(0.4686)\n",
      "4694 Traning Loss: tensor(0.4685)\n",
      "4695 Traning Loss: tensor(0.4683)\n",
      "4696 Traning Loss: tensor(0.4682)\n",
      "4697 Traning Loss: tensor(0.4680)\n",
      "4698 Traning Loss: tensor(0.4678)\n",
      "4699 Traning Loss: tensor(0.4677)\n",
      "4700 Traning Loss: tensor(0.4675)\n",
      "4701 Traning Loss: tensor(0.4674)\n",
      "4702 Traning Loss: tensor(0.4672)\n",
      "4703 Traning Loss: tensor(0.4671)\n",
      "4704 Traning Loss: tensor(0.4669)\n",
      "4705 Traning Loss: tensor(0.4668)\n",
      "4706 Traning Loss: tensor(0.4666)\n",
      "4707 Traning Loss: tensor(0.4665)\n",
      "4708 Traning Loss: tensor(0.4663)\n",
      "4709 Traning Loss: tensor(0.4662)\n",
      "4710 Traning Loss: tensor(0.4660)\n",
      "4711 Traning Loss: tensor(0.4658)\n",
      "4712 Traning Loss: tensor(0.4657)\n",
      "4713 Traning Loss: tensor(0.4655)\n",
      "4714 Traning Loss: tensor(0.4654)\n",
      "4715 Traning Loss: tensor(0.4652)\n",
      "4716 Traning Loss: tensor(0.4651)\n",
      "4717 Traning Loss: tensor(0.4649)\n",
      "4718 Traning Loss: tensor(0.4648)\n",
      "4719 Traning Loss: tensor(0.4646)\n",
      "4720 Traning Loss: tensor(0.4645)\n",
      "4721 Traning Loss: tensor(0.4643)\n",
      "4722 Traning Loss: tensor(0.4642)\n",
      "4723 Traning Loss: tensor(0.4640)\n",
      "4724 Traning Loss: tensor(0.4639)\n",
      "4725 Traning Loss: tensor(0.4637)\n",
      "4726 Traning Loss: tensor(0.4636)\n",
      "4727 Traning Loss: tensor(0.4634)\n",
      "4728 Traning Loss: tensor(0.4633)\n",
      "4729 Traning Loss: tensor(0.4631)\n",
      "4730 Traning Loss: tensor(0.4630)\n",
      "4731 Traning Loss: tensor(0.4628)\n",
      "4732 Traning Loss: tensor(0.4627)\n",
      "4733 Traning Loss: tensor(0.4625)\n",
      "4734 Traning Loss: tensor(0.4624)\n",
      "4735 Traning Loss: tensor(0.4622)\n",
      "4736 Traning Loss: tensor(0.4621)\n",
      "4737 Traning Loss: tensor(0.4619)\n",
      "4738 Traning Loss: tensor(0.4618)\n",
      "4739 Traning Loss: tensor(0.4616)\n",
      "4740 Traning Loss: tensor(0.4615)\n",
      "4741 Traning Loss: tensor(0.4613)\n",
      "4742 Traning Loss: tensor(0.4612)\n",
      "4743 Traning Loss: tensor(0.4610)\n",
      "4744 Traning Loss: tensor(0.4609)\n",
      "4745 Traning Loss: tensor(0.4607)\n",
      "4746 Traning Loss: tensor(0.4606)\n",
      "4747 Traning Loss: tensor(0.4604)\n",
      "4748 Traning Loss: tensor(0.4603)\n",
      "4749 Traning Loss: tensor(0.4601)\n",
      "4750 Traning Loss: tensor(0.4600)\n",
      "4751 Traning Loss: tensor(0.4599)\n",
      "4752 Traning Loss: tensor(0.4597)\n",
      "4753 Traning Loss: tensor(0.4596)\n",
      "4754 Traning Loss: tensor(0.4594)\n",
      "4755 Traning Loss: tensor(0.4593)\n",
      "4756 Traning Loss: tensor(0.4591)\n",
      "4757 Traning Loss: tensor(0.4590)\n",
      "4758 Traning Loss: tensor(0.4588)\n",
      "4759 Traning Loss: tensor(0.4587)\n",
      "4760 Traning Loss: tensor(0.4585)\n",
      "4761 Traning Loss: tensor(0.4584)\n",
      "4762 Traning Loss: tensor(0.4582)\n",
      "4763 Traning Loss: tensor(0.4581)\n",
      "4764 Traning Loss: tensor(0.4579)\n",
      "4765 Traning Loss: tensor(0.4578)\n",
      "4766 Traning Loss: tensor(0.4577)\n",
      "4767 Traning Loss: tensor(0.4575)\n",
      "4768 Traning Loss: tensor(0.4574)\n",
      "4769 Traning Loss: tensor(0.4572)\n",
      "4770 Traning Loss: tensor(0.4571)\n",
      "4771 Traning Loss: tensor(0.4569)\n",
      "4772 Traning Loss: tensor(0.4568)\n",
      "4773 Traning Loss: tensor(0.4566)\n",
      "4774 Traning Loss: tensor(0.4565)\n",
      "4775 Traning Loss: tensor(0.4563)\n",
      "4776 Traning Loss: tensor(0.4562)\n",
      "4777 Traning Loss: tensor(0.4561)\n",
      "4778 Traning Loss: tensor(0.4559)\n",
      "4779 Traning Loss: tensor(0.4558)\n",
      "4780 Traning Loss: tensor(0.4556)\n",
      "4781 Traning Loss: tensor(0.4555)\n",
      "4782 Traning Loss: tensor(0.4553)\n",
      "4783 Traning Loss: tensor(0.4552)\n",
      "4784 Traning Loss: tensor(0.4550)\n",
      "4785 Traning Loss: tensor(0.4549)\n",
      "4786 Traning Loss: tensor(0.4548)\n",
      "4787 Traning Loss: tensor(0.4546)\n",
      "4788 Traning Loss: tensor(0.4545)\n",
      "4789 Traning Loss: tensor(0.4543)\n",
      "4790 Traning Loss: tensor(0.4542)\n",
      "4791 Traning Loss: tensor(0.4540)\n",
      "4792 Traning Loss: tensor(0.4539)\n",
      "4793 Traning Loss: tensor(0.4537)\n",
      "4794 Traning Loss: tensor(0.4536)\n",
      "4795 Traning Loss: tensor(0.4535)\n",
      "4796 Traning Loss: tensor(0.4533)\n",
      "4797 Traning Loss: tensor(0.4532)\n",
      "4798 Traning Loss: tensor(0.4530)\n",
      "4799 Traning Loss: tensor(0.4529)\n",
      "4800 Traning Loss: tensor(0.4527)\n",
      "4801 Traning Loss: tensor(0.4526)\n",
      "4802 Traning Loss: tensor(0.4525)\n",
      "4803 Traning Loss: tensor(0.4523)\n",
      "4804 Traning Loss: tensor(0.4522)\n",
      "4805 Traning Loss: tensor(0.4520)\n",
      "4806 Traning Loss: tensor(0.4519)\n",
      "4807 Traning Loss: tensor(0.4517)\n",
      "4808 Traning Loss: tensor(0.4516)\n",
      "4809 Traning Loss: tensor(0.4515)\n",
      "4810 Traning Loss: tensor(0.4513)\n",
      "4811 Traning Loss: tensor(0.4512)\n",
      "4812 Traning Loss: tensor(0.4510)\n",
      "4813 Traning Loss: tensor(0.4509)\n",
      "4814 Traning Loss: tensor(0.4507)\n",
      "4815 Traning Loss: tensor(0.4506)\n",
      "4816 Traning Loss: tensor(0.4505)\n",
      "4817 Traning Loss: tensor(0.4503)\n",
      "4818 Traning Loss: tensor(0.4502)\n",
      "4819 Traning Loss: tensor(0.4501)\n",
      "4820 Traning Loss: tensor(0.4500)\n",
      "4821 Traning Loss: tensor(0.4499)\n",
      "4822 Traning Loss: tensor(0.4497)\n",
      "4823 Traning Loss: tensor(0.4496)\n",
      "4824 Traning Loss: tensor(0.4494)\n",
      "4825 Traning Loss: tensor(0.4492)\n",
      "4826 Traning Loss: tensor(0.4490)\n",
      "4827 Traning Loss: tensor(0.4489)\n",
      "4828 Traning Loss: tensor(0.4488)\n",
      "4829 Traning Loss: tensor(0.4487)\n",
      "4830 Traning Loss: tensor(0.4485)\n",
      "4831 Traning Loss: tensor(0.4484)\n",
      "4832 Traning Loss: tensor(0.4482)\n",
      "4833 Traning Loss: tensor(0.4481)\n",
      "4834 Traning Loss: tensor(0.4479)\n",
      "4835 Traning Loss: tensor(0.4478)\n",
      "4836 Traning Loss: tensor(0.4477)\n",
      "4837 Traning Loss: tensor(0.4475)\n",
      "4838 Traning Loss: tensor(0.4474)\n",
      "4839 Traning Loss: tensor(0.4472)\n",
      "4840 Traning Loss: tensor(0.4471)\n",
      "4841 Traning Loss: tensor(0.4470)\n",
      "4842 Traning Loss: tensor(0.4468)\n",
      "4843 Traning Loss: tensor(0.4467)\n",
      "4844 Traning Loss: tensor(0.4465)\n",
      "4845 Traning Loss: tensor(0.4464)\n",
      "4846 Traning Loss: tensor(0.4463)\n",
      "4847 Traning Loss: tensor(0.4461)\n",
      "4848 Traning Loss: tensor(0.4460)\n",
      "4849 Traning Loss: tensor(0.4458)\n",
      "4850 Traning Loss: tensor(0.4457)\n",
      "4851 Traning Loss: tensor(0.4456)\n",
      "4852 Traning Loss: tensor(0.4454)\n",
      "4853 Traning Loss: tensor(0.4453)\n",
      "4854 Traning Loss: tensor(0.4451)\n",
      "4855 Traning Loss: tensor(0.4450)\n",
      "4856 Traning Loss: tensor(0.4449)\n",
      "4857 Traning Loss: tensor(0.4447)\n",
      "4858 Traning Loss: tensor(0.4446)\n",
      "4859 Traning Loss: tensor(0.4445)\n",
      "4860 Traning Loss: tensor(0.4443)\n",
      "4861 Traning Loss: tensor(0.4442)\n",
      "4862 Traning Loss: tensor(0.4440)\n",
      "4863 Traning Loss: tensor(0.4439)\n",
      "4864 Traning Loss: tensor(0.4438)\n",
      "4865 Traning Loss: tensor(0.4436)\n",
      "4866 Traning Loss: tensor(0.4435)\n",
      "4867 Traning Loss: tensor(0.4433)\n",
      "4868 Traning Loss: tensor(0.4432)\n",
      "4869 Traning Loss: tensor(0.4431)\n",
      "4870 Traning Loss: tensor(0.4429)\n",
      "4871 Traning Loss: tensor(0.4428)\n",
      "4872 Traning Loss: tensor(0.4427)\n",
      "4873 Traning Loss: tensor(0.4425)\n",
      "4874 Traning Loss: tensor(0.4424)\n",
      "4875 Traning Loss: tensor(0.4422)\n",
      "4876 Traning Loss: tensor(0.4421)\n",
      "4877 Traning Loss: tensor(0.4420)\n",
      "4878 Traning Loss: tensor(0.4418)\n",
      "4879 Traning Loss: tensor(0.4417)\n",
      "4880 Traning Loss: tensor(0.4415)\n",
      "4881 Traning Loss: tensor(0.4414)\n",
      "4882 Traning Loss: tensor(0.4413)\n",
      "4883 Traning Loss: tensor(0.4411)\n",
      "4884 Traning Loss: tensor(0.4410)\n",
      "4885 Traning Loss: tensor(0.4409)\n",
      "4886 Traning Loss: tensor(0.4407)\n",
      "4887 Traning Loss: tensor(0.4406)\n",
      "4888 Traning Loss: tensor(0.4404)\n",
      "4889 Traning Loss: tensor(0.4403)\n",
      "4890 Traning Loss: tensor(0.4402)\n",
      "4891 Traning Loss: tensor(0.4400)\n",
      "4892 Traning Loss: tensor(0.4399)\n",
      "4893 Traning Loss: tensor(0.4397)\n",
      "4894 Traning Loss: tensor(0.4396)\n",
      "4895 Traning Loss: tensor(0.4395)\n",
      "4896 Traning Loss: tensor(0.4393)\n",
      "4897 Traning Loss: tensor(0.4392)\n",
      "4898 Traning Loss: tensor(0.4391)\n",
      "4899 Traning Loss: tensor(0.4389)\n",
      "4900 Traning Loss: tensor(0.4388)\n",
      "4901 Traning Loss: tensor(0.4386)\n",
      "4902 Traning Loss: tensor(0.4385)\n",
      "4903 Traning Loss: tensor(0.4384)\n",
      "4904 Traning Loss: tensor(0.4382)\n",
      "4905 Traning Loss: tensor(0.4381)\n",
      "4906 Traning Loss: tensor(0.4379)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4907 Traning Loss: tensor(0.4378)\n",
      "4908 Traning Loss: tensor(0.4377)\n",
      "4909 Traning Loss: tensor(0.4375)\n",
      "4910 Traning Loss: tensor(0.4374)\n",
      "4911 Traning Loss: tensor(0.4372)\n",
      "4912 Traning Loss: tensor(0.4371)\n",
      "4913 Traning Loss: tensor(0.4370)\n",
      "4914 Traning Loss: tensor(0.4368)\n",
      "4915 Traning Loss: tensor(0.4367)\n",
      "4916 Traning Loss: tensor(0.4366)\n",
      "4917 Traning Loss: tensor(0.4364)\n",
      "4918 Traning Loss: tensor(0.4363)\n",
      "4919 Traning Loss: tensor(0.4361)\n",
      "4920 Traning Loss: tensor(0.4360)\n",
      "4921 Traning Loss: tensor(0.4359)\n",
      "4922 Traning Loss: tensor(0.4357)\n",
      "4923 Traning Loss: tensor(0.4356)\n",
      "4924 Traning Loss: tensor(0.4354)\n",
      "4925 Traning Loss: tensor(0.4353)\n",
      "4926 Traning Loss: tensor(0.4352)\n",
      "4927 Traning Loss: tensor(0.4350)\n",
      "4928 Traning Loss: tensor(0.4349)\n",
      "4929 Traning Loss: tensor(0.4347)\n",
      "4930 Traning Loss: tensor(0.4346)\n",
      "4931 Traning Loss: tensor(0.4345)\n",
      "4932 Traning Loss: tensor(0.4343)\n",
      "4933 Traning Loss: tensor(0.4342)\n",
      "4934 Traning Loss: tensor(0.4340)\n",
      "4935 Traning Loss: tensor(0.4339)\n",
      "4936 Traning Loss: tensor(0.4338)\n",
      "4937 Traning Loss: tensor(0.4336)\n",
      "4938 Traning Loss: tensor(0.4335)\n",
      "4939 Traning Loss: tensor(0.4333)\n",
      "4940 Traning Loss: tensor(0.4332)\n",
      "4941 Traning Loss: tensor(0.4331)\n",
      "4942 Traning Loss: tensor(0.4329)\n",
      "4943 Traning Loss: tensor(0.4328)\n",
      "4944 Traning Loss: tensor(0.4326)\n",
      "4945 Traning Loss: tensor(0.4325)\n",
      "4946 Traning Loss: tensor(0.4324)\n",
      "4947 Traning Loss: tensor(0.4322)\n",
      "4948 Traning Loss: tensor(0.4321)\n",
      "4949 Traning Loss: tensor(0.4319)\n",
      "4950 Traning Loss: tensor(0.4318)\n",
      "4951 Traning Loss: tensor(0.4317)\n",
      "4952 Traning Loss: tensor(0.4315)\n",
      "4953 Traning Loss: tensor(0.4314)\n",
      "4954 Traning Loss: tensor(0.4312)\n",
      "4955 Traning Loss: tensor(0.4311)\n",
      "4956 Traning Loss: tensor(0.4310)\n",
      "4957 Traning Loss: tensor(0.4308)\n",
      "4958 Traning Loss: tensor(0.4307)\n",
      "4959 Traning Loss: tensor(0.4305)\n",
      "4960 Traning Loss: tensor(0.4304)\n",
      "4961 Traning Loss: tensor(0.4303)\n",
      "4962 Traning Loss: tensor(0.4301)\n",
      "4963 Traning Loss: tensor(0.4300)\n",
      "4964 Traning Loss: tensor(0.4298)\n",
      "4965 Traning Loss: tensor(0.4297)\n",
      "4966 Traning Loss: tensor(0.4295)\n",
      "4967 Traning Loss: tensor(0.4294)\n",
      "4968 Traning Loss: tensor(0.4293)\n",
      "4969 Traning Loss: tensor(0.4291)\n",
      "4970 Traning Loss: tensor(0.4290)\n",
      "4971 Traning Loss: tensor(0.4288)\n",
      "4972 Traning Loss: tensor(0.4287)\n",
      "4973 Traning Loss: tensor(0.4286)\n",
      "4974 Traning Loss: tensor(0.4284)\n",
      "4975 Traning Loss: tensor(0.4283)\n",
      "4976 Traning Loss: tensor(0.4281)\n",
      "4977 Traning Loss: tensor(0.4280)\n",
      "4978 Traning Loss: tensor(0.4278)\n",
      "4979 Traning Loss: tensor(0.4277)\n",
      "4980 Traning Loss: tensor(0.4276)\n",
      "4981 Traning Loss: tensor(0.4274)\n",
      "4982 Traning Loss: tensor(0.4273)\n",
      "4983 Traning Loss: tensor(0.4271)\n",
      "4984 Traning Loss: tensor(0.4270)\n",
      "4985 Traning Loss: tensor(0.4268)\n",
      "4986 Traning Loss: tensor(0.4267)\n",
      "4987 Traning Loss: tensor(0.4266)\n",
      "4988 Traning Loss: tensor(0.4264)\n",
      "4989 Traning Loss: tensor(0.4263)\n",
      "4990 Traning Loss: tensor(0.4261)\n",
      "4991 Traning Loss: tensor(0.4260)\n",
      "4992 Traning Loss: tensor(0.4259)\n",
      "4993 Traning Loss: tensor(0.4257)\n",
      "4994 Traning Loss: tensor(0.4256)\n",
      "4995 Traning Loss: tensor(0.4255)\n",
      "4996 Traning Loss: tensor(0.4254)\n",
      "4997 Traning Loss: tensor(0.4253)\n",
      "4998 Traning Loss: tensor(0.4251)\n",
      "4999 Traning Loss: tensor(0.4250)\n",
      "5000 Traning Loss: tensor(0.4248)\n",
      "5001 Traning Loss: tensor(0.4246)\n",
      "5002 Traning Loss: tensor(0.4244)\n",
      "5003 Traning Loss: tensor(0.4243)\n",
      "5004 Traning Loss: tensor(0.4242)\n",
      "5005 Traning Loss: tensor(0.4240)\n",
      "5006 Traning Loss: tensor(0.4239)\n",
      "5007 Traning Loss: tensor(0.4237)\n",
      "5008 Traning Loss: tensor(0.4236)\n",
      "5009 Traning Loss: tensor(0.4234)\n",
      "5010 Traning Loss: tensor(0.4233)\n",
      "5011 Traning Loss: tensor(0.4232)\n",
      "5012 Traning Loss: tensor(0.4230)\n",
      "5013 Traning Loss: tensor(0.4229)\n",
      "5014 Traning Loss: tensor(0.4227)\n",
      "5015 Traning Loss: tensor(0.4226)\n",
      "5016 Traning Loss: tensor(0.4224)\n",
      "5017 Traning Loss: tensor(0.4223)\n",
      "5018 Traning Loss: tensor(0.4221)\n",
      "5019 Traning Loss: tensor(0.4220)\n",
      "5020 Traning Loss: tensor(0.4219)\n",
      "5021 Traning Loss: tensor(0.4217)\n",
      "5022 Traning Loss: tensor(0.4216)\n",
      "5023 Traning Loss: tensor(0.4214)\n",
      "5024 Traning Loss: tensor(0.4213)\n",
      "5025 Traning Loss: tensor(0.4211)\n",
      "5026 Traning Loss: tensor(0.4210)\n",
      "5027 Traning Loss: tensor(0.4208)\n",
      "5028 Traning Loss: tensor(0.4207)\n",
      "5029 Traning Loss: tensor(0.4205)\n",
      "5030 Traning Loss: tensor(0.4204)\n",
      "5031 Traning Loss: tensor(0.4203)\n",
      "5032 Traning Loss: tensor(0.4201)\n",
      "5033 Traning Loss: tensor(0.4200)\n",
      "5034 Traning Loss: tensor(0.4198)\n",
      "5035 Traning Loss: tensor(0.4197)\n",
      "5036 Traning Loss: tensor(0.4195)\n",
      "5037 Traning Loss: tensor(0.4194)\n",
      "5038 Traning Loss: tensor(0.4192)\n",
      "5039 Traning Loss: tensor(0.4191)\n",
      "5040 Traning Loss: tensor(0.4189)\n",
      "5041 Traning Loss: tensor(0.4188)\n",
      "5042 Traning Loss: tensor(0.4187)\n",
      "5043 Traning Loss: tensor(0.4185)\n",
      "5044 Traning Loss: tensor(0.4184)\n",
      "5045 Traning Loss: tensor(0.4182)\n",
      "5046 Traning Loss: tensor(0.4181)\n",
      "5047 Traning Loss: tensor(0.4179)\n",
      "5048 Traning Loss: tensor(0.4178)\n",
      "5049 Traning Loss: tensor(0.4176)\n",
      "5050 Traning Loss: tensor(0.4175)\n",
      "5051 Traning Loss: tensor(0.4173)\n",
      "5052 Traning Loss: tensor(0.4172)\n",
      "5053 Traning Loss: tensor(0.4170)\n",
      "5054 Traning Loss: tensor(0.4169)\n",
      "5055 Traning Loss: tensor(0.4167)\n",
      "5056 Traning Loss: tensor(0.4166)\n",
      "5057 Traning Loss: tensor(0.4164)\n",
      "5058 Traning Loss: tensor(0.4163)\n",
      "5059 Traning Loss: tensor(0.4161)\n",
      "5060 Traning Loss: tensor(0.4160)\n",
      "5061 Traning Loss: tensor(0.4158)\n",
      "5062 Traning Loss: tensor(0.4157)\n",
      "5063 Traning Loss: tensor(0.4155)\n",
      "5064 Traning Loss: tensor(0.4154)\n",
      "5065 Traning Loss: tensor(0.4152)\n",
      "5066 Traning Loss: tensor(0.4151)\n",
      "5067 Traning Loss: tensor(0.4149)\n",
      "5068 Traning Loss: tensor(0.4148)\n",
      "5069 Traning Loss: tensor(0.4146)\n",
      "5070 Traning Loss: tensor(0.4145)\n",
      "5071 Traning Loss: tensor(0.4143)\n",
      "5072 Traning Loss: tensor(0.4142)\n",
      "5073 Traning Loss: tensor(0.4140)\n",
      "5074 Traning Loss: tensor(0.4139)\n",
      "5075 Traning Loss: tensor(0.4137)\n",
      "5076 Traning Loss: tensor(0.4136)\n",
      "5077 Traning Loss: tensor(0.4134)\n",
      "5078 Traning Loss: tensor(0.4133)\n",
      "5079 Traning Loss: tensor(0.4131)\n",
      "5080 Traning Loss: tensor(0.4130)\n",
      "5081 Traning Loss: tensor(0.4128)\n",
      "5082 Traning Loss: tensor(0.4127)\n",
      "5083 Traning Loss: tensor(0.4125)\n",
      "5084 Traning Loss: tensor(0.4124)\n",
      "5085 Traning Loss: tensor(0.4122)\n",
      "5086 Traning Loss: tensor(0.4121)\n",
      "5087 Traning Loss: tensor(0.4119)\n",
      "5088 Traning Loss: tensor(0.4117)\n",
      "5089 Traning Loss: tensor(0.4116)\n",
      "5090 Traning Loss: tensor(0.4114)\n",
      "5091 Traning Loss: tensor(0.4113)\n",
      "5092 Traning Loss: tensor(0.4111)\n",
      "5093 Traning Loss: tensor(0.4110)\n",
      "5094 Traning Loss: tensor(0.4108)\n",
      "5095 Traning Loss: tensor(0.4107)\n",
      "5096 Traning Loss: tensor(0.4105)\n",
      "5097 Traning Loss: tensor(0.4103)\n",
      "5098 Traning Loss: tensor(0.4102)\n",
      "5099 Traning Loss: tensor(0.4100)\n",
      "5100 Traning Loss: tensor(0.4099)\n",
      "5101 Traning Loss: tensor(0.4097)\n",
      "5102 Traning Loss: tensor(0.4096)\n",
      "5103 Traning Loss: tensor(0.4094)\n",
      "5104 Traning Loss: tensor(0.4092)\n",
      "5105 Traning Loss: tensor(0.4091)\n",
      "5106 Traning Loss: tensor(0.4089)\n",
      "5107 Traning Loss: tensor(0.4088)\n",
      "5108 Traning Loss: tensor(0.4086)\n",
      "5109 Traning Loss: tensor(0.4084)\n",
      "5110 Traning Loss: tensor(0.4083)\n",
      "5111 Traning Loss: tensor(0.4081)\n",
      "5112 Traning Loss: tensor(0.4080)\n",
      "5113 Traning Loss: tensor(0.4078)\n",
      "5114 Traning Loss: tensor(0.4076)\n",
      "5115 Traning Loss: tensor(0.4075)\n",
      "5116 Traning Loss: tensor(0.4073)\n",
      "5117 Traning Loss: tensor(0.4072)\n",
      "5118 Traning Loss: tensor(0.4070)\n",
      "5119 Traning Loss: tensor(0.4068)\n",
      "5120 Traning Loss: tensor(0.4067)\n",
      "5121 Traning Loss: tensor(0.4065)\n",
      "5122 Traning Loss: tensor(0.4063)\n",
      "5123 Traning Loss: tensor(0.4062)\n",
      "5124 Traning Loss: tensor(0.4060)\n",
      "5125 Traning Loss: tensor(0.4059)\n",
      "5126 Traning Loss: tensor(0.4057)\n",
      "5127 Traning Loss: tensor(0.4055)\n",
      "5128 Traning Loss: tensor(0.4054)\n",
      "5129 Traning Loss: tensor(0.4052)\n",
      "5130 Traning Loss: tensor(0.4050)\n",
      "5131 Traning Loss: tensor(0.4049)\n",
      "5132 Traning Loss: tensor(0.4047)\n",
      "5133 Traning Loss: tensor(0.4045)\n",
      "5134 Traning Loss: tensor(0.4044)\n",
      "5135 Traning Loss: tensor(0.4042)\n",
      "5136 Traning Loss: tensor(0.4040)\n",
      "5137 Traning Loss: tensor(0.4039)\n",
      "5138 Traning Loss: tensor(0.4037)\n",
      "5139 Traning Loss: tensor(0.4035)\n",
      "5140 Traning Loss: tensor(0.4034)\n",
      "5141 Traning Loss: tensor(0.4032)\n",
      "5142 Traning Loss: tensor(0.4030)\n",
      "5143 Traning Loss: tensor(0.4028)\n",
      "5144 Traning Loss: tensor(0.4027)\n",
      "5145 Traning Loss: tensor(0.4025)\n",
      "5146 Traning Loss: tensor(0.4023)\n",
      "5147 Traning Loss: tensor(0.4022)\n",
      "5148 Traning Loss: tensor(0.4020)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5149 Traning Loss: tensor(0.4018)\n",
      "5150 Traning Loss: tensor(0.4016)\n",
      "5151 Traning Loss: tensor(0.4015)\n",
      "5152 Traning Loss: tensor(0.4013)\n",
      "5153 Traning Loss: tensor(0.4011)\n",
      "5154 Traning Loss: tensor(0.4009)\n",
      "5155 Traning Loss: tensor(0.4008)\n",
      "5156 Traning Loss: tensor(0.4006)\n",
      "5157 Traning Loss: tensor(0.4004)\n",
      "5158 Traning Loss: tensor(0.4002)\n",
      "5159 Traning Loss: tensor(0.4001)\n",
      "5160 Traning Loss: tensor(0.3999)\n",
      "5161 Traning Loss: tensor(0.3997)\n",
      "5162 Traning Loss: tensor(0.3996)\n",
      "5163 Traning Loss: tensor(0.3994)\n",
      "5164 Traning Loss: tensor(0.3993)\n",
      "5165 Traning Loss: tensor(0.3993)\n",
      "5166 Traning Loss: tensor(0.3992)\n",
      "5167 Traning Loss: tensor(0.3990)\n",
      "5168 Traning Loss: tensor(0.3988)\n",
      "5169 Traning Loss: tensor(0.3984)\n",
      "5170 Traning Loss: tensor(0.3981)\n",
      "5171 Traning Loss: tensor(0.3980)\n",
      "5172 Traning Loss: tensor(0.3979)\n",
      "5173 Traning Loss: tensor(0.3977)\n",
      "5174 Traning Loss: tensor(0.3975)\n",
      "5175 Traning Loss: tensor(0.3972)\n",
      "5176 Traning Loss: tensor(0.3970)\n",
      "5177 Traning Loss: tensor(0.3969)\n",
      "5178 Traning Loss: tensor(0.3968)\n",
      "5179 Traning Loss: tensor(0.3965)\n",
      "5180 Traning Loss: tensor(0.3963)\n",
      "5181 Traning Loss: tensor(0.3961)\n",
      "5182 Traning Loss: tensor(0.3960)\n",
      "5183 Traning Loss: tensor(0.3958)\n",
      "5184 Traning Loss: tensor(0.3956)\n",
      "5185 Traning Loss: tensor(0.3953)\n",
      "5186 Traning Loss: tensor(0.3952)\n",
      "5187 Traning Loss: tensor(0.3950)\n",
      "5188 Traning Loss: tensor(0.3948)\n",
      "5189 Traning Loss: tensor(0.3946)\n",
      "5190 Traning Loss: tensor(0.3944)\n",
      "5191 Traning Loss: tensor(0.3942)\n",
      "5192 Traning Loss: tensor(0.3940)\n",
      "5193 Traning Loss: tensor(0.3938)\n",
      "5194 Traning Loss: tensor(0.3936)\n",
      "5195 Traning Loss: tensor(0.3934)\n",
      "5196 Traning Loss: tensor(0.3932)\n",
      "5197 Traning Loss: tensor(0.3931)\n",
      "5198 Traning Loss: tensor(0.3929)\n",
      "5199 Traning Loss: tensor(0.3926)\n",
      "5200 Traning Loss: tensor(0.3924)\n",
      "5201 Traning Loss: tensor(0.3923)\n",
      "5202 Traning Loss: tensor(0.3921)\n",
      "5203 Traning Loss: tensor(0.3918)\n",
      "5204 Traning Loss: tensor(0.3916)\n",
      "5205 Traning Loss: tensor(0.3914)\n",
      "5206 Traning Loss: tensor(0.3912)\n",
      "5207 Traning Loss: tensor(0.3910)\n",
      "5208 Traning Loss: tensor(0.3908)\n",
      "5209 Traning Loss: tensor(0.3906)\n",
      "5210 Traning Loss: tensor(0.3904)\n",
      "5211 Traning Loss: tensor(0.3902)\n",
      "5212 Traning Loss: tensor(0.3900)\n",
      "5213 Traning Loss: tensor(0.3898)\n",
      "5214 Traning Loss: tensor(0.3895)\n",
      "5215 Traning Loss: tensor(0.3893)\n",
      "5216 Traning Loss: tensor(0.3891)\n",
      "5217 Traning Loss: tensor(0.3889)\n",
      "5218 Traning Loss: tensor(0.3887)\n",
      "5219 Traning Loss: tensor(0.3885)\n",
      "5220 Traning Loss: tensor(0.3882)\n",
      "5221 Traning Loss: tensor(0.3880)\n",
      "5222 Traning Loss: tensor(0.3878)\n",
      "5223 Traning Loss: tensor(0.3876)\n",
      "5224 Traning Loss: tensor(0.3873)\n",
      "5225 Traning Loss: tensor(0.3871)\n",
      "5226 Traning Loss: tensor(0.3869)\n",
      "5227 Traning Loss: tensor(0.3866)\n",
      "5228 Traning Loss: tensor(0.3864)\n",
      "5229 Traning Loss: tensor(0.3862)\n",
      "5230 Traning Loss: tensor(0.3859)\n",
      "5231 Traning Loss: tensor(0.3857)\n",
      "5232 Traning Loss: tensor(0.3854)\n",
      "5233 Traning Loss: tensor(0.3852)\n",
      "5234 Traning Loss: tensor(0.3849)\n",
      "5235 Traning Loss: tensor(0.3847)\n",
      "5236 Traning Loss: tensor(0.3845)\n",
      "5237 Traning Loss: tensor(0.3842)\n",
      "5238 Traning Loss: tensor(0.3840)\n",
      "5239 Traning Loss: tensor(0.3837)\n",
      "5240 Traning Loss: tensor(0.3834)\n",
      "5241 Traning Loss: tensor(0.3832)\n",
      "5242 Traning Loss: tensor(0.3829)\n",
      "5243 Traning Loss: tensor(0.3827)\n",
      "5244 Traning Loss: tensor(0.3824)\n",
      "5245 Traning Loss: tensor(0.3821)\n",
      "5246 Traning Loss: tensor(0.3819)\n",
      "5247 Traning Loss: tensor(0.3816)\n",
      "5248 Traning Loss: tensor(0.3813)\n",
      "5249 Traning Loss: tensor(0.3811)\n",
      "5250 Traning Loss: tensor(0.3808)\n",
      "5251 Traning Loss: tensor(0.3805)\n",
      "5252 Traning Loss: tensor(0.3802)\n",
      "5253 Traning Loss: tensor(0.3800)\n",
      "5254 Traning Loss: tensor(0.3797)\n",
      "5255 Traning Loss: tensor(0.3794)\n",
      "5256 Traning Loss: tensor(0.3791)\n",
      "5257 Traning Loss: tensor(0.3788)\n",
      "5258 Traning Loss: tensor(0.3785)\n",
      "5259 Traning Loss: tensor(0.3782)\n",
      "5260 Traning Loss: tensor(0.3779)\n",
      "5261 Traning Loss: tensor(0.3777)\n",
      "5262 Traning Loss: tensor(0.3774)\n",
      "5263 Traning Loss: tensor(0.3771)\n",
      "5264 Traning Loss: tensor(0.3768)\n",
      "5265 Traning Loss: tensor(0.3765)\n",
      "5266 Traning Loss: tensor(0.3762)\n",
      "5267 Traning Loss: tensor(0.3759)\n",
      "5268 Traning Loss: tensor(0.3756)\n",
      "5269 Traning Loss: tensor(0.3752)\n",
      "5270 Traning Loss: tensor(0.3749)\n",
      "5271 Traning Loss: tensor(0.3746)\n",
      "5272 Traning Loss: tensor(0.3743)\n",
      "5273 Traning Loss: tensor(0.3740)\n",
      "5274 Traning Loss: tensor(0.3737)\n",
      "5275 Traning Loss: tensor(0.3734)\n",
      "5276 Traning Loss: tensor(0.3731)\n",
      "5277 Traning Loss: tensor(0.3727)\n",
      "5278 Traning Loss: tensor(0.3724)\n",
      "5279 Traning Loss: tensor(0.3721)\n",
      "5280 Traning Loss: tensor(0.3718)\n",
      "5281 Traning Loss: tensor(0.3714)\n",
      "5282 Traning Loss: tensor(0.3711)\n",
      "5283 Traning Loss: tensor(0.3708)\n",
      "5284 Traning Loss: tensor(0.3705)\n",
      "5285 Traning Loss: tensor(0.3701)\n",
      "5286 Traning Loss: tensor(0.3698)\n",
      "5287 Traning Loss: tensor(0.3695)\n",
      "5288 Traning Loss: tensor(0.3691)\n",
      "5289 Traning Loss: tensor(0.3688)\n",
      "5290 Traning Loss: tensor(0.3686)\n",
      "5291 Traning Loss: tensor(0.3685)\n",
      "5292 Traning Loss: tensor(0.3687)\n",
      "5293 Traning Loss: tensor(0.3691)\n",
      "5294 Traning Loss: tensor(0.3691)\n",
      "5295 Traning Loss: tensor(0.3679)\n",
      "5296 Traning Loss: tensor(0.3669)\n",
      "5297 Traning Loss: tensor(0.3669)\n",
      "5298 Traning Loss: tensor(0.3669)\n",
      "5299 Traning Loss: tensor(0.3663)\n",
      "5300 Traning Loss: tensor(0.3657)\n",
      "5301 Traning Loss: tensor(0.3656)\n",
      "5302 Traning Loss: tensor(0.3654)\n",
      "5303 Traning Loss: tensor(0.3649)\n",
      "5304 Traning Loss: tensor(0.3645)\n",
      "5305 Traning Loss: tensor(0.3644)\n",
      "5306 Traning Loss: tensor(0.3641)\n",
      "5307 Traning Loss: tensor(0.3635)\n",
      "5308 Traning Loss: tensor(0.3634)\n",
      "5309 Traning Loss: tensor(0.3632)\n",
      "5310 Traning Loss: tensor(0.3626)\n",
      "5311 Traning Loss: tensor(0.3625)\n",
      "5312 Traning Loss: tensor(0.3622)\n",
      "5313 Traning Loss: tensor(0.3618)\n",
      "5314 Traning Loss: tensor(0.3616)\n",
      "5315 Traning Loss: tensor(0.3613)\n",
      "5316 Traning Loss: tensor(0.3609)\n",
      "5317 Traning Loss: tensor(0.3607)\n",
      "5318 Traning Loss: tensor(0.3604)\n",
      "5319 Traning Loss: tensor(0.3601)\n",
      "5320 Traning Loss: tensor(0.3598)\n",
      "5321 Traning Loss: tensor(0.3595)\n",
      "5322 Traning Loss: tensor(0.3592)\n",
      "5323 Traning Loss: tensor(0.3589)\n",
      "5324 Traning Loss: tensor(0.3586)\n",
      "5325 Traning Loss: tensor(0.3583)\n",
      "5326 Traning Loss: tensor(0.3581)\n",
      "5327 Traning Loss: tensor(0.3577)\n",
      "5328 Traning Loss: tensor(0.3574)\n",
      "5329 Traning Loss: tensor(0.3572)\n",
      "5330 Traning Loss: tensor(0.3568)\n",
      "5331 Traning Loss: tensor(0.3566)\n",
      "5332 Traning Loss: tensor(0.3563)\n",
      "5333 Traning Loss: tensor(0.3560)\n",
      "5334 Traning Loss: tensor(0.3557)\n",
      "5335 Traning Loss: tensor(0.3554)\n",
      "5336 Traning Loss: tensor(0.3551)\n",
      "5337 Traning Loss: tensor(0.3548)\n",
      "5338 Traning Loss: tensor(0.3545)\n",
      "5339 Traning Loss: tensor(0.3542)\n",
      "5340 Traning Loss: tensor(0.3539)\n",
      "5341 Traning Loss: tensor(0.3536)\n",
      "5342 Traning Loss: tensor(0.3533)\n",
      "5343 Traning Loss: tensor(0.3530)\n",
      "5344 Traning Loss: tensor(0.3527)\n",
      "5345 Traning Loss: tensor(0.3524)\n",
      "5346 Traning Loss: tensor(0.3521)\n",
      "5347 Traning Loss: tensor(0.3518)\n",
      "5348 Traning Loss: tensor(0.3515)\n",
      "5349 Traning Loss: tensor(0.3512)\n",
      "5350 Traning Loss: tensor(0.3509)\n",
      "5351 Traning Loss: tensor(0.3506)\n",
      "5352 Traning Loss: tensor(0.3503)\n",
      "5353 Traning Loss: tensor(0.3500)\n",
      "5354 Traning Loss: tensor(0.3497)\n",
      "5355 Traning Loss: tensor(0.3494)\n",
      "5356 Traning Loss: tensor(0.3491)\n",
      "5357 Traning Loss: tensor(0.3487)\n",
      "5358 Traning Loss: tensor(0.3484)\n",
      "5359 Traning Loss: tensor(0.3481)\n",
      "5360 Traning Loss: tensor(0.3478)\n",
      "5361 Traning Loss: tensor(0.3475)\n",
      "5362 Traning Loss: tensor(0.3472)\n",
      "5363 Traning Loss: tensor(0.3469)\n",
      "5364 Traning Loss: tensor(0.3466)\n",
      "5365 Traning Loss: tensor(0.3463)\n",
      "5366 Traning Loss: tensor(0.3460)\n",
      "5367 Traning Loss: tensor(0.3457)\n",
      "5368 Traning Loss: tensor(0.3454)\n",
      "5369 Traning Loss: tensor(0.3451)\n",
      "5370 Traning Loss: tensor(0.3448)\n",
      "5371 Traning Loss: tensor(0.3444)\n",
      "5372 Traning Loss: tensor(0.3441)\n",
      "5373 Traning Loss: tensor(0.3438)\n",
      "5374 Traning Loss: tensor(0.3435)\n",
      "5375 Traning Loss: tensor(0.3432)\n",
      "5376 Traning Loss: tensor(0.3429)\n",
      "5377 Traning Loss: tensor(0.3426)\n",
      "5378 Traning Loss: tensor(0.3423)\n",
      "5379 Traning Loss: tensor(0.3420)\n",
      "5380 Traning Loss: tensor(0.3416)\n",
      "5381 Traning Loss: tensor(0.3413)\n",
      "5382 Traning Loss: tensor(0.3410)\n",
      "5383 Traning Loss: tensor(0.3407)\n",
      "5384 Traning Loss: tensor(0.3404)\n",
      "5385 Traning Loss: tensor(0.3401)\n",
      "5386 Traning Loss: tensor(0.3398)\n",
      "5387 Traning Loss: tensor(0.3395)\n",
      "5388 Traning Loss: tensor(0.3391)\n",
      "5389 Traning Loss: tensor(0.3388)\n",
      "5390 Traning Loss: tensor(0.3385)\n",
      "5391 Traning Loss: tensor(0.3382)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5392 Traning Loss: tensor(0.3379)\n",
      "5393 Traning Loss: tensor(0.3376)\n",
      "5394 Traning Loss: tensor(0.3373)\n",
      "5395 Traning Loss: tensor(0.3369)\n",
      "5396 Traning Loss: tensor(0.3366)\n",
      "5397 Traning Loss: tensor(0.3363)\n",
      "5398 Traning Loss: tensor(0.3360)\n",
      "5399 Traning Loss: tensor(0.3357)\n",
      "5400 Traning Loss: tensor(0.3354)\n",
      "5401 Traning Loss: tensor(0.3350)\n",
      "5402 Traning Loss: tensor(0.3347)\n",
      "5403 Traning Loss: tensor(0.3344)\n",
      "5404 Traning Loss: tensor(0.3341)\n",
      "5405 Traning Loss: tensor(0.3338)\n",
      "5406 Traning Loss: tensor(0.3335)\n",
      "5407 Traning Loss: tensor(0.3331)\n",
      "5408 Traning Loss: tensor(0.3328)\n",
      "5409 Traning Loss: tensor(0.3325)\n",
      "5410 Traning Loss: tensor(0.3322)\n",
      "5411 Traning Loss: tensor(0.3319)\n",
      "5412 Traning Loss: tensor(0.3316)\n",
      "5413 Traning Loss: tensor(0.3313)\n",
      "5414 Traning Loss: tensor(0.3310)\n",
      "5415 Traning Loss: tensor(0.3307)\n",
      "5416 Traning Loss: tensor(0.3305)\n",
      "5417 Traning Loss: tensor(0.3304)\n",
      "5418 Traning Loss: tensor(0.3305)\n",
      "5419 Traning Loss: tensor(0.3304)\n",
      "5420 Traning Loss: tensor(0.3300)\n",
      "5421 Traning Loss: tensor(0.3291)\n",
      "5422 Traning Loss: tensor(0.3285)\n",
      "5423 Traning Loss: tensor(0.3284)\n",
      "5424 Traning Loss: tensor(0.3284)\n",
      "5425 Traning Loss: tensor(0.3280)\n",
      "5426 Traning Loss: tensor(0.3274)\n",
      "5427 Traning Loss: tensor(0.3270)\n",
      "5428 Traning Loss: tensor(0.3270)\n",
      "5429 Traning Loss: tensor(0.3267)\n",
      "5430 Traning Loss: tensor(0.3262)\n",
      "5431 Traning Loss: tensor(0.3258)\n",
      "5432 Traning Loss: tensor(0.3257)\n",
      "5433 Traning Loss: tensor(0.3254)\n",
      "5434 Traning Loss: tensor(0.3250)\n",
      "5435 Traning Loss: tensor(0.3246)\n",
      "5436 Traning Loss: tensor(0.3244)\n",
      "5437 Traning Loss: tensor(0.3242)\n",
      "5438 Traning Loss: tensor(0.3238)\n",
      "5439 Traning Loss: tensor(0.3235)\n",
      "5440 Traning Loss: tensor(0.3232)\n",
      "5441 Traning Loss: tensor(0.3230)\n",
      "5442 Traning Loss: tensor(0.3226)\n",
      "5443 Traning Loss: tensor(0.3223)\n",
      "5444 Traning Loss: tensor(0.3220)\n",
      "5445 Traning Loss: tensor(0.3218)\n",
      "5446 Traning Loss: tensor(0.3215)\n",
      "5447 Traning Loss: tensor(0.3211)\n",
      "5448 Traning Loss: tensor(0.3208)\n",
      "5449 Traning Loss: tensor(0.3206)\n",
      "5450 Traning Loss: tensor(0.3203)\n",
      "5451 Traning Loss: tensor(0.3200)\n",
      "5452 Traning Loss: tensor(0.3197)\n",
      "5453 Traning Loss: tensor(0.3194)\n",
      "5454 Traning Loss: tensor(0.3191)\n",
      "5455 Traning Loss: tensor(0.3188)\n",
      "5456 Traning Loss: tensor(0.3185)\n",
      "5457 Traning Loss: tensor(0.3182)\n",
      "5458 Traning Loss: tensor(0.3179)\n",
      "5459 Traning Loss: tensor(0.3176)\n",
      "5460 Traning Loss: tensor(0.3173)\n",
      "5461 Traning Loss: tensor(0.3170)\n",
      "5462 Traning Loss: tensor(0.3167)\n",
      "5463 Traning Loss: tensor(0.3165)\n",
      "5464 Traning Loss: tensor(0.3162)\n",
      "5465 Traning Loss: tensor(0.3159)\n",
      "5466 Traning Loss: tensor(0.3156)\n",
      "5467 Traning Loss: tensor(0.3153)\n",
      "5468 Traning Loss: tensor(0.3150)\n",
      "5469 Traning Loss: tensor(0.3147)\n",
      "5470 Traning Loss: tensor(0.3144)\n",
      "5471 Traning Loss: tensor(0.3141)\n",
      "5472 Traning Loss: tensor(0.3138)\n",
      "5473 Traning Loss: tensor(0.3135)\n",
      "5474 Traning Loss: tensor(0.3132)\n",
      "5475 Traning Loss: tensor(0.3129)\n",
      "5476 Traning Loss: tensor(0.3126)\n",
      "5477 Traning Loss: tensor(0.3123)\n",
      "5478 Traning Loss: tensor(0.3120)\n",
      "5479 Traning Loss: tensor(0.3117)\n",
      "5480 Traning Loss: tensor(0.3114)\n",
      "5481 Traning Loss: tensor(0.3111)\n",
      "5482 Traning Loss: tensor(0.3108)\n",
      "5483 Traning Loss: tensor(0.3105)\n",
      "5484 Traning Loss: tensor(0.3102)\n",
      "5485 Traning Loss: tensor(0.3100)\n",
      "5486 Traning Loss: tensor(0.3097)\n",
      "5487 Traning Loss: tensor(0.3094)\n",
      "5488 Traning Loss: tensor(0.3091)\n",
      "5489 Traning Loss: tensor(0.3088)\n",
      "5490 Traning Loss: tensor(0.3085)\n",
      "5491 Traning Loss: tensor(0.3082)\n",
      "5492 Traning Loss: tensor(0.3079)\n",
      "5493 Traning Loss: tensor(0.3076)\n",
      "5494 Traning Loss: tensor(0.3073)\n",
      "5495 Traning Loss: tensor(0.3070)\n",
      "5496 Traning Loss: tensor(0.3067)\n",
      "5497 Traning Loss: tensor(0.3064)\n",
      "5498 Traning Loss: tensor(0.3061)\n",
      "5499 Traning Loss: tensor(0.3058)\n",
      "5500 Traning Loss: tensor(0.3055)\n",
      "5501 Traning Loss: tensor(0.3052)\n",
      "5502 Traning Loss: tensor(0.3049)\n",
      "5503 Traning Loss: tensor(0.3046)\n",
      "5504 Traning Loss: tensor(0.3043)\n",
      "5505 Traning Loss: tensor(0.3040)\n",
      "5506 Traning Loss: tensor(0.3037)\n",
      "5507 Traning Loss: tensor(0.3034)\n",
      "5508 Traning Loss: tensor(0.3031)\n",
      "5509 Traning Loss: tensor(0.3028)\n",
      "5510 Traning Loss: tensor(0.3025)\n",
      "5511 Traning Loss: tensor(0.3022)\n",
      "5512 Traning Loss: tensor(0.3019)\n",
      "5513 Traning Loss: tensor(0.3016)\n",
      "5514 Traning Loss: tensor(0.3013)\n",
      "5515 Traning Loss: tensor(0.3010)\n",
      "5516 Traning Loss: tensor(0.3007)\n",
      "5517 Traning Loss: tensor(0.3004)\n",
      "5518 Traning Loss: tensor(0.3001)\n",
      "5519 Traning Loss: tensor(0.2998)\n",
      "5520 Traning Loss: tensor(0.2995)\n",
      "5521 Traning Loss: tensor(0.2992)\n",
      "5522 Traning Loss: tensor(0.2990)\n",
      "5523 Traning Loss: tensor(0.2987)\n",
      "5524 Traning Loss: tensor(0.2985)\n",
      "5525 Traning Loss: tensor(0.2983)\n",
      "5526 Traning Loss: tensor(0.2983)\n",
      "5527 Traning Loss: tensor(0.2983)\n",
      "5528 Traning Loss: tensor(0.2983)\n",
      "5529 Traning Loss: tensor(0.2979)\n",
      "5530 Traning Loss: tensor(0.2971)\n",
      "5531 Traning Loss: tensor(0.2964)\n",
      "5532 Traning Loss: tensor(0.2961)\n",
      "5533 Traning Loss: tensor(0.2961)\n",
      "5534 Traning Loss: tensor(0.2960)\n",
      "5535 Traning Loss: tensor(0.2955)\n",
      "5536 Traning Loss: tensor(0.2950)\n",
      "5537 Traning Loss: tensor(0.2946)\n",
      "5538 Traning Loss: tensor(0.2945)\n",
      "5539 Traning Loss: tensor(0.2943)\n",
      "5540 Traning Loss: tensor(0.2940)\n",
      "5541 Traning Loss: tensor(0.2935)\n",
      "5542 Traning Loss: tensor(0.2932)\n",
      "5543 Traning Loss: tensor(0.2931)\n",
      "5544 Traning Loss: tensor(0.2928)\n",
      "5545 Traning Loss: tensor(0.2924)\n",
      "5546 Traning Loss: tensor(0.2921)\n",
      "5547 Traning Loss: tensor(0.2918)\n",
      "5548 Traning Loss: tensor(0.2916)\n",
      "5549 Traning Loss: tensor(0.2913)\n",
      "5550 Traning Loss: tensor(0.2910)\n",
      "5551 Traning Loss: tensor(0.2907)\n",
      "5552 Traning Loss: tensor(0.2904)\n",
      "5553 Traning Loss: tensor(0.2902)\n",
      "5554 Traning Loss: tensor(0.2899)\n",
      "5555 Traning Loss: tensor(0.2896)\n",
      "5556 Traning Loss: tensor(0.2893)\n",
      "5557 Traning Loss: tensor(0.2890)\n",
      "5558 Traning Loss: tensor(0.2888)\n",
      "5559 Traning Loss: tensor(0.2885)\n",
      "5560 Traning Loss: tensor(0.2882)\n",
      "5561 Traning Loss: tensor(0.2879)\n",
      "5562 Traning Loss: tensor(0.2876)\n",
      "5563 Traning Loss: tensor(0.2874)\n",
      "5564 Traning Loss: tensor(0.2871)\n",
      "5565 Traning Loss: tensor(0.2868)\n",
      "5566 Traning Loss: tensor(0.2865)\n",
      "5567 Traning Loss: tensor(0.2862)\n",
      "5568 Traning Loss: tensor(0.2860)\n",
      "5569 Traning Loss: tensor(0.2857)\n",
      "5570 Traning Loss: tensor(0.2854)\n",
      "5571 Traning Loss: tensor(0.2851)\n",
      "5572 Traning Loss: tensor(0.2848)\n",
      "5573 Traning Loss: tensor(0.2846)\n",
      "5574 Traning Loss: tensor(0.2843)\n",
      "5575 Traning Loss: tensor(0.2840)\n",
      "5576 Traning Loss: tensor(0.2837)\n",
      "5577 Traning Loss: tensor(0.2834)\n",
      "5578 Traning Loss: tensor(0.2832)\n",
      "5579 Traning Loss: tensor(0.2829)\n",
      "5580 Traning Loss: tensor(0.2826)\n",
      "5581 Traning Loss: tensor(0.2823)\n",
      "5582 Traning Loss: tensor(0.2821)\n",
      "5583 Traning Loss: tensor(0.2818)\n",
      "5584 Traning Loss: tensor(0.2815)\n",
      "5585 Traning Loss: tensor(0.2812)\n",
      "5586 Traning Loss: tensor(0.2809)\n",
      "5587 Traning Loss: tensor(0.2807)\n",
      "5588 Traning Loss: tensor(0.2804)\n",
      "5589 Traning Loss: tensor(0.2801)\n",
      "5590 Traning Loss: tensor(0.2798)\n",
      "5591 Traning Loss: tensor(0.2796)\n",
      "5592 Traning Loss: tensor(0.2793)\n",
      "5593 Traning Loss: tensor(0.2790)\n",
      "5594 Traning Loss: tensor(0.2787)\n",
      "5595 Traning Loss: tensor(0.2784)\n",
      "5596 Traning Loss: tensor(0.2782)\n",
      "5597 Traning Loss: tensor(0.2779)\n",
      "5598 Traning Loss: tensor(0.2776)\n",
      "5599 Traning Loss: tensor(0.2773)\n",
      "5600 Traning Loss: tensor(0.2771)\n",
      "5601 Traning Loss: tensor(0.2768)\n",
      "5602 Traning Loss: tensor(0.2765)\n",
      "5603 Traning Loss: tensor(0.2762)\n",
      "5604 Traning Loss: tensor(0.2759)\n",
      "5605 Traning Loss: tensor(0.2757)\n",
      "5606 Traning Loss: tensor(0.2754)\n",
      "5607 Traning Loss: tensor(0.2751)\n",
      "5608 Traning Loss: tensor(0.2748)\n",
      "5609 Traning Loss: tensor(0.2746)\n",
      "5610 Traning Loss: tensor(0.2743)\n",
      "5611 Traning Loss: tensor(0.2740)\n",
      "5612 Traning Loss: tensor(0.2737)\n",
      "5613 Traning Loss: tensor(0.2735)\n",
      "5614 Traning Loss: tensor(0.2732)\n",
      "5615 Traning Loss: tensor(0.2729)\n",
      "5616 Traning Loss: tensor(0.2726)\n",
      "5617 Traning Loss: tensor(0.2724)\n",
      "5618 Traning Loss: tensor(0.2721)\n",
      "5619 Traning Loss: tensor(0.2718)\n",
      "5620 Traning Loss: tensor(0.2715)\n",
      "5621 Traning Loss: tensor(0.2713)\n",
      "5622 Traning Loss: tensor(0.2710)\n",
      "5623 Traning Loss: tensor(0.2708)\n",
      "5624 Traning Loss: tensor(0.2706)\n",
      "5625 Traning Loss: tensor(0.2705)\n",
      "5626 Traning Loss: tensor(0.2705)\n",
      "5627 Traning Loss: tensor(0.2706)\n",
      "5628 Traning Loss: tensor(0.2705)\n",
      "5629 Traning Loss: tensor(0.2701)\n",
      "5630 Traning Loss: tensor(0.2694)\n",
      "5631 Traning Loss: tensor(0.2686)\n",
      "5632 Traning Loss: tensor(0.2683)\n",
      "5633 Traning Loss: tensor(0.2683)\n",
      "5634 Traning Loss: tensor(0.2683)\n",
      "5635 Traning Loss: tensor(0.2679)\n",
      "5636 Traning Loss: tensor(0.2674)\n",
      "5637 Traning Loss: tensor(0.2670)\n",
      "5638 Traning Loss: tensor(0.2668)\n",
      "5639 Traning Loss: tensor(0.2667)\n",
      "5640 Traning Loss: tensor(0.2664)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5641 Traning Loss: tensor(0.2661)\n",
      "5642 Traning Loss: tensor(0.2657)\n",
      "5643 Traning Loss: tensor(0.2655)\n",
      "5644 Traning Loss: tensor(0.2653)\n",
      "5645 Traning Loss: tensor(0.2650)\n",
      "5646 Traning Loss: tensor(0.2647)\n",
      "5647 Traning Loss: tensor(0.2644)\n",
      "5648 Traning Loss: tensor(0.2641)\n",
      "5649 Traning Loss: tensor(0.2639)\n",
      "5650 Traning Loss: tensor(0.2637)\n",
      "5651 Traning Loss: tensor(0.2634)\n",
      "5652 Traning Loss: tensor(0.2631)\n",
      "5653 Traning Loss: tensor(0.2628)\n",
      "5654 Traning Loss: tensor(0.2626)\n",
      "5655 Traning Loss: tensor(0.2624)\n",
      "5656 Traning Loss: tensor(0.2621)\n",
      "5657 Traning Loss: tensor(0.2618)\n",
      "5658 Traning Loss: tensor(0.2615)\n",
      "5659 Traning Loss: tensor(0.2613)\n",
      "5660 Traning Loss: tensor(0.2611)\n",
      "5661 Traning Loss: tensor(0.2608)\n",
      "5662 Traning Loss: tensor(0.2605)\n",
      "5663 Traning Loss: tensor(0.2603)\n",
      "5664 Traning Loss: tensor(0.2600)\n",
      "5665 Traning Loss: tensor(0.2598)\n",
      "5666 Traning Loss: tensor(0.2595)\n",
      "5667 Traning Loss: tensor(0.2593)\n",
      "5668 Traning Loss: tensor(0.2590)\n",
      "5669 Traning Loss: tensor(0.2587)\n",
      "5670 Traning Loss: tensor(0.2585)\n",
      "5671 Traning Loss: tensor(0.2582)\n",
      "5672 Traning Loss: tensor(0.2580)\n",
      "5673 Traning Loss: tensor(0.2577)\n",
      "5674 Traning Loss: tensor(0.2575)\n",
      "5675 Traning Loss: tensor(0.2572)\n",
      "5676 Traning Loss: tensor(0.2569)\n",
      "5677 Traning Loss: tensor(0.2567)\n",
      "5678 Traning Loss: tensor(0.2564)\n",
      "5679 Traning Loss: tensor(0.2562)\n",
      "5680 Traning Loss: tensor(0.2559)\n",
      "5681 Traning Loss: tensor(0.2557)\n",
      "5682 Traning Loss: tensor(0.2554)\n",
      "5683 Traning Loss: tensor(0.2552)\n",
      "5684 Traning Loss: tensor(0.2549)\n",
      "5685 Traning Loss: tensor(0.2547)\n",
      "5686 Traning Loss: tensor(0.2544)\n",
      "5687 Traning Loss: tensor(0.2542)\n",
      "5688 Traning Loss: tensor(0.2539)\n",
      "5689 Traning Loss: tensor(0.2536)\n",
      "5690 Traning Loss: tensor(0.2534)\n",
      "5691 Traning Loss: tensor(0.2531)\n",
      "5692 Traning Loss: tensor(0.2529)\n",
      "5693 Traning Loss: tensor(0.2526)\n",
      "5694 Traning Loss: tensor(0.2524)\n",
      "5695 Traning Loss: tensor(0.2521)\n",
      "5696 Traning Loss: tensor(0.2519)\n",
      "5697 Traning Loss: tensor(0.2516)\n",
      "5698 Traning Loss: tensor(0.2514)\n",
      "5699 Traning Loss: tensor(0.2511)\n",
      "5700 Traning Loss: tensor(0.2509)\n",
      "5701 Traning Loss: tensor(0.2506)\n",
      "5702 Traning Loss: tensor(0.2504)\n",
      "5703 Traning Loss: tensor(0.2501)\n",
      "5704 Traning Loss: tensor(0.2499)\n",
      "5705 Traning Loss: tensor(0.2496)\n",
      "5706 Traning Loss: tensor(0.2494)\n",
      "5707 Traning Loss: tensor(0.2491)\n",
      "5708 Traning Loss: tensor(0.2489)\n",
      "5709 Traning Loss: tensor(0.2486)\n",
      "5710 Traning Loss: tensor(0.2484)\n",
      "5711 Traning Loss: tensor(0.2481)\n",
      "5712 Traning Loss: tensor(0.2479)\n",
      "5713 Traning Loss: tensor(0.2476)\n",
      "5714 Traning Loss: tensor(0.2474)\n",
      "5715 Traning Loss: tensor(0.2471)\n",
      "5716 Traning Loss: tensor(0.2469)\n",
      "5717 Traning Loss: tensor(0.2466)\n",
      "5718 Traning Loss: tensor(0.2464)\n",
      "5719 Traning Loss: tensor(0.2462)\n",
      "5720 Traning Loss: tensor(0.2460)\n",
      "5721 Traning Loss: tensor(0.2458)\n",
      "5722 Traning Loss: tensor(0.2457)\n",
      "5723 Traning Loss: tensor(0.2457)\n",
      "5724 Traning Loss: tensor(0.2457)\n",
      "5725 Traning Loss: tensor(0.2458)\n",
      "5726 Traning Loss: tensor(0.2456)\n",
      "5727 Traning Loss: tensor(0.2450)\n",
      "5728 Traning Loss: tensor(0.2443)\n",
      "5729 Traning Loss: tensor(0.2437)\n",
      "5730 Traning Loss: tensor(0.2435)\n",
      "5731 Traning Loss: tensor(0.2435)\n",
      "5732 Traning Loss: tensor(0.2435)\n",
      "5733 Traning Loss: tensor(0.2432)\n",
      "5734 Traning Loss: tensor(0.2427)\n",
      "5735 Traning Loss: tensor(0.2423)\n",
      "5736 Traning Loss: tensor(0.2421)\n",
      "5737 Traning Loss: tensor(0.2420)\n",
      "5738 Traning Loss: tensor(0.2418)\n",
      "5739 Traning Loss: tensor(0.2415)\n",
      "5740 Traning Loss: tensor(0.2411)\n",
      "5741 Traning Loss: tensor(0.2409)\n",
      "5742 Traning Loss: tensor(0.2407)\n",
      "5743 Traning Loss: tensor(0.2405)\n",
      "5744 Traning Loss: tensor(0.2403)\n",
      "5745 Traning Loss: tensor(0.2400)\n",
      "5746 Traning Loss: tensor(0.2397)\n",
      "5747 Traning Loss: tensor(0.2394)\n",
      "5748 Traning Loss: tensor(0.2392)\n",
      "5749 Traning Loss: tensor(0.2390)\n",
      "5750 Traning Loss: tensor(0.2388)\n",
      "5751 Traning Loss: tensor(0.2385)\n",
      "5752 Traning Loss: tensor(0.2383)\n",
      "5753 Traning Loss: tensor(0.2380)\n",
      "5754 Traning Loss: tensor(0.2378)\n",
      "5755 Traning Loss: tensor(0.2376)\n",
      "5756 Traning Loss: tensor(0.2374)\n",
      "5757 Traning Loss: tensor(0.2371)\n",
      "5758 Traning Loss: tensor(0.2369)\n",
      "5759 Traning Loss: tensor(0.2366)\n",
      "5760 Traning Loss: tensor(0.2364)\n",
      "5761 Traning Loss: tensor(0.2362)\n",
      "5762 Traning Loss: tensor(0.2360)\n",
      "5763 Traning Loss: tensor(0.2357)\n",
      "5764 Traning Loss: tensor(0.2355)\n",
      "5765 Traning Loss: tensor(0.2353)\n",
      "5766 Traning Loss: tensor(0.2350)\n",
      "5767 Traning Loss: tensor(0.2348)\n",
      "5768 Traning Loss: tensor(0.2346)\n",
      "5769 Traning Loss: tensor(0.2344)\n",
      "5770 Traning Loss: tensor(0.2341)\n",
      "5771 Traning Loss: tensor(0.2339)\n",
      "5772 Traning Loss: tensor(0.2337)\n",
      "5773 Traning Loss: tensor(0.2334)\n",
      "5774 Traning Loss: tensor(0.2332)\n",
      "5775 Traning Loss: tensor(0.2330)\n",
      "5776 Traning Loss: tensor(0.2327)\n",
      "5777 Traning Loss: tensor(0.2325)\n",
      "5778 Traning Loss: tensor(0.2323)\n",
      "5779 Traning Loss: tensor(0.2321)\n",
      "5780 Traning Loss: tensor(0.2318)\n",
      "5781 Traning Loss: tensor(0.2316)\n",
      "5782 Traning Loss: tensor(0.2314)\n",
      "5783 Traning Loss: tensor(0.2311)\n",
      "5784 Traning Loss: tensor(0.2309)\n",
      "5785 Traning Loss: tensor(0.2307)\n",
      "5786 Traning Loss: tensor(0.2305)\n",
      "5787 Traning Loss: tensor(0.2302)\n",
      "5788 Traning Loss: tensor(0.2300)\n",
      "5789 Traning Loss: tensor(0.2298)\n",
      "5790 Traning Loss: tensor(0.2296)\n",
      "5791 Traning Loss: tensor(0.2293)\n",
      "5792 Traning Loss: tensor(0.2291)\n",
      "5793 Traning Loss: tensor(0.2289)\n",
      "5794 Traning Loss: tensor(0.2287)\n",
      "5795 Traning Loss: tensor(0.2284)\n",
      "5796 Traning Loss: tensor(0.2282)\n",
      "5797 Traning Loss: tensor(0.2280)\n",
      "5798 Traning Loss: tensor(0.2278)\n",
      "5799 Traning Loss: tensor(0.2275)\n",
      "5800 Traning Loss: tensor(0.2273)\n",
      "5801 Traning Loss: tensor(0.2271)\n",
      "5802 Traning Loss: tensor(0.2269)\n",
      "5803 Traning Loss: tensor(0.2266)\n",
      "5804 Traning Loss: tensor(0.2264)\n",
      "5805 Traning Loss: tensor(0.2262)\n",
      "5806 Traning Loss: tensor(0.2260)\n",
      "5807 Traning Loss: tensor(0.2257)\n",
      "5808 Traning Loss: tensor(0.2255)\n",
      "5809 Traning Loss: tensor(0.2253)\n",
      "5810 Traning Loss: tensor(0.2251)\n",
      "5811 Traning Loss: tensor(0.2249)\n",
      "5812 Traning Loss: tensor(0.2246)\n",
      "5813 Traning Loss: tensor(0.2244)\n",
      "5814 Traning Loss: tensor(0.2242)\n",
      "5815 Traning Loss: tensor(0.2240)\n",
      "5816 Traning Loss: tensor(0.2239)\n",
      "5817 Traning Loss: tensor(0.2237)\n",
      "5818 Traning Loss: tensor(0.2237)\n",
      "5819 Traning Loss: tensor(0.2236)\n",
      "5820 Traning Loss: tensor(0.2237)\n",
      "5821 Traning Loss: tensor(0.2237)\n",
      "5822 Traning Loss: tensor(0.2237)\n",
      "5823 Traning Loss: tensor(0.2233)\n",
      "5824 Traning Loss: tensor(0.2226)\n",
      "5825 Traning Loss: tensor(0.2220)\n",
      "5826 Traning Loss: tensor(0.2216)\n",
      "5827 Traning Loss: tensor(0.2215)\n",
      "5828 Traning Loss: tensor(0.2216)\n",
      "5829 Traning Loss: tensor(0.2215)\n",
      "5830 Traning Loss: tensor(0.2211)\n",
      "5831 Traning Loss: tensor(0.2207)\n",
      "5832 Traning Loss: tensor(0.2204)\n",
      "5833 Traning Loss: tensor(0.2202)\n",
      "5834 Traning Loss: tensor(0.2201)\n",
      "5835 Traning Loss: tensor(0.2199)\n",
      "5836 Traning Loss: tensor(0.2197)\n",
      "5837 Traning Loss: tensor(0.2194)\n",
      "5838 Traning Loss: tensor(0.2191)\n",
      "5839 Traning Loss: tensor(0.2189)\n",
      "5840 Traning Loss: tensor(0.2188)\n",
      "5841 Traning Loss: tensor(0.2186)\n",
      "5842 Traning Loss: tensor(0.2183)\n",
      "5843 Traning Loss: tensor(0.2181)\n",
      "5844 Traning Loss: tensor(0.2179)\n",
      "5845 Traning Loss: tensor(0.2177)\n",
      "5846 Traning Loss: tensor(0.2175)\n",
      "5847 Traning Loss: tensor(0.2173)\n",
      "5848 Traning Loss: tensor(0.2171)\n",
      "5849 Traning Loss: tensor(0.2168)\n",
      "5850 Traning Loss: tensor(0.2166)\n",
      "5851 Traning Loss: tensor(0.2164)\n",
      "5852 Traning Loss: tensor(0.2162)\n",
      "5853 Traning Loss: tensor(0.2160)\n",
      "5854 Traning Loss: tensor(0.2158)\n",
      "5855 Traning Loss: tensor(0.2156)\n",
      "5856 Traning Loss: tensor(0.2154)\n",
      "5857 Traning Loss: tensor(0.2152)\n",
      "5858 Traning Loss: tensor(0.2150)\n",
      "5859 Traning Loss: tensor(0.2148)\n",
      "5860 Traning Loss: tensor(0.2146)\n",
      "5861 Traning Loss: tensor(0.2144)\n",
      "5862 Traning Loss: tensor(0.2142)\n",
      "5863 Traning Loss: tensor(0.2140)\n",
      "5864 Traning Loss: tensor(0.2138)\n",
      "5865 Traning Loss: tensor(0.2136)\n",
      "5866 Traning Loss: tensor(0.2134)\n",
      "5867 Traning Loss: tensor(0.2132)\n",
      "5868 Traning Loss: tensor(0.2130)\n",
      "5869 Traning Loss: tensor(0.2128)\n",
      "5870 Traning Loss: tensor(0.2126)\n",
      "5871 Traning Loss: tensor(0.2124)\n",
      "5872 Traning Loss: tensor(0.2122)\n",
      "5873 Traning Loss: tensor(0.2120)\n",
      "5874 Traning Loss: tensor(0.2118)\n",
      "5875 Traning Loss: tensor(0.2116)\n",
      "5876 Traning Loss: tensor(0.2114)\n",
      "5877 Traning Loss: tensor(0.2112)\n",
      "5878 Traning Loss: tensor(0.2110)\n",
      "5879 Traning Loss: tensor(0.2108)\n",
      "5880 Traning Loss: tensor(0.2106)\n",
      "5881 Traning Loss: tensor(0.2104)\n",
      "5882 Traning Loss: tensor(0.2102)\n",
      "5883 Traning Loss: tensor(0.2100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5884 Traning Loss: tensor(0.2098)\n",
      "5885 Traning Loss: tensor(0.2096)\n",
      "5886 Traning Loss: tensor(0.2094)\n",
      "5887 Traning Loss: tensor(0.2092)\n",
      "5888 Traning Loss: tensor(0.2090)\n",
      "5889 Traning Loss: tensor(0.2088)\n",
      "5890 Traning Loss: tensor(0.2086)\n",
      "5891 Traning Loss: tensor(0.2084)\n",
      "5892 Traning Loss: tensor(0.2082)\n",
      "5893 Traning Loss: tensor(0.2080)\n",
      "5894 Traning Loss: tensor(0.2078)\n",
      "5895 Traning Loss: tensor(0.2076)\n",
      "5896 Traning Loss: tensor(0.2074)\n",
      "5897 Traning Loss: tensor(0.2072)\n",
      "5898 Traning Loss: tensor(0.2071)\n",
      "5899 Traning Loss: tensor(0.2069)\n",
      "5900 Traning Loss: tensor(0.2067)\n",
      "5901 Traning Loss: tensor(0.2065)\n",
      "5902 Traning Loss: tensor(0.2063)\n",
      "5903 Traning Loss: tensor(0.2061)\n",
      "5904 Traning Loss: tensor(0.2059)\n",
      "5905 Traning Loss: tensor(0.2057)\n",
      "5906 Traning Loss: tensor(0.2055)\n",
      "5907 Traning Loss: tensor(0.2053)\n",
      "5908 Traning Loss: tensor(0.2051)\n",
      "5909 Traning Loss: tensor(0.2050)\n",
      "5910 Traning Loss: tensor(0.2048)\n",
      "5911 Traning Loss: tensor(0.2046)\n",
      "5912 Traning Loss: tensor(0.2044)\n",
      "5913 Traning Loss: tensor(0.2043)\n",
      "5914 Traning Loss: tensor(0.2042)\n",
      "5915 Traning Loss: tensor(0.2041)\n",
      "5916 Traning Loss: tensor(0.2041)\n",
      "5917 Traning Loss: tensor(0.2042)\n",
      "5918 Traning Loss: tensor(0.2044)\n",
      "5919 Traning Loss: tensor(0.2046)\n",
      "5920 Traning Loss: tensor(0.2046)\n",
      "5921 Traning Loss: tensor(0.2042)\n",
      "5922 Traning Loss: tensor(0.2033)\n",
      "5923 Traning Loss: tensor(0.2025)\n",
      "5924 Traning Loss: tensor(0.2022)\n",
      "5925 Traning Loss: tensor(0.2024)\n",
      "5926 Traning Loss: tensor(0.2025)\n",
      "5927 Traning Loss: tensor(0.2023)\n",
      "5928 Traning Loss: tensor(0.2018)\n",
      "5929 Traning Loss: tensor(0.2014)\n",
      "5930 Traning Loss: tensor(0.2012)\n",
      "5931 Traning Loss: tensor(0.2012)\n",
      "5932 Traning Loss: tensor(0.2012)\n",
      "5933 Traning Loss: tensor(0.2009)\n",
      "5934 Traning Loss: tensor(0.2005)\n",
      "5935 Traning Loss: tensor(0.2003)\n",
      "5936 Traning Loss: tensor(0.2002)\n",
      "5937 Traning Loss: tensor(0.2001)\n",
      "5938 Traning Loss: tensor(0.1999)\n",
      "5939 Traning Loss: tensor(0.1996)\n",
      "5940 Traning Loss: tensor(0.1994)\n",
      "5941 Traning Loss: tensor(0.1993)\n",
      "5942 Traning Loss: tensor(0.1991)\n",
      "5943 Traning Loss: tensor(0.1990)\n",
      "5944 Traning Loss: tensor(0.1988)\n",
      "5945 Traning Loss: tensor(0.1986)\n",
      "5946 Traning Loss: tensor(0.1984)\n",
      "5947 Traning Loss: tensor(0.1982)\n",
      "5948 Traning Loss: tensor(0.1981)\n",
      "5949 Traning Loss: tensor(0.1979)\n",
      "5950 Traning Loss: tensor(0.1977)\n",
      "5951 Traning Loss: tensor(0.1976)\n",
      "5952 Traning Loss: tensor(0.1974)\n",
      "5953 Traning Loss: tensor(0.1972)\n",
      "5954 Traning Loss: tensor(0.1970)\n",
      "5955 Traning Loss: tensor(0.1969)\n",
      "5956 Traning Loss: tensor(0.1967)\n",
      "5957 Traning Loss: tensor(0.1965)\n",
      "5958 Traning Loss: tensor(0.1964)\n",
      "5959 Traning Loss: tensor(0.1962)\n",
      "5960 Traning Loss: tensor(0.1960)\n",
      "5961 Traning Loss: tensor(0.1959)\n",
      "5962 Traning Loss: tensor(0.1957)\n",
      "5963 Traning Loss: tensor(0.1955)\n",
      "5964 Traning Loss: tensor(0.1954)\n",
      "5965 Traning Loss: tensor(0.1952)\n",
      "5966 Traning Loss: tensor(0.1951)\n",
      "5967 Traning Loss: tensor(0.1949)\n",
      "5968 Traning Loss: tensor(0.1947)\n",
      "5969 Traning Loss: tensor(0.1946)\n",
      "5970 Traning Loss: tensor(0.1944)\n",
      "5971 Traning Loss: tensor(0.1942)\n",
      "5972 Traning Loss: tensor(0.1941)\n",
      "5973 Traning Loss: tensor(0.1939)\n",
      "5974 Traning Loss: tensor(0.1938)\n",
      "5975 Traning Loss: tensor(0.1936)\n",
      "5976 Traning Loss: tensor(0.1934)\n",
      "5977 Traning Loss: tensor(0.1933)\n",
      "5978 Traning Loss: tensor(0.1931)\n",
      "5979 Traning Loss: tensor(0.1930)\n",
      "5980 Traning Loss: tensor(0.1928)\n",
      "5981 Traning Loss: tensor(0.1926)\n",
      "5982 Traning Loss: tensor(0.1925)\n",
      "5983 Traning Loss: tensor(0.1923)\n",
      "5984 Traning Loss: tensor(0.1922)\n",
      "5985 Traning Loss: tensor(0.1920)\n",
      "5986 Traning Loss: tensor(0.1919)\n",
      "5987 Traning Loss: tensor(0.1917)\n",
      "5988 Traning Loss: tensor(0.1915)\n",
      "5989 Traning Loss: tensor(0.1914)\n",
      "5990 Traning Loss: tensor(0.1912)\n",
      "5991 Traning Loss: tensor(0.1911)\n",
      "5992 Traning Loss: tensor(0.1909)\n",
      "5993 Traning Loss: tensor(0.1908)\n",
      "5994 Traning Loss: tensor(0.1906)\n",
      "5995 Traning Loss: tensor(0.1905)\n",
      "5996 Traning Loss: tensor(0.1903)\n",
      "5997 Traning Loss: tensor(0.1902)\n",
      "5998 Traning Loss: tensor(0.1900)\n",
      "5999 Traning Loss: tensor(0.1898)\n",
      "6000 Traning Loss: tensor(0.1897)\n",
      "6001 Traning Loss: tensor(0.1895)\n",
      "6002 Traning Loss: tensor(0.1894)\n",
      "6003 Traning Loss: tensor(0.1892)\n",
      "6004 Traning Loss: tensor(0.1891)\n",
      "6005 Traning Loss: tensor(0.1889)\n",
      "6006 Traning Loss: tensor(0.1888)\n",
      "6007 Traning Loss: tensor(0.1886)\n",
      "6008 Traning Loss: tensor(0.1885)\n",
      "6009 Traning Loss: tensor(0.1883)\n",
      "6010 Traning Loss: tensor(0.1882)\n",
      "6011 Traning Loss: tensor(0.1880)\n",
      "6012 Traning Loss: tensor(0.1879)\n",
      "6013 Traning Loss: tensor(0.1877)\n",
      "6014 Traning Loss: tensor(0.1876)\n",
      "6015 Traning Loss: tensor(0.1874)\n",
      "6016 Traning Loss: tensor(0.1873)\n",
      "6017 Traning Loss: tensor(0.1872)\n",
      "6018 Traning Loss: tensor(0.1870)\n",
      "6019 Traning Loss: tensor(0.1869)\n",
      "6020 Traning Loss: tensor(0.1867)\n",
      "6021 Traning Loss: tensor(0.1866)\n",
      "6022 Traning Loss: tensor(0.1864)\n",
      "6023 Traning Loss: tensor(0.1863)\n",
      "6024 Traning Loss: tensor(0.1861)\n",
      "6025 Traning Loss: tensor(0.1860)\n",
      "6026 Traning Loss: tensor(0.1859)\n",
      "6027 Traning Loss: tensor(0.1857)\n",
      "6028 Traning Loss: tensor(0.1856)\n",
      "6029 Traning Loss: tensor(0.1854)\n",
      "6030 Traning Loss: tensor(0.1853)\n",
      "6031 Traning Loss: tensor(0.1852)\n",
      "6032 Traning Loss: tensor(0.1851)\n",
      "6033 Traning Loss: tensor(0.1850)\n",
      "6034 Traning Loss: tensor(0.1850)\n",
      "6035 Traning Loss: tensor(0.1850)\n",
      "6036 Traning Loss: tensor(0.1852)\n",
      "6037 Traning Loss: tensor(0.1855)\n",
      "6038 Traning Loss: tensor(0.1860)\n",
      "6039 Traning Loss: tensor(0.1863)\n",
      "6040 Traning Loss: tensor(0.1860)\n",
      "6041 Traning Loss: tensor(0.1851)\n",
      "6042 Traning Loss: tensor(0.1840)\n",
      "6043 Traning Loss: tensor(0.1835)\n",
      "6044 Traning Loss: tensor(0.1837)\n",
      "6045 Traning Loss: tensor(0.1841)\n",
      "6046 Traning Loss: tensor(0.1841)\n",
      "6047 Traning Loss: tensor(0.1835)\n",
      "6048 Traning Loss: tensor(0.1829)\n",
      "6049 Traning Loss: tensor(0.1828)\n",
      "6050 Traning Loss: tensor(0.1830)\n",
      "6051 Traning Loss: tensor(0.1830)\n",
      "6052 Traning Loss: tensor(0.1827)\n",
      "6053 Traning Loss: tensor(0.1823)\n",
      "6054 Traning Loss: tensor(0.1821)\n",
      "6055 Traning Loss: tensor(0.1822)\n",
      "6056 Traning Loss: tensor(0.1822)\n",
      "6057 Traning Loss: tensor(0.1819)\n",
      "6058 Traning Loss: tensor(0.1816)\n",
      "6059 Traning Loss: tensor(0.1815)\n",
      "6060 Traning Loss: tensor(0.1815)\n",
      "6061 Traning Loss: tensor(0.1814)\n",
      "6062 Traning Loss: tensor(0.1812)\n",
      "6063 Traning Loss: tensor(0.1810)\n",
      "6064 Traning Loss: tensor(0.1809)\n",
      "6065 Traning Loss: tensor(0.1808)\n",
      "6066 Traning Loss: tensor(0.1807)\n",
      "6067 Traning Loss: tensor(0.1805)\n",
      "6068 Traning Loss: tensor(0.1804)\n",
      "6069 Traning Loss: tensor(0.1802)\n",
      "6070 Traning Loss: tensor(0.1802)\n",
      "6071 Traning Loss: tensor(0.1801)\n",
      "6072 Traning Loss: tensor(0.1799)\n",
      "6073 Traning Loss: tensor(0.1798)\n",
      "6074 Traning Loss: tensor(0.1796)\n",
      "6075 Traning Loss: tensor(0.1795)\n",
      "6076 Traning Loss: tensor(0.1794)\n",
      "6077 Traning Loss: tensor(0.1793)\n",
      "6078 Traning Loss: tensor(0.1792)\n",
      "6079 Traning Loss: tensor(0.1790)\n",
      "6080 Traning Loss: tensor(0.1789)\n",
      "6081 Traning Loss: tensor(0.1788)\n",
      "6082 Traning Loss: tensor(0.1787)\n",
      "6083 Traning Loss: tensor(0.1786)\n",
      "6084 Traning Loss: tensor(0.1785)\n",
      "6085 Traning Loss: tensor(0.1783)\n",
      "6086 Traning Loss: tensor(0.1782)\n",
      "6087 Traning Loss: tensor(0.1781)\n",
      "6088 Traning Loss: tensor(0.1780)\n",
      "6089 Traning Loss: tensor(0.1779)\n",
      "6090 Traning Loss: tensor(0.1778)\n",
      "6091 Traning Loss: tensor(0.1776)\n",
      "6092 Traning Loss: tensor(0.1775)\n",
      "6093 Traning Loss: tensor(0.1774)\n",
      "6094 Traning Loss: tensor(0.1773)\n",
      "6095 Traning Loss: tensor(0.1772)\n",
      "6096 Traning Loss: tensor(0.1771)\n",
      "6097 Traning Loss: tensor(0.1770)\n",
      "6098 Traning Loss: tensor(0.1769)\n",
      "6099 Traning Loss: tensor(0.1767)\n",
      "6100 Traning Loss: tensor(0.1766)\n",
      "6101 Traning Loss: tensor(0.1765)\n",
      "6102 Traning Loss: tensor(0.1764)\n",
      "6103 Traning Loss: tensor(0.1763)\n",
      "6104 Traning Loss: tensor(0.1762)\n",
      "6105 Traning Loss: tensor(0.1761)\n",
      "6106 Traning Loss: tensor(0.1760)\n",
      "6107 Traning Loss: tensor(0.1758)\n",
      "6108 Traning Loss: tensor(0.1757)\n",
      "6109 Traning Loss: tensor(0.1756)\n",
      "6110 Traning Loss: tensor(0.1755)\n",
      "6111 Traning Loss: tensor(0.1754)\n",
      "6112 Traning Loss: tensor(0.1753)\n",
      "6113 Traning Loss: tensor(0.1752)\n",
      "6114 Traning Loss: tensor(0.1751)\n",
      "6115 Traning Loss: tensor(0.1750)\n",
      "6116 Traning Loss: tensor(0.1749)\n",
      "6117 Traning Loss: tensor(0.1748)\n",
      "6118 Traning Loss: tensor(0.1746)\n",
      "6119 Traning Loss: tensor(0.1745)\n",
      "6120 Traning Loss: tensor(0.1744)\n",
      "6121 Traning Loss: tensor(0.1743)\n",
      "6122 Traning Loss: tensor(0.1742)\n",
      "6123 Traning Loss: tensor(0.1741)\n",
      "6124 Traning Loss: tensor(0.1740)\n",
      "6125 Traning Loss: tensor(0.1739)\n",
      "6126 Traning Loss: tensor(0.1738)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6127 Traning Loss: tensor(0.1737)\n",
      "6128 Traning Loss: tensor(0.1736)\n",
      "6129 Traning Loss: tensor(0.1735)\n",
      "6130 Traning Loss: tensor(0.1734)\n",
      "6131 Traning Loss: tensor(0.1733)\n",
      "6132 Traning Loss: tensor(0.1732)\n",
      "6133 Traning Loss: tensor(0.1731)\n",
      "6134 Traning Loss: tensor(0.1730)\n",
      "6135 Traning Loss: tensor(0.1729)\n",
      "6136 Traning Loss: tensor(0.1728)\n",
      "6137 Traning Loss: tensor(0.1726)\n",
      "6138 Traning Loss: tensor(0.1725)\n",
      "6139 Traning Loss: tensor(0.1724)\n",
      "6140 Traning Loss: tensor(0.1723)\n",
      "6141 Traning Loss: tensor(0.1722)\n",
      "6142 Traning Loss: tensor(0.1721)\n",
      "6143 Traning Loss: tensor(0.1720)\n",
      "6144 Traning Loss: tensor(0.1719)\n",
      "6145 Traning Loss: tensor(0.1718)\n",
      "6146 Traning Loss: tensor(0.1717)\n",
      "6147 Traning Loss: tensor(0.1716)\n",
      "6148 Traning Loss: tensor(0.1715)\n",
      "6149 Traning Loss: tensor(0.1714)\n",
      "6150 Traning Loss: tensor(0.1713)\n",
      "6151 Traning Loss: tensor(0.1712)\n",
      "6152 Traning Loss: tensor(0.1711)\n",
      "6153 Traning Loss: tensor(0.1710)\n",
      "6154 Traning Loss: tensor(0.1709)\n",
      "6155 Traning Loss: tensor(0.1708)\n",
      "6156 Traning Loss: tensor(0.1707)\n",
      "6157 Traning Loss: tensor(0.1706)\n",
      "6158 Traning Loss: tensor(0.1705)\n",
      "6159 Traning Loss: tensor(0.1704)\n",
      "6160 Traning Loss: tensor(0.1703)\n",
      "6161 Traning Loss: tensor(0.1703)\n",
      "6162 Traning Loss: tensor(0.1702)\n",
      "6163 Traning Loss: tensor(0.1701)\n",
      "6164 Traning Loss: tensor(0.1700)\n",
      "6165 Traning Loss: tensor(0.1699)\n",
      "6166 Traning Loss: tensor(0.1698)\n",
      "6167 Traning Loss: tensor(0.1697)\n",
      "6168 Traning Loss: tensor(0.1696)\n",
      "6169 Traning Loss: tensor(0.1695)\n",
      "6170 Traning Loss: tensor(0.1694)\n",
      "6171 Traning Loss: tensor(0.1693)\n",
      "6172 Traning Loss: tensor(0.1692)\n",
      "6173 Traning Loss: tensor(0.1691)\n",
      "6174 Traning Loss: tensor(0.1690)\n",
      "6175 Traning Loss: tensor(0.1689)\n",
      "6176 Traning Loss: tensor(0.1688)\n",
      "6177 Traning Loss: tensor(0.1687)\n",
      "6178 Traning Loss: tensor(0.1686)\n",
      "6179 Traning Loss: tensor(0.1685)\n",
      "6180 Traning Loss: tensor(0.1684)\n",
      "6181 Traning Loss: tensor(0.1684)\n",
      "6182 Traning Loss: tensor(0.1683)\n",
      "6183 Traning Loss: tensor(0.1682)\n",
      "6184 Traning Loss: tensor(0.1681)\n",
      "6185 Traning Loss: tensor(0.1680)\n",
      "6186 Traning Loss: tensor(0.1679)\n",
      "6187 Traning Loss: tensor(0.1679)\n",
      "6188 Traning Loss: tensor(0.1679)\n",
      "6189 Traning Loss: tensor(0.1680)\n",
      "6190 Traning Loss: tensor(0.1682)\n",
      "6191 Traning Loss: tensor(0.1687)\n",
      "6192 Traning Loss: tensor(0.1694)\n",
      "6193 Traning Loss: tensor(0.1703)\n",
      "6194 Traning Loss: tensor(0.1708)\n",
      "6195 Traning Loss: tensor(0.1704)\n",
      "6196 Traning Loss: tensor(0.1689)\n",
      "6197 Traning Loss: tensor(0.1676)\n",
      "6198 Traning Loss: tensor(0.1676)\n",
      "6199 Traning Loss: tensor(0.1681)\n",
      "6200 Traning Loss: tensor(0.1682)\n",
      "6201 Traning Loss: tensor(0.1677)\n",
      "6202 Traning Loss: tensor(0.1670)\n",
      "6203 Traning Loss: tensor(0.1668)\n",
      "6204 Traning Loss: tensor(0.1671)\n",
      "6205 Traning Loss: tensor(0.1673)\n",
      "6206 Traning Loss: tensor(0.1667)\n",
      "6207 Traning Loss: tensor(0.1662)\n",
      "6208 Traning Loss: tensor(0.1664)\n",
      "6209 Traning Loss: tensor(0.1667)\n",
      "6210 Traning Loss: tensor(0.1663)\n",
      "6211 Traning Loss: tensor(0.1659)\n",
      "6212 Traning Loss: tensor(0.1659)\n",
      "6213 Traning Loss: tensor(0.1660)\n",
      "6214 Traning Loss: tensor(0.1659)\n",
      "6215 Traning Loss: tensor(0.1657)\n",
      "6216 Traning Loss: tensor(0.1655)\n",
      "6217 Traning Loss: tensor(0.1654)\n",
      "6218 Traning Loss: tensor(0.1655)\n",
      "6219 Traning Loss: tensor(0.1654)\n",
      "6220 Traning Loss: tensor(0.1651)\n",
      "6221 Traning Loss: tensor(0.1651)\n",
      "6222 Traning Loss: tensor(0.1651)\n",
      "6223 Traning Loss: tensor(0.1650)\n",
      "6224 Traning Loss: tensor(0.1649)\n",
      "6225 Traning Loss: tensor(0.1648)\n",
      "6226 Traning Loss: tensor(0.1647)\n",
      "6227 Traning Loss: tensor(0.1647)\n",
      "6228 Traning Loss: tensor(0.1646)\n",
      "6229 Traning Loss: tensor(0.1645)\n",
      "6230 Traning Loss: tensor(0.1644)\n",
      "6231 Traning Loss: tensor(0.1644)\n",
      "6232 Traning Loss: tensor(0.1643)\n",
      "6233 Traning Loss: tensor(0.1642)\n",
      "6234 Traning Loss: tensor(0.1641)\n",
      "6235 Traning Loss: tensor(0.1640)\n",
      "6236 Traning Loss: tensor(0.1640)\n",
      "6237 Traning Loss: tensor(0.1639)\n",
      "6238 Traning Loss: tensor(0.1638)\n",
      "6239 Traning Loss: tensor(0.1637)\n",
      "6240 Traning Loss: tensor(0.1637)\n",
      "6241 Traning Loss: tensor(0.1636)\n",
      "6242 Traning Loss: tensor(0.1635)\n",
      "6243 Traning Loss: tensor(0.1634)\n",
      "6244 Traning Loss: tensor(0.1633)\n",
      "6245 Traning Loss: tensor(0.1633)\n",
      "6246 Traning Loss: tensor(0.1632)\n",
      "6247 Traning Loss: tensor(0.1631)\n",
      "6248 Traning Loss: tensor(0.1631)\n",
      "6249 Traning Loss: tensor(0.1630)\n",
      "6250 Traning Loss: tensor(0.1629)\n",
      "6251 Traning Loss: tensor(0.1628)\n",
      "6252 Traning Loss: tensor(0.1628)\n",
      "6253 Traning Loss: tensor(0.1627)\n",
      "6254 Traning Loss: tensor(0.1626)\n",
      "6255 Traning Loss: tensor(0.1626)\n",
      "6256 Traning Loss: tensor(0.1625)\n",
      "6257 Traning Loss: tensor(0.1624)\n",
      "6258 Traning Loss: tensor(0.1623)\n",
      "6259 Traning Loss: tensor(0.1623)\n",
      "6260 Traning Loss: tensor(0.1622)\n",
      "6261 Traning Loss: tensor(0.1621)\n",
      "6262 Traning Loss: tensor(0.1621)\n",
      "6263 Traning Loss: tensor(0.1620)\n",
      "6264 Traning Loss: tensor(0.1619)\n",
      "6265 Traning Loss: tensor(0.1619)\n",
      "6266 Traning Loss: tensor(0.1618)\n",
      "6267 Traning Loss: tensor(0.1617)\n",
      "6268 Traning Loss: tensor(0.1616)\n",
      "6269 Traning Loss: tensor(0.1616)\n",
      "6270 Traning Loss: tensor(0.1615)\n",
      "6271 Traning Loss: tensor(0.1614)\n",
      "6272 Traning Loss: tensor(0.1614)\n",
      "6273 Traning Loss: tensor(0.1613)\n",
      "6274 Traning Loss: tensor(0.1612)\n",
      "6275 Traning Loss: tensor(0.1612)\n",
      "6276 Traning Loss: tensor(0.1611)\n",
      "6277 Traning Loss: tensor(0.1610)\n",
      "6278 Traning Loss: tensor(0.1610)\n",
      "6279 Traning Loss: tensor(0.1609)\n",
      "6280 Traning Loss: tensor(0.1608)\n",
      "6281 Traning Loss: tensor(0.1607)\n",
      "6282 Traning Loss: tensor(0.1607)\n",
      "6283 Traning Loss: tensor(0.1606)\n",
      "6284 Traning Loss: tensor(0.1605)\n",
      "6285 Traning Loss: tensor(0.1605)\n",
      "6286 Traning Loss: tensor(0.1604)\n",
      "6287 Traning Loss: tensor(0.1603)\n",
      "6288 Traning Loss: tensor(0.1603)\n",
      "6289 Traning Loss: tensor(0.1602)\n",
      "6290 Traning Loss: tensor(0.1601)\n",
      "6291 Traning Loss: tensor(0.1601)\n",
      "6292 Traning Loss: tensor(0.1600)\n",
      "6293 Traning Loss: tensor(0.1599)\n",
      "6294 Traning Loss: tensor(0.1599)\n",
      "6295 Traning Loss: tensor(0.1598)\n",
      "6296 Traning Loss: tensor(0.1597)\n",
      "6297 Traning Loss: tensor(0.1597)\n",
      "6298 Traning Loss: tensor(0.1596)\n",
      "6299 Traning Loss: tensor(0.1595)\n",
      "6300 Traning Loss: tensor(0.1595)\n",
      "6301 Traning Loss: tensor(0.1594)\n",
      "6302 Traning Loss: tensor(0.1593)\n",
      "6303 Traning Loss: tensor(0.1593)\n",
      "6304 Traning Loss: tensor(0.1592)\n",
      "6305 Traning Loss: tensor(0.1592)\n",
      "6306 Traning Loss: tensor(0.1591)\n",
      "6307 Traning Loss: tensor(0.1590)\n",
      "6308 Traning Loss: tensor(0.1590)\n",
      "6309 Traning Loss: tensor(0.1589)\n",
      "6310 Traning Loss: tensor(0.1588)\n",
      "6311 Traning Loss: tensor(0.1588)\n",
      "6312 Traning Loss: tensor(0.1587)\n",
      "6313 Traning Loss: tensor(0.1586)\n",
      "6314 Traning Loss: tensor(0.1586)\n",
      "6315 Traning Loss: tensor(0.1585)\n",
      "6316 Traning Loss: tensor(0.1584)\n",
      "6317 Traning Loss: tensor(0.1584)\n",
      "6318 Traning Loss: tensor(0.1583)\n",
      "6319 Traning Loss: tensor(0.1582)\n",
      "6320 Traning Loss: tensor(0.1582)\n",
      "6321 Traning Loss: tensor(0.1581)\n",
      "6322 Traning Loss: tensor(0.1581)\n",
      "6323 Traning Loss: tensor(0.1580)\n",
      "6324 Traning Loss: tensor(0.1579)\n",
      "6325 Traning Loss: tensor(0.1579)\n",
      "6326 Traning Loss: tensor(0.1578)\n",
      "6327 Traning Loss: tensor(0.1577)\n",
      "6328 Traning Loss: tensor(0.1577)\n",
      "6329 Traning Loss: tensor(0.1576)\n",
      "6330 Traning Loss: tensor(0.1575)\n",
      "6331 Traning Loss: tensor(0.1575)\n",
      "6332 Traning Loss: tensor(0.1574)\n",
      "6333 Traning Loss: tensor(0.1574)\n",
      "6334 Traning Loss: tensor(0.1573)\n",
      "6335 Traning Loss: tensor(0.1572)\n",
      "6336 Traning Loss: tensor(0.1572)\n",
      "6337 Traning Loss: tensor(0.1571)\n",
      "6338 Traning Loss: tensor(0.1570)\n",
      "6339 Traning Loss: tensor(0.1570)\n",
      "6340 Traning Loss: tensor(0.1569)\n",
      "6341 Traning Loss: tensor(0.1569)\n",
      "6342 Traning Loss: tensor(0.1568)\n",
      "6343 Traning Loss: tensor(0.1567)\n",
      "6344 Traning Loss: tensor(0.1567)\n",
      "6345 Traning Loss: tensor(0.1566)\n",
      "6346 Traning Loss: tensor(0.1565)\n",
      "6347 Traning Loss: tensor(0.1565)\n",
      "6348 Traning Loss: tensor(0.1564)\n",
      "6349 Traning Loss: tensor(0.1564)\n",
      "6350 Traning Loss: tensor(0.1563)\n",
      "6351 Traning Loss: tensor(0.1562)\n",
      "6352 Traning Loss: tensor(0.1562)\n",
      "6353 Traning Loss: tensor(0.1561)\n",
      "6354 Traning Loss: tensor(0.1561)\n",
      "6355 Traning Loss: tensor(0.1560)\n",
      "6356 Traning Loss: tensor(0.1559)\n",
      "6357 Traning Loss: tensor(0.1559)\n",
      "6358 Traning Loss: tensor(0.1558)\n",
      "6359 Traning Loss: tensor(0.1558)\n",
      "6360 Traning Loss: tensor(0.1557)\n",
      "6361 Traning Loss: tensor(0.1556)\n",
      "6362 Traning Loss: tensor(0.1556)\n",
      "6363 Traning Loss: tensor(0.1555)\n",
      "6364 Traning Loss: tensor(0.1554)\n",
      "6365 Traning Loss: tensor(0.1554)\n",
      "6366 Traning Loss: tensor(0.1553)\n",
      "6367 Traning Loss: tensor(0.1553)\n",
      "6368 Traning Loss: tensor(0.1552)\n",
      "6369 Traning Loss: tensor(0.1551)\n",
      "6370 Traning Loss: tensor(0.1551)\n",
      "6371 Traning Loss: tensor(0.1550)\n",
      "6372 Traning Loss: tensor(0.1550)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6373 Traning Loss: tensor(0.1549)\n",
      "6374 Traning Loss: tensor(0.1548)\n",
      "6375 Traning Loss: tensor(0.1548)\n",
      "6376 Traning Loss: tensor(0.1547)\n",
      "6377 Traning Loss: tensor(0.1547)\n",
      "6378 Traning Loss: tensor(0.1546)\n",
      "6379 Traning Loss: tensor(0.1546)\n",
      "6380 Traning Loss: tensor(0.1545)\n",
      "6381 Traning Loss: tensor(0.1544)\n",
      "6382 Traning Loss: tensor(0.1544)\n",
      "6383 Traning Loss: tensor(0.1543)\n",
      "6384 Traning Loss: tensor(0.1543)\n",
      "6385 Traning Loss: tensor(0.1542)\n",
      "6386 Traning Loss: tensor(0.1541)\n",
      "6387 Traning Loss: tensor(0.1541)\n",
      "6388 Traning Loss: tensor(0.1540)\n",
      "6389 Traning Loss: tensor(0.1540)\n",
      "6390 Traning Loss: tensor(0.1539)\n",
      "6391 Traning Loss: tensor(0.1539)\n",
      "6392 Traning Loss: tensor(0.1539)\n",
      "6393 Traning Loss: tensor(0.1539)\n",
      "6394 Traning Loss: tensor(0.1540)\n",
      "6395 Traning Loss: tensor(0.1543)\n",
      "6396 Traning Loss: tensor(0.1547)\n",
      "6397 Traning Loss: tensor(0.1555)\n",
      "6398 Traning Loss: tensor(0.1564)\n",
      "6399 Traning Loss: tensor(0.1571)\n",
      "6400 Traning Loss: tensor(0.1568)\n",
      "6401 Traning Loss: tensor(0.1553)\n",
      "6402 Traning Loss: tensor(0.1536)\n",
      "6403 Traning Loss: tensor(0.1532)\n",
      "6404 Traning Loss: tensor(0.1541)\n",
      "6405 Traning Loss: tensor(0.1548)\n",
      "6406 Traning Loss: tensor(0.1545)\n",
      "6407 Traning Loss: tensor(0.1534)\n",
      "6408 Traning Loss: tensor(0.1529)\n",
      "6409 Traning Loss: tensor(0.1534)\n",
      "6410 Traning Loss: tensor(0.1538)\n",
      "6411 Traning Loss: tensor(0.1535)\n",
      "6412 Traning Loss: tensor(0.1529)\n",
      "6413 Traning Loss: tensor(0.1527)\n",
      "6414 Traning Loss: tensor(0.1530)\n",
      "6415 Traning Loss: tensor(0.1532)\n",
      "6416 Traning Loss: tensor(0.1528)\n",
      "6417 Traning Loss: tensor(0.1525)\n",
      "6418 Traning Loss: tensor(0.1525)\n",
      "6419 Traning Loss: tensor(0.1527)\n",
      "6420 Traning Loss: tensor(0.1526)\n",
      "6421 Traning Loss: tensor(0.1523)\n",
      "6422 Traning Loss: tensor(0.1522)\n",
      "6423 Traning Loss: tensor(0.1523)\n",
      "6424 Traning Loss: tensor(0.1523)\n",
      "6425 Traning Loss: tensor(0.1522)\n",
      "6426 Traning Loss: tensor(0.1520)\n",
      "6427 Traning Loss: tensor(0.1520)\n",
      "6428 Traning Loss: tensor(0.1520)\n",
      "6429 Traning Loss: tensor(0.1520)\n",
      "6430 Traning Loss: tensor(0.1518)\n",
      "6431 Traning Loss: tensor(0.1517)\n",
      "6432 Traning Loss: tensor(0.1517)\n",
      "6433 Traning Loss: tensor(0.1517)\n",
      "6434 Traning Loss: tensor(0.1517)\n",
      "6435 Traning Loss: tensor(0.1515)\n",
      "6436 Traning Loss: tensor(0.1515)\n",
      "6437 Traning Loss: tensor(0.1515)\n",
      "6438 Traning Loss: tensor(0.1514)\n",
      "6439 Traning Loss: tensor(0.1514)\n",
      "6440 Traning Loss: tensor(0.1513)\n",
      "6441 Traning Loss: tensor(0.1512)\n",
      "6442 Traning Loss: tensor(0.1512)\n",
      "6443 Traning Loss: tensor(0.1512)\n",
      "6444 Traning Loss: tensor(0.1511)\n",
      "6445 Traning Loss: tensor(0.1510)\n",
      "6446 Traning Loss: tensor(0.1510)\n",
      "6447 Traning Loss: tensor(0.1509)\n",
      "6448 Traning Loss: tensor(0.1509)\n",
      "6449 Traning Loss: tensor(0.1508)\n",
      "6450 Traning Loss: tensor(0.1508)\n",
      "6451 Traning Loss: tensor(0.1507)\n",
      "6452 Traning Loss: tensor(0.1507)\n",
      "6453 Traning Loss: tensor(0.1506)\n",
      "6454 Traning Loss: tensor(0.1506)\n",
      "6455 Traning Loss: tensor(0.1505)\n",
      "6456 Traning Loss: tensor(0.1505)\n",
      "6457 Traning Loss: tensor(0.1504)\n",
      "6458 Traning Loss: tensor(0.1504)\n",
      "6459 Traning Loss: tensor(0.1503)\n",
      "6460 Traning Loss: tensor(0.1503)\n",
      "6461 Traning Loss: tensor(0.1502)\n",
      "6462 Traning Loss: tensor(0.1502)\n",
      "6463 Traning Loss: tensor(0.1501)\n",
      "6464 Traning Loss: tensor(0.1501)\n",
      "6465 Traning Loss: tensor(0.1500)\n",
      "6466 Traning Loss: tensor(0.1500)\n",
      "6467 Traning Loss: tensor(0.1499)\n",
      "6468 Traning Loss: tensor(0.1499)\n",
      "6469 Traning Loss: tensor(0.1498)\n",
      "6470 Traning Loss: tensor(0.1498)\n",
      "6471 Traning Loss: tensor(0.1497)\n",
      "6472 Traning Loss: tensor(0.1497)\n",
      "6473 Traning Loss: tensor(0.1497)\n",
      "6474 Traning Loss: tensor(0.1496)\n",
      "6475 Traning Loss: tensor(0.1496)\n",
      "6476 Traning Loss: tensor(0.1495)\n",
      "6477 Traning Loss: tensor(0.1495)\n",
      "6478 Traning Loss: tensor(0.1494)\n",
      "6479 Traning Loss: tensor(0.1494)\n",
      "6480 Traning Loss: tensor(0.1493)\n",
      "6481 Traning Loss: tensor(0.1493)\n",
      "6482 Traning Loss: tensor(0.1492)\n",
      "6483 Traning Loss: tensor(0.1492)\n",
      "6484 Traning Loss: tensor(0.1491)\n",
      "6485 Traning Loss: tensor(0.1491)\n",
      "6486 Traning Loss: tensor(0.1490)\n",
      "6487 Traning Loss: tensor(0.1490)\n",
      "6488 Traning Loss: tensor(0.1489)\n",
      "6489 Traning Loss: tensor(0.1489)\n",
      "6490 Traning Loss: tensor(0.1488)\n",
      "6491 Traning Loss: tensor(0.1488)\n",
      "6492 Traning Loss: tensor(0.1487)\n",
      "6493 Traning Loss: tensor(0.1487)\n",
      "6494 Traning Loss: tensor(0.1486)\n",
      "6495 Traning Loss: tensor(0.1486)\n",
      "6496 Traning Loss: tensor(0.1485)\n",
      "6497 Traning Loss: tensor(0.1485)\n",
      "6498 Traning Loss: tensor(0.1484)\n",
      "6499 Traning Loss: tensor(0.1484)\n",
      "6500 Traning Loss: tensor(0.1483)\n",
      "6501 Traning Loss: tensor(0.1483)\n",
      "6502 Traning Loss: tensor(0.1482)\n",
      "6503 Traning Loss: tensor(0.1482)\n",
      "6504 Traning Loss: tensor(0.1482)\n",
      "6505 Traning Loss: tensor(0.1481)\n",
      "6506 Traning Loss: tensor(0.1481)\n",
      "6507 Traning Loss: tensor(0.1480)\n",
      "6508 Traning Loss: tensor(0.1480)\n",
      "6509 Traning Loss: tensor(0.1479)\n",
      "6510 Traning Loss: tensor(0.1479)\n",
      "6511 Traning Loss: tensor(0.1478)\n",
      "6512 Traning Loss: tensor(0.1478)\n",
      "6513 Traning Loss: tensor(0.1477)\n",
      "6514 Traning Loss: tensor(0.1477)\n",
      "6515 Traning Loss: tensor(0.1476)\n",
      "6516 Traning Loss: tensor(0.1476)\n",
      "6517 Traning Loss: tensor(0.1475)\n",
      "6518 Traning Loss: tensor(0.1475)\n",
      "6519 Traning Loss: tensor(0.1474)\n",
      "6520 Traning Loss: tensor(0.1474)\n",
      "6521 Traning Loss: tensor(0.1473)\n",
      "6522 Traning Loss: tensor(0.1473)\n",
      "6523 Traning Loss: tensor(0.1473)\n",
      "6524 Traning Loss: tensor(0.1472)\n",
      "6525 Traning Loss: tensor(0.1472)\n",
      "6526 Traning Loss: tensor(0.1471)\n",
      "6527 Traning Loss: tensor(0.1471)\n",
      "6528 Traning Loss: tensor(0.1470)\n",
      "6529 Traning Loss: tensor(0.1470)\n",
      "6530 Traning Loss: tensor(0.1469)\n",
      "6531 Traning Loss: tensor(0.1469)\n",
      "6532 Traning Loss: tensor(0.1468)\n",
      "6533 Traning Loss: tensor(0.1468)\n",
      "6534 Traning Loss: tensor(0.1467)\n",
      "6535 Traning Loss: tensor(0.1467)\n",
      "6536 Traning Loss: tensor(0.1466)\n",
      "6537 Traning Loss: tensor(0.1466)\n",
      "6538 Traning Loss: tensor(0.1465)\n",
      "6539 Traning Loss: tensor(0.1465)\n",
      "6540 Traning Loss: tensor(0.1465)\n",
      "6541 Traning Loss: tensor(0.1464)\n",
      "6542 Traning Loss: tensor(0.1464)\n",
      "6543 Traning Loss: tensor(0.1463)\n",
      "6544 Traning Loss: tensor(0.1463)\n",
      "6545 Traning Loss: tensor(0.1462)\n",
      "6546 Traning Loss: tensor(0.1462)\n",
      "6547 Traning Loss: tensor(0.1461)\n",
      "6548 Traning Loss: tensor(0.1461)\n",
      "6549 Traning Loss: tensor(0.1460)\n",
      "6550 Traning Loss: tensor(0.1460)\n",
      "6551 Traning Loss: tensor(0.1459)\n",
      "6552 Traning Loss: tensor(0.1459)\n",
      "6553 Traning Loss: tensor(0.1458)\n",
      "6554 Traning Loss: tensor(0.1458)\n",
      "6555 Traning Loss: tensor(0.1458)\n",
      "6556 Traning Loss: tensor(0.1457)\n",
      "6557 Traning Loss: tensor(0.1457)\n",
      "6558 Traning Loss: tensor(0.1456)\n",
      "6559 Traning Loss: tensor(0.1456)\n",
      "6560 Traning Loss: tensor(0.1455)\n",
      "6561 Traning Loss: tensor(0.1455)\n",
      "6562 Traning Loss: tensor(0.1454)\n",
      "6563 Traning Loss: tensor(0.1454)\n",
      "6564 Traning Loss: tensor(0.1453)\n",
      "6565 Traning Loss: tensor(0.1453)\n",
      "6566 Traning Loss: tensor(0.1452)\n",
      "6567 Traning Loss: tensor(0.1452)\n",
      "6568 Traning Loss: tensor(0.1452)\n",
      "6569 Traning Loss: tensor(0.1451)\n",
      "6570 Traning Loss: tensor(0.1451)\n",
      "6571 Traning Loss: tensor(0.1450)\n",
      "6572 Traning Loss: tensor(0.1450)\n",
      "6573 Traning Loss: tensor(0.1449)\n",
      "6574 Traning Loss: tensor(0.1449)\n",
      "6575 Traning Loss: tensor(0.1448)\n",
      "6576 Traning Loss: tensor(0.1448)\n",
      "6577 Traning Loss: tensor(0.1447)\n",
      "6578 Traning Loss: tensor(0.1447)\n",
      "6579 Traning Loss: tensor(0.1446)\n",
      "6580 Traning Loss: tensor(0.1446)\n",
      "6581 Traning Loss: tensor(0.1446)\n",
      "6582 Traning Loss: tensor(0.1445)\n",
      "6583 Traning Loss: tensor(0.1445)\n",
      "6584 Traning Loss: tensor(0.1444)\n",
      "6585 Traning Loss: tensor(0.1444)\n",
      "6586 Traning Loss: tensor(0.1443)\n",
      "6587 Traning Loss: tensor(0.1443)\n",
      "6588 Traning Loss: tensor(0.1442)\n",
      "6589 Traning Loss: tensor(0.1442)\n",
      "6590 Traning Loss: tensor(0.1441)\n",
      "6591 Traning Loss: tensor(0.1441)\n",
      "6592 Traning Loss: tensor(0.1440)\n",
      "6593 Traning Loss: tensor(0.1440)\n",
      "6594 Traning Loss: tensor(0.1440)\n",
      "6595 Traning Loss: tensor(0.1439)\n",
      "6596 Traning Loss: tensor(0.1439)\n",
      "6597 Traning Loss: tensor(0.1438)\n",
      "6598 Traning Loss: tensor(0.1438)\n",
      "6599 Traning Loss: tensor(0.1437)\n",
      "6600 Traning Loss: tensor(0.1437)\n",
      "6601 Traning Loss: tensor(0.1437)\n",
      "6602 Traning Loss: tensor(0.1436)\n",
      "6603 Traning Loss: tensor(0.1436)\n",
      "6604 Traning Loss: tensor(0.1436)\n",
      "6605 Traning Loss: tensor(0.1436)\n",
      "6606 Traning Loss: tensor(0.1437)\n",
      "6607 Traning Loss: tensor(0.1438)\n",
      "6608 Traning Loss: tensor(0.1441)\n",
      "6609 Traning Loss: tensor(0.1446)\n",
      "6610 Traning Loss: tensor(0.1453)\n",
      "6611 Traning Loss: tensor(0.1461)\n",
      "6612 Traning Loss: tensor(0.1465)\n",
      "6613 Traning Loss: tensor(0.1461)\n",
      "6614 Traning Loss: tensor(0.1448)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6615 Traning Loss: tensor(0.1434)\n",
      "6616 Traning Loss: tensor(0.1430)\n",
      "6617 Traning Loss: tensor(0.1436)\n",
      "6618 Traning Loss: tensor(0.1443)\n",
      "6619 Traning Loss: tensor(0.1443)\n",
      "6620 Traning Loss: tensor(0.1435)\n",
      "6621 Traning Loss: tensor(0.1429)\n",
      "6622 Traning Loss: tensor(0.1429)\n",
      "6623 Traning Loss: tensor(0.1433)\n",
      "6624 Traning Loss: tensor(0.1435)\n",
      "6625 Traning Loss: tensor(0.1431)\n",
      "6626 Traning Loss: tensor(0.1427)\n",
      "6627 Traning Loss: tensor(0.1426)\n",
      "6628 Traning Loss: tensor(0.1428)\n",
      "6629 Traning Loss: tensor(0.1429)\n",
      "6630 Traning Loss: tensor(0.1427)\n",
      "6631 Traning Loss: tensor(0.1424)\n",
      "6632 Traning Loss: tensor(0.1423)\n",
      "6633 Traning Loss: tensor(0.1424)\n",
      "6634 Traning Loss: tensor(0.1425)\n",
      "6635 Traning Loss: tensor(0.1424)\n",
      "6636 Traning Loss: tensor(0.1422)\n",
      "6637 Traning Loss: tensor(0.1421)\n",
      "6638 Traning Loss: tensor(0.1422)\n",
      "6639 Traning Loss: tensor(0.1422)\n",
      "6640 Traning Loss: tensor(0.1421)\n",
      "6641 Traning Loss: tensor(0.1420)\n",
      "6642 Traning Loss: tensor(0.1419)\n",
      "6643 Traning Loss: tensor(0.1419)\n",
      "6644 Traning Loss: tensor(0.1419)\n",
      "6645 Traning Loss: tensor(0.1419)\n",
      "6646 Traning Loss: tensor(0.1418)\n",
      "6647 Traning Loss: tensor(0.1417)\n",
      "6648 Traning Loss: tensor(0.1417)\n",
      "6649 Traning Loss: tensor(0.1417)\n",
      "6650 Traning Loss: tensor(0.1416)\n",
      "6651 Traning Loss: tensor(0.1416)\n",
      "6652 Traning Loss: tensor(0.1415)\n",
      "6653 Traning Loss: tensor(0.1415)\n",
      "6654 Traning Loss: tensor(0.1414)\n",
      "6655 Traning Loss: tensor(0.1414)\n",
      "6656 Traning Loss: tensor(0.1413)\n",
      "6657 Traning Loss: tensor(0.1413)\n",
      "6658 Traning Loss: tensor(0.1412)\n",
      "6659 Traning Loss: tensor(0.1412)\n",
      "6660 Traning Loss: tensor(0.1412)\n",
      "6661 Traning Loss: tensor(0.1411)\n",
      "6662 Traning Loss: tensor(0.1411)\n",
      "6663 Traning Loss: tensor(0.1410)\n",
      "6664 Traning Loss: tensor(0.1410)\n",
      "6665 Traning Loss: tensor(0.1410)\n",
      "6666 Traning Loss: tensor(0.1409)\n",
      "6667 Traning Loss: tensor(0.1409)\n",
      "6668 Traning Loss: tensor(0.1408)\n",
      "6669 Traning Loss: tensor(0.1408)\n",
      "6670 Traning Loss: tensor(0.1408)\n",
      "6671 Traning Loss: tensor(0.1407)\n",
      "6672 Traning Loss: tensor(0.1407)\n",
      "6673 Traning Loss: tensor(0.1406)\n",
      "6674 Traning Loss: tensor(0.1406)\n",
      "6675 Traning Loss: tensor(0.1406)\n",
      "6676 Traning Loss: tensor(0.1405)\n",
      "6677 Traning Loss: tensor(0.1405)\n",
      "6678 Traning Loss: tensor(0.1404)\n",
      "6679 Traning Loss: tensor(0.1404)\n",
      "6680 Traning Loss: tensor(0.1403)\n",
      "6681 Traning Loss: tensor(0.1403)\n",
      "6682 Traning Loss: tensor(0.1403)\n",
      "6683 Traning Loss: tensor(0.1402)\n",
      "6684 Traning Loss: tensor(0.1402)\n",
      "6685 Traning Loss: tensor(0.1401)\n",
      "6686 Traning Loss: tensor(0.1401)\n",
      "6687 Traning Loss: tensor(0.1401)\n",
      "6688 Traning Loss: tensor(0.1400)\n",
      "6689 Traning Loss: tensor(0.1400)\n",
      "6690 Traning Loss: tensor(0.1399)\n",
      "6691 Traning Loss: tensor(0.1399)\n",
      "6692 Traning Loss: tensor(0.1399)\n",
      "6693 Traning Loss: tensor(0.1398)\n",
      "6694 Traning Loss: tensor(0.1398)\n",
      "6695 Traning Loss: tensor(0.1397)\n",
      "6696 Traning Loss: tensor(0.1397)\n",
      "6697 Traning Loss: tensor(0.1397)\n",
      "6698 Traning Loss: tensor(0.1396)\n",
      "6699 Traning Loss: tensor(0.1396)\n",
      "6700 Traning Loss: tensor(0.1395)\n",
      "6701 Traning Loss: tensor(0.1395)\n",
      "6702 Traning Loss: tensor(0.1395)\n",
      "6703 Traning Loss: tensor(0.1394)\n",
      "6704 Traning Loss: tensor(0.1394)\n",
      "6705 Traning Loss: tensor(0.1393)\n",
      "6706 Traning Loss: tensor(0.1393)\n",
      "6707 Traning Loss: tensor(0.1393)\n",
      "6708 Traning Loss: tensor(0.1392)\n",
      "6709 Traning Loss: tensor(0.1392)\n",
      "6710 Traning Loss: tensor(0.1391)\n",
      "6711 Traning Loss: tensor(0.1391)\n",
      "6712 Traning Loss: tensor(0.1391)\n",
      "6713 Traning Loss: tensor(0.1390)\n",
      "6714 Traning Loss: tensor(0.1390)\n",
      "6715 Traning Loss: tensor(0.1389)\n",
      "6716 Traning Loss: tensor(0.1389)\n",
      "6717 Traning Loss: tensor(0.1388)\n",
      "6718 Traning Loss: tensor(0.1388)\n",
      "6719 Traning Loss: tensor(0.1388)\n",
      "6720 Traning Loss: tensor(0.1387)\n",
      "6721 Traning Loss: tensor(0.1387)\n",
      "6722 Traning Loss: tensor(0.1386)\n",
      "6723 Traning Loss: tensor(0.1386)\n",
      "6724 Traning Loss: tensor(0.1386)\n",
      "6725 Traning Loss: tensor(0.1385)\n",
      "6726 Traning Loss: tensor(0.1385)\n",
      "6727 Traning Loss: tensor(0.1384)\n",
      "6728 Traning Loss: tensor(0.1384)\n",
      "6729 Traning Loss: tensor(0.1384)\n",
      "6730 Traning Loss: tensor(0.1383)\n",
      "6731 Traning Loss: tensor(0.1383)\n",
      "6732 Traning Loss: tensor(0.1382)\n",
      "6733 Traning Loss: tensor(0.1382)\n",
      "6734 Traning Loss: tensor(0.1382)\n",
      "6735 Traning Loss: tensor(0.1382)\n",
      "6736 Traning Loss: tensor(0.1381)\n",
      "6737 Traning Loss: tensor(0.1381)\n",
      "6738 Traning Loss: tensor(0.1381)\n",
      "6739 Traning Loss: tensor(0.1382)\n",
      "6740 Traning Loss: tensor(0.1382)\n",
      "6741 Traning Loss: tensor(0.1382)\n",
      "6742 Traning Loss: tensor(0.1381)\n",
      "6743 Traning Loss: tensor(0.1379)\n",
      "6744 Traning Loss: tensor(0.1378)\n",
      "6745 Traning Loss: tensor(0.1377)\n",
      "6746 Traning Loss: tensor(0.1377)\n",
      "6747 Traning Loss: tensor(0.1377)\n",
      "6748 Traning Loss: tensor(0.1377)\n",
      "6749 Traning Loss: tensor(0.1376)\n",
      "6750 Traning Loss: tensor(0.1375)\n",
      "6751 Traning Loss: tensor(0.1375)\n",
      "6752 Traning Loss: tensor(0.1375)\n",
      "6753 Traning Loss: tensor(0.1375)\n",
      "6754 Traning Loss: tensor(0.1374)\n",
      "6755 Traning Loss: tensor(0.1374)\n",
      "6756 Traning Loss: tensor(0.1373)\n",
      "6757 Traning Loss: tensor(0.1373)\n",
      "6758 Traning Loss: tensor(0.1372)\n",
      "6759 Traning Loss: tensor(0.1372)\n",
      "6760 Traning Loss: tensor(0.1371)\n",
      "6761 Traning Loss: tensor(0.1371)\n",
      "6762 Traning Loss: tensor(0.1370)\n",
      "6763 Traning Loss: tensor(0.1370)\n",
      "6764 Traning Loss: tensor(0.1370)\n",
      "6765 Traning Loss: tensor(0.1369)\n",
      "6766 Traning Loss: tensor(0.1369)\n",
      "6767 Traning Loss: tensor(0.1368)\n",
      "6768 Traning Loss: tensor(0.1368)\n",
      "6769 Traning Loss: tensor(0.1368)\n",
      "6770 Traning Loss: tensor(0.1367)\n",
      "6771 Traning Loss: tensor(0.1367)\n",
      "6772 Traning Loss: tensor(0.1367)\n",
      "6773 Traning Loss: tensor(0.1366)\n",
      "6774 Traning Loss: tensor(0.1366)\n",
      "6775 Traning Loss: tensor(0.1365)\n",
      "6776 Traning Loss: tensor(0.1365)\n",
      "6777 Traning Loss: tensor(0.1365)\n",
      "6778 Traning Loss: tensor(0.1364)\n",
      "6779 Traning Loss: tensor(0.1364)\n",
      "6780 Traning Loss: tensor(0.1363)\n",
      "6781 Traning Loss: tensor(0.1363)\n",
      "6782 Traning Loss: tensor(0.1363)\n",
      "6783 Traning Loss: tensor(0.1362)\n",
      "6784 Traning Loss: tensor(0.1362)\n",
      "6785 Traning Loss: tensor(0.1361)\n",
      "6786 Traning Loss: tensor(0.1361)\n",
      "6787 Traning Loss: tensor(0.1361)\n",
      "6788 Traning Loss: tensor(0.1360)\n",
      "6789 Traning Loss: tensor(0.1360)\n",
      "6790 Traning Loss: tensor(0.1360)\n",
      "6791 Traning Loss: tensor(0.1359)\n",
      "6792 Traning Loss: tensor(0.1359)\n",
      "6793 Traning Loss: tensor(0.1359)\n",
      "6794 Traning Loss: tensor(0.1359)\n",
      "6795 Traning Loss: tensor(0.1360)\n",
      "6796 Traning Loss: tensor(0.1360)\n",
      "6797 Traning Loss: tensor(0.1361)\n",
      "6798 Traning Loss: tensor(0.1363)\n",
      "6799 Traning Loss: tensor(0.1364)\n",
      "6800 Traning Loss: tensor(0.1367)\n",
      "6801 Traning Loss: tensor(0.1369)\n",
      "6802 Traning Loss: tensor(0.1370)\n",
      "6803 Traning Loss: tensor(0.1369)\n",
      "6804 Traning Loss: tensor(0.1366)\n",
      "6805 Traning Loss: tensor(0.1361)\n",
      "6806 Traning Loss: tensor(0.1356)\n",
      "6807 Traning Loss: tensor(0.1353)\n",
      "6808 Traning Loss: tensor(0.1353)\n",
      "6809 Traning Loss: tensor(0.1354)\n",
      "6810 Traning Loss: tensor(0.1356)\n",
      "6811 Traning Loss: tensor(0.1357)\n",
      "6812 Traning Loss: tensor(0.1356)\n",
      "6813 Traning Loss: tensor(0.1354)\n",
      "6814 Traning Loss: tensor(0.1351)\n",
      "6815 Traning Loss: tensor(0.1350)\n",
      "6816 Traning Loss: tensor(0.1349)\n",
      "6817 Traning Loss: tensor(0.1350)\n",
      "6818 Traning Loss: tensor(0.1351)\n",
      "6819 Traning Loss: tensor(0.1351)\n",
      "6820 Traning Loss: tensor(0.1350)\n",
      "6821 Traning Loss: tensor(0.1349)\n",
      "6822 Traning Loss: tensor(0.1347)\n",
      "6823 Traning Loss: tensor(0.1347)\n",
      "6824 Traning Loss: tensor(0.1346)\n",
      "6825 Traning Loss: tensor(0.1346)\n",
      "6826 Traning Loss: tensor(0.1347)\n",
      "6827 Traning Loss: tensor(0.1346)\n",
      "6828 Traning Loss: tensor(0.1346)\n",
      "6829 Traning Loss: tensor(0.1345)\n",
      "6830 Traning Loss: tensor(0.1344)\n",
      "6831 Traning Loss: tensor(0.1344)\n",
      "6832 Traning Loss: tensor(0.1343)\n",
      "6833 Traning Loss: tensor(0.1343)\n",
      "6834 Traning Loss: tensor(0.1343)\n",
      "6835 Traning Loss: tensor(0.1343)\n",
      "6836 Traning Loss: tensor(0.1342)\n",
      "6837 Traning Loss: tensor(0.1342)\n",
      "6838 Traning Loss: tensor(0.1341)\n",
      "6839 Traning Loss: tensor(0.1341)\n",
      "6840 Traning Loss: tensor(0.1340)\n",
      "6841 Traning Loss: tensor(0.1340)\n",
      "6842 Traning Loss: tensor(0.1340)\n",
      "6843 Traning Loss: tensor(0.1339)\n",
      "6844 Traning Loss: tensor(0.1339)\n",
      "6845 Traning Loss: tensor(0.1338)\n",
      "6846 Traning Loss: tensor(0.1338)\n",
      "6847 Traning Loss: tensor(0.1338)\n",
      "6848 Traning Loss: tensor(0.1337)\n",
      "6849 Traning Loss: tensor(0.1337)\n",
      "6850 Traning Loss: tensor(0.1336)\n",
      "6851 Traning Loss: tensor(0.1336)\n",
      "6852 Traning Loss: tensor(0.1336)\n",
      "6853 Traning Loss: tensor(0.1335)\n",
      "6854 Traning Loss: tensor(0.1335)\n",
      "6855 Traning Loss: tensor(0.1335)\n",
      "6856 Traning Loss: tensor(0.1334)\n",
      "6857 Traning Loss: tensor(0.1334)\n",
      "6858 Traning Loss: tensor(0.1333)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6859 Traning Loss: tensor(0.1333)\n",
      "6860 Traning Loss: tensor(0.1333)\n",
      "6861 Traning Loss: tensor(0.1332)\n",
      "6862 Traning Loss: tensor(0.1332)\n",
      "6863 Traning Loss: tensor(0.1331)\n",
      "6864 Traning Loss: tensor(0.1331)\n",
      "6865 Traning Loss: tensor(0.1331)\n",
      "6866 Traning Loss: tensor(0.1330)\n",
      "6867 Traning Loss: tensor(0.1330)\n",
      "6868 Traning Loss: tensor(0.1330)\n",
      "6869 Traning Loss: tensor(0.1329)\n",
      "6870 Traning Loss: tensor(0.1329)\n",
      "6871 Traning Loss: tensor(0.1328)\n",
      "6872 Traning Loss: tensor(0.1328)\n",
      "6873 Traning Loss: tensor(0.1328)\n",
      "6874 Traning Loss: tensor(0.1327)\n",
      "6875 Traning Loss: tensor(0.1327)\n",
      "6876 Traning Loss: tensor(0.1326)\n",
      "6877 Traning Loss: tensor(0.1326)\n",
      "6878 Traning Loss: tensor(0.1326)\n",
      "6879 Traning Loss: tensor(0.1325)\n",
      "6880 Traning Loss: tensor(0.1325)\n",
      "6881 Traning Loss: tensor(0.1325)\n",
      "6882 Traning Loss: tensor(0.1324)\n",
      "6883 Traning Loss: tensor(0.1324)\n",
      "6884 Traning Loss: tensor(0.1323)\n",
      "6885 Traning Loss: tensor(0.1323)\n",
      "6886 Traning Loss: tensor(0.1323)\n",
      "6887 Traning Loss: tensor(0.1322)\n",
      "6888 Traning Loss: tensor(0.1322)\n",
      "6889 Traning Loss: tensor(0.1322)\n",
      "6890 Traning Loss: tensor(0.1321)\n",
      "6891 Traning Loss: tensor(0.1321)\n",
      "6892 Traning Loss: tensor(0.1320)\n",
      "6893 Traning Loss: tensor(0.1320)\n",
      "6894 Traning Loss: tensor(0.1320)\n",
      "6895 Traning Loss: tensor(0.1319)\n",
      "6896 Traning Loss: tensor(0.1319)\n",
      "6897 Traning Loss: tensor(0.1319)\n",
      "6898 Traning Loss: tensor(0.1318)\n",
      "6899 Traning Loss: tensor(0.1318)\n",
      "6900 Traning Loss: tensor(0.1317)\n",
      "6901 Traning Loss: tensor(0.1317)\n",
      "6902 Traning Loss: tensor(0.1317)\n",
      "6903 Traning Loss: tensor(0.1317)\n",
      "6904 Traning Loss: tensor(0.1317)\n",
      "6905 Traning Loss: tensor(0.1317)\n",
      "6906 Traning Loss: tensor(0.1317)\n",
      "6907 Traning Loss: tensor(0.1317)\n",
      "6908 Traning Loss: tensor(0.1318)\n",
      "6909 Traning Loss: tensor(0.1319)\n",
      "6910 Traning Loss: tensor(0.1321)\n",
      "6911 Traning Loss: tensor(0.1323)\n",
      "6912 Traning Loss: tensor(0.1326)\n",
      "6913 Traning Loss: tensor(0.1329)\n",
      "6914 Traning Loss: tensor(0.1331)\n",
      "6915 Traning Loss: tensor(0.1329)\n",
      "6916 Traning Loss: tensor(0.1325)\n",
      "6917 Traning Loss: tensor(0.1318)\n",
      "6918 Traning Loss: tensor(0.1313)\n",
      "6919 Traning Loss: tensor(0.1310)\n",
      "6920 Traning Loss: tensor(0.1311)\n",
      "6921 Traning Loss: tensor(0.1313)\n",
      "6922 Traning Loss: tensor(0.1316)\n",
      "6923 Traning Loss: tensor(0.1316)\n",
      "6924 Traning Loss: tensor(0.1313)\n",
      "6925 Traning Loss: tensor(0.1310)\n",
      "6926 Traning Loss: tensor(0.1308)\n",
      "6927 Traning Loss: tensor(0.1307)\n",
      "6928 Traning Loss: tensor(0.1308)\n",
      "6929 Traning Loss: tensor(0.1309)\n",
      "6930 Traning Loss: tensor(0.1309)\n",
      "6931 Traning Loss: tensor(0.1308)\n",
      "6932 Traning Loss: tensor(0.1307)\n",
      "6933 Traning Loss: tensor(0.1305)\n",
      "6934 Traning Loss: tensor(0.1305)\n",
      "6935 Traning Loss: tensor(0.1305)\n",
      "6936 Traning Loss: tensor(0.1305)\n",
      "6937 Traning Loss: tensor(0.1305)\n",
      "6938 Traning Loss: tensor(0.1305)\n",
      "6939 Traning Loss: tensor(0.1304)\n",
      "6940 Traning Loss: tensor(0.1303)\n",
      "6941 Traning Loss: tensor(0.1302)\n",
      "6942 Traning Loss: tensor(0.1302)\n",
      "6943 Traning Loss: tensor(0.1302)\n",
      "6944 Traning Loss: tensor(0.1302)\n",
      "6945 Traning Loss: tensor(0.1301)\n",
      "6946 Traning Loss: tensor(0.1301)\n",
      "6947 Traning Loss: tensor(0.1300)\n",
      "6948 Traning Loss: tensor(0.1300)\n",
      "6949 Traning Loss: tensor(0.1299)\n",
      "6950 Traning Loss: tensor(0.1299)\n",
      "6951 Traning Loss: tensor(0.1299)\n",
      "6952 Traning Loss: tensor(0.1298)\n",
      "6953 Traning Loss: tensor(0.1298)\n",
      "6954 Traning Loss: tensor(0.1298)\n",
      "6955 Traning Loss: tensor(0.1297)\n",
      "6956 Traning Loss: tensor(0.1297)\n",
      "6957 Traning Loss: tensor(0.1296)\n",
      "6958 Traning Loss: tensor(0.1296)\n",
      "6959 Traning Loss: tensor(0.1296)\n",
      "6960 Traning Loss: tensor(0.1295)\n",
      "6961 Traning Loss: tensor(0.1295)\n",
      "6962 Traning Loss: tensor(0.1294)\n",
      "6963 Traning Loss: tensor(0.1294)\n",
      "6964 Traning Loss: tensor(0.1294)\n",
      "6965 Traning Loss: tensor(0.1293)\n",
      "6966 Traning Loss: tensor(0.1293)\n",
      "6967 Traning Loss: tensor(0.1293)\n",
      "6968 Traning Loss: tensor(0.1292)\n",
      "6969 Traning Loss: tensor(0.1292)\n",
      "6970 Traning Loss: tensor(0.1291)\n",
      "6971 Traning Loss: tensor(0.1291)\n",
      "6972 Traning Loss: tensor(0.1291)\n",
      "6973 Traning Loss: tensor(0.1290)\n",
      "6974 Traning Loss: tensor(0.1290)\n",
      "6975 Traning Loss: tensor(0.1290)\n",
      "6976 Traning Loss: tensor(0.1289)\n",
      "6977 Traning Loss: tensor(0.1289)\n",
      "6978 Traning Loss: tensor(0.1288)\n",
      "6979 Traning Loss: tensor(0.1288)\n",
      "6980 Traning Loss: tensor(0.1288)\n",
      "6981 Traning Loss: tensor(0.1287)\n",
      "6982 Traning Loss: tensor(0.1287)\n",
      "6983 Traning Loss: tensor(0.1287)\n",
      "6984 Traning Loss: tensor(0.1286)\n",
      "6985 Traning Loss: tensor(0.1286)\n",
      "6986 Traning Loss: tensor(0.1285)\n",
      "6987 Traning Loss: tensor(0.1285)\n",
      "6988 Traning Loss: tensor(0.1285)\n",
      "6989 Traning Loss: tensor(0.1284)\n",
      "6990 Traning Loss: tensor(0.1284)\n",
      "6991 Traning Loss: tensor(0.1284)\n",
      "6992 Traning Loss: tensor(0.1283)\n",
      "6993 Traning Loss: tensor(0.1283)\n",
      "6994 Traning Loss: tensor(0.1283)\n",
      "6995 Traning Loss: tensor(0.1282)\n",
      "6996 Traning Loss: tensor(0.1282)\n",
      "6997 Traning Loss: tensor(0.1282)\n",
      "6998 Traning Loss: tensor(0.1281)\n",
      "6999 Traning Loss: tensor(0.1281)\n",
      "7000 Traning Loss: tensor(0.1281)\n",
      "7001 Traning Loss: tensor(0.1281)\n",
      "7002 Traning Loss: tensor(0.1281)\n",
      "7003 Traning Loss: tensor(0.1281)\n",
      "7004 Traning Loss: tensor(0.1280)\n",
      "7005 Traning Loss: tensor(0.1280)\n",
      "7006 Traning Loss: tensor(0.1279)\n",
      "7007 Traning Loss: tensor(0.1278)\n",
      "7008 Traning Loss: tensor(0.1277)\n",
      "7009 Traning Loss: tensor(0.1277)\n",
      "7010 Traning Loss: tensor(0.1277)\n",
      "7011 Traning Loss: tensor(0.1277)\n",
      "7012 Traning Loss: tensor(0.1276)\n",
      "7013 Traning Loss: tensor(0.1276)\n",
      "7014 Traning Loss: tensor(0.1275)\n",
      "7015 Traning Loss: tensor(0.1275)\n",
      "7016 Traning Loss: tensor(0.1274)\n",
      "7017 Traning Loss: tensor(0.1274)\n",
      "7018 Traning Loss: tensor(0.1274)\n",
      "7019 Traning Loss: tensor(0.1273)\n",
      "7020 Traning Loss: tensor(0.1273)\n",
      "7021 Traning Loss: tensor(0.1273)\n",
      "7022 Traning Loss: tensor(0.1272)\n",
      "7023 Traning Loss: tensor(0.1272)\n",
      "7024 Traning Loss: tensor(0.1271)\n",
      "7025 Traning Loss: tensor(0.1271)\n",
      "7026 Traning Loss: tensor(0.1271)\n",
      "7027 Traning Loss: tensor(0.1271)\n",
      "7028 Traning Loss: tensor(0.1271)\n",
      "7029 Traning Loss: tensor(0.1270)\n",
      "7030 Traning Loss: tensor(0.1270)\n",
      "7031 Traning Loss: tensor(0.1271)\n",
      "7032 Traning Loss: tensor(0.1271)\n",
      "7033 Traning Loss: tensor(0.1272)\n",
      "7034 Traning Loss: tensor(0.1274)\n",
      "7035 Traning Loss: tensor(0.1276)\n",
      "7036 Traning Loss: tensor(0.1278)\n",
      "7037 Traning Loss: tensor(0.1281)\n",
      "7038 Traning Loss: tensor(0.1283)\n",
      "7039 Traning Loss: tensor(0.1284)\n",
      "7040 Traning Loss: tensor(0.1282)\n",
      "7041 Traning Loss: tensor(0.1277)\n",
      "7042 Traning Loss: tensor(0.1271)\n",
      "7043 Traning Loss: tensor(0.1266)\n",
      "7044 Traning Loss: tensor(0.1264)\n",
      "7045 Traning Loss: tensor(0.1265)\n",
      "7046 Traning Loss: tensor(0.1267)\n",
      "7047 Traning Loss: tensor(0.1269)\n",
      "7048 Traning Loss: tensor(0.1269)\n",
      "7049 Traning Loss: tensor(0.1267)\n",
      "7050 Traning Loss: tensor(0.1264)\n",
      "7051 Traning Loss: tensor(0.1262)\n",
      "7052 Traning Loss: tensor(0.1261)\n",
      "7053 Traning Loss: tensor(0.1262)\n",
      "7054 Traning Loss: tensor(0.1263)\n",
      "7055 Traning Loss: tensor(0.1263)\n",
      "7056 Traning Loss: tensor(0.1262)\n",
      "7057 Traning Loss: tensor(0.1261)\n",
      "7058 Traning Loss: tensor(0.1259)\n",
      "7059 Traning Loss: tensor(0.1258)\n",
      "7060 Traning Loss: tensor(0.1258)\n",
      "7061 Traning Loss: tensor(0.1258)\n",
      "7062 Traning Loss: tensor(0.1259)\n",
      "7063 Traning Loss: tensor(0.1258)\n",
      "7064 Traning Loss: tensor(0.1258)\n",
      "7065 Traning Loss: tensor(0.1257)\n",
      "7066 Traning Loss: tensor(0.1256)\n",
      "7067 Traning Loss: tensor(0.1256)\n",
      "7068 Traning Loss: tensor(0.1255)\n",
      "7069 Traning Loss: tensor(0.1255)\n",
      "7070 Traning Loss: tensor(0.1255)\n",
      "7071 Traning Loss: tensor(0.1255)\n",
      "7072 Traning Loss: tensor(0.1254)\n",
      "7073 Traning Loss: tensor(0.1254)\n",
      "7074 Traning Loss: tensor(0.1253)\n",
      "7075 Traning Loss: tensor(0.1253)\n",
      "7076 Traning Loss: tensor(0.1252)\n",
      "7077 Traning Loss: tensor(0.1252)\n",
      "7078 Traning Loss: tensor(0.1252)\n",
      "7079 Traning Loss: tensor(0.1251)\n",
      "7080 Traning Loss: tensor(0.1251)\n",
      "7081 Traning Loss: tensor(0.1251)\n",
      "7082 Traning Loss: tensor(0.1250)\n",
      "7083 Traning Loss: tensor(0.1250)\n",
      "7084 Traning Loss: tensor(0.1249)\n",
      "7085 Traning Loss: tensor(0.1249)\n",
      "7086 Traning Loss: tensor(0.1249)\n",
      "7087 Traning Loss: tensor(0.1248)\n",
      "7088 Traning Loss: tensor(0.1248)\n",
      "7089 Traning Loss: tensor(0.1248)\n",
      "7090 Traning Loss: tensor(0.1247)\n",
      "7091 Traning Loss: tensor(0.1247)\n",
      "7092 Traning Loss: tensor(0.1246)\n",
      "7093 Traning Loss: tensor(0.1246)\n",
      "7094 Traning Loss: tensor(0.1246)\n",
      "7095 Traning Loss: tensor(0.1245)\n",
      "7096 Traning Loss: tensor(0.1245)\n",
      "7097 Traning Loss: tensor(0.1245)\n",
      "7098 Traning Loss: tensor(0.1244)\n",
      "7099 Traning Loss: tensor(0.1244)\n",
      "7100 Traning Loss: tensor(0.1244)\n",
      "7101 Traning Loss: tensor(0.1243)\n",
      "7102 Traning Loss: tensor(0.1243)\n",
      "7103 Traning Loss: tensor(0.1242)\n",
      "7104 Traning Loss: tensor(0.1242)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7105 Traning Loss: tensor(0.1242)\n",
      "7106 Traning Loss: tensor(0.1241)\n",
      "7107 Traning Loss: tensor(0.1241)\n",
      "7108 Traning Loss: tensor(0.1241)\n",
      "7109 Traning Loss: tensor(0.1240)\n",
      "7110 Traning Loss: tensor(0.1240)\n",
      "7111 Traning Loss: tensor(0.1239)\n",
      "7112 Traning Loss: tensor(0.1239)\n",
      "7113 Traning Loss: tensor(0.1239)\n",
      "7114 Traning Loss: tensor(0.1238)\n",
      "7115 Traning Loss: tensor(0.1238)\n",
      "7116 Traning Loss: tensor(0.1238)\n",
      "7117 Traning Loss: tensor(0.1237)\n",
      "7118 Traning Loss: tensor(0.1237)\n",
      "7119 Traning Loss: tensor(0.1236)\n",
      "7120 Traning Loss: tensor(0.1236)\n",
      "7121 Traning Loss: tensor(0.1236)\n",
      "7122 Traning Loss: tensor(0.1235)\n",
      "7123 Traning Loss: tensor(0.1235)\n",
      "7124 Traning Loss: tensor(0.1235)\n",
      "7125 Traning Loss: tensor(0.1234)\n",
      "7126 Traning Loss: tensor(0.1234)\n",
      "7127 Traning Loss: tensor(0.1233)\n",
      "7128 Traning Loss: tensor(0.1233)\n",
      "7129 Traning Loss: tensor(0.1233)\n",
      "7130 Traning Loss: tensor(0.1232)\n",
      "7131 Traning Loss: tensor(0.1232)\n",
      "7132 Traning Loss: tensor(0.1232)\n",
      "7133 Traning Loss: tensor(0.1231)\n",
      "7134 Traning Loss: tensor(0.1231)\n",
      "7135 Traning Loss: tensor(0.1230)\n",
      "7136 Traning Loss: tensor(0.1230)\n",
      "7137 Traning Loss: tensor(0.1230)\n",
      "7138 Traning Loss: tensor(0.1229)\n",
      "7139 Traning Loss: tensor(0.1229)\n",
      "7140 Traning Loss: tensor(0.1229)\n",
      "7141 Traning Loss: tensor(0.1228)\n",
      "7142 Traning Loss: tensor(0.1228)\n",
      "7143 Traning Loss: tensor(0.1228)\n",
      "7144 Traning Loss: tensor(0.1227)\n",
      "7145 Traning Loss: tensor(0.1227)\n",
      "7146 Traning Loss: tensor(0.1227)\n",
      "7147 Traning Loss: tensor(0.1226)\n",
      "7148 Traning Loss: tensor(0.1226)\n",
      "7149 Traning Loss: tensor(0.1226)\n",
      "7150 Traning Loss: tensor(0.1226)\n",
      "7151 Traning Loss: tensor(0.1227)\n",
      "7152 Traning Loss: tensor(0.1228)\n",
      "7153 Traning Loss: tensor(0.1229)\n",
      "7154 Traning Loss: tensor(0.1232)\n",
      "7155 Traning Loss: tensor(0.1235)\n",
      "7156 Traning Loss: tensor(0.1239)\n",
      "7157 Traning Loss: tensor(0.1243)\n",
      "7158 Traning Loss: tensor(0.1246)\n",
      "7159 Traning Loss: tensor(0.1245)\n",
      "7160 Traning Loss: tensor(0.1239)\n",
      "7161 Traning Loss: tensor(0.1231)\n",
      "7162 Traning Loss: tensor(0.1223)\n",
      "7163 Traning Loss: tensor(0.1220)\n",
      "7164 Traning Loss: tensor(0.1222)\n",
      "7165 Traning Loss: tensor(0.1226)\n",
      "7166 Traning Loss: tensor(0.1229)\n",
      "7167 Traning Loss: tensor(0.1228)\n",
      "7168 Traning Loss: tensor(0.1223)\n",
      "7169 Traning Loss: tensor(0.1219)\n",
      "7170 Traning Loss: tensor(0.1217)\n",
      "7171 Traning Loss: tensor(0.1219)\n",
      "7172 Traning Loss: tensor(0.1221)\n",
      "7173 Traning Loss: tensor(0.1221)\n",
      "7174 Traning Loss: tensor(0.1220)\n",
      "7175 Traning Loss: tensor(0.1217)\n",
      "7176 Traning Loss: tensor(0.1216)\n",
      "7177 Traning Loss: tensor(0.1215)\n",
      "7178 Traning Loss: tensor(0.1216)\n",
      "7179 Traning Loss: tensor(0.1217)\n",
      "7180 Traning Loss: tensor(0.1216)\n",
      "7181 Traning Loss: tensor(0.1215)\n",
      "7182 Traning Loss: tensor(0.1214)\n",
      "7183 Traning Loss: tensor(0.1213)\n",
      "7184 Traning Loss: tensor(0.1213)\n",
      "7185 Traning Loss: tensor(0.1213)\n",
      "7186 Traning Loss: tensor(0.1213)\n",
      "7187 Traning Loss: tensor(0.1212)\n",
      "7188 Traning Loss: tensor(0.1212)\n",
      "7189 Traning Loss: tensor(0.1211)\n",
      "7190 Traning Loss: tensor(0.1210)\n",
      "7191 Traning Loss: tensor(0.1210)\n",
      "7192 Traning Loss: tensor(0.1210)\n",
      "7193 Traning Loss: tensor(0.1210)\n",
      "7194 Traning Loss: tensor(0.1209)\n",
      "7195 Traning Loss: tensor(0.1209)\n",
      "7196 Traning Loss: tensor(0.1208)\n",
      "7197 Traning Loss: tensor(0.1208)\n",
      "7198 Traning Loss: tensor(0.1207)\n",
      "7199 Traning Loss: tensor(0.1207)\n",
      "7200 Traning Loss: tensor(0.1207)\n",
      "7201 Traning Loss: tensor(0.1206)\n",
      "7202 Traning Loss: tensor(0.1206)\n",
      "7203 Traning Loss: tensor(0.1206)\n",
      "7204 Traning Loss: tensor(0.1205)\n",
      "7205 Traning Loss: tensor(0.1205)\n",
      "7206 Traning Loss: tensor(0.1205)\n",
      "7207 Traning Loss: tensor(0.1204)\n",
      "7208 Traning Loss: tensor(0.1204)\n",
      "7209 Traning Loss: tensor(0.1203)\n",
      "7210 Traning Loss: tensor(0.1203)\n",
      "7211 Traning Loss: tensor(0.1203)\n",
      "7212 Traning Loss: tensor(0.1202)\n",
      "7213 Traning Loss: tensor(0.1202)\n",
      "7214 Traning Loss: tensor(0.1202)\n",
      "7215 Traning Loss: tensor(0.1201)\n",
      "7216 Traning Loss: tensor(0.1201)\n",
      "7217 Traning Loss: tensor(0.1200)\n",
      "7218 Traning Loss: tensor(0.1200)\n",
      "7219 Traning Loss: tensor(0.1200)\n",
      "7220 Traning Loss: tensor(0.1199)\n",
      "7221 Traning Loss: tensor(0.1199)\n",
      "7222 Traning Loss: tensor(0.1199)\n",
      "7223 Traning Loss: tensor(0.1198)\n",
      "7224 Traning Loss: tensor(0.1198)\n",
      "7225 Traning Loss: tensor(0.1198)\n",
      "7226 Traning Loss: tensor(0.1197)\n",
      "7227 Traning Loss: tensor(0.1197)\n",
      "7228 Traning Loss: tensor(0.1197)\n",
      "7229 Traning Loss: tensor(0.1197)\n",
      "7230 Traning Loss: tensor(0.1197)\n",
      "7231 Traning Loss: tensor(0.1196)\n",
      "7232 Traning Loss: tensor(0.1196)\n",
      "7233 Traning Loss: tensor(0.1196)\n",
      "7234 Traning Loss: tensor(0.1195)\n",
      "7235 Traning Loss: tensor(0.1195)\n",
      "7236 Traning Loss: tensor(0.1194)\n",
      "7237 Traning Loss: tensor(0.1193)\n",
      "7238 Traning Loss: tensor(0.1193)\n",
      "7239 Traning Loss: tensor(0.1192)\n",
      "7240 Traning Loss: tensor(0.1192)\n",
      "7241 Traning Loss: tensor(0.1192)\n",
      "7242 Traning Loss: tensor(0.1192)\n",
      "7243 Traning Loss: tensor(0.1191)\n",
      "7244 Traning Loss: tensor(0.1191)\n",
      "7245 Traning Loss: tensor(0.1190)\n",
      "7246 Traning Loss: tensor(0.1190)\n",
      "7247 Traning Loss: tensor(0.1189)\n",
      "7248 Traning Loss: tensor(0.1189)\n",
      "7249 Traning Loss: tensor(0.1189)\n",
      "7250 Traning Loss: tensor(0.1188)\n",
      "7251 Traning Loss: tensor(0.1188)\n",
      "7252 Traning Loss: tensor(0.1188)\n",
      "7253 Traning Loss: tensor(0.1187)\n",
      "7254 Traning Loss: tensor(0.1187)\n",
      "7255 Traning Loss: tensor(0.1186)\n",
      "7256 Traning Loss: tensor(0.1186)\n",
      "7257 Traning Loss: tensor(0.1186)\n",
      "7258 Traning Loss: tensor(0.1185)\n",
      "7259 Traning Loss: tensor(0.1185)\n",
      "7260 Traning Loss: tensor(0.1185)\n",
      "7261 Traning Loss: tensor(0.1184)\n",
      "7262 Traning Loss: tensor(0.1184)\n",
      "7263 Traning Loss: tensor(0.1183)\n",
      "7264 Traning Loss: tensor(0.1183)\n",
      "7265 Traning Loss: tensor(0.1183)\n",
      "7266 Traning Loss: tensor(0.1182)\n",
      "7267 Traning Loss: tensor(0.1182)\n",
      "7268 Traning Loss: tensor(0.1182)\n",
      "7269 Traning Loss: tensor(0.1181)\n",
      "7270 Traning Loss: tensor(0.1181)\n",
      "7271 Traning Loss: tensor(0.1180)\n",
      "7272 Traning Loss: tensor(0.1180)\n",
      "7273 Traning Loss: tensor(0.1180)\n",
      "7274 Traning Loss: tensor(0.1179)\n",
      "7275 Traning Loss: tensor(0.1179)\n",
      "7276 Traning Loss: tensor(0.1179)\n",
      "7277 Traning Loss: tensor(0.1178)\n",
      "7278 Traning Loss: tensor(0.1178)\n",
      "7279 Traning Loss: tensor(0.1177)\n",
      "7280 Traning Loss: tensor(0.1177)\n",
      "7281 Traning Loss: tensor(0.1177)\n",
      "7282 Traning Loss: tensor(0.1176)\n",
      "7283 Traning Loss: tensor(0.1176)\n",
      "7284 Traning Loss: tensor(0.1176)\n",
      "7285 Traning Loss: tensor(0.1175)\n",
      "7286 Traning Loss: tensor(0.1175)\n",
      "7287 Traning Loss: tensor(0.1175)\n",
      "7288 Traning Loss: tensor(0.1174)\n",
      "7289 Traning Loss: tensor(0.1174)\n",
      "7290 Traning Loss: tensor(0.1174)\n",
      "7291 Traning Loss: tensor(0.1174)\n",
      "7292 Traning Loss: tensor(0.1173)\n",
      "7293 Traning Loss: tensor(0.1174)\n",
      "7294 Traning Loss: tensor(0.1174)\n",
      "7295 Traning Loss: tensor(0.1175)\n",
      "7296 Traning Loss: tensor(0.1176)\n",
      "7297 Traning Loss: tensor(0.1178)\n",
      "7298 Traning Loss: tensor(0.1182)\n",
      "7299 Traning Loss: tensor(0.1186)\n",
      "7300 Traning Loss: tensor(0.1192)\n",
      "7301 Traning Loss: tensor(0.1196)\n",
      "7302 Traning Loss: tensor(0.1197)\n",
      "7303 Traning Loss: tensor(0.1192)\n",
      "7304 Traning Loss: tensor(0.1182)\n",
      "7305 Traning Loss: tensor(0.1173)\n",
      "7306 Traning Loss: tensor(0.1168)\n",
      "7307 Traning Loss: tensor(0.1169)\n",
      "7308 Traning Loss: tensor(0.1174)\n",
      "7309 Traning Loss: tensor(0.1177)\n",
      "7310 Traning Loss: tensor(0.1177)\n",
      "7311 Traning Loss: tensor(0.1172)\n",
      "7312 Traning Loss: tensor(0.1167)\n",
      "7313 Traning Loss: tensor(0.1165)\n",
      "7314 Traning Loss: tensor(0.1166)\n",
      "7315 Traning Loss: tensor(0.1169)\n",
      "7316 Traning Loss: tensor(0.1170)\n",
      "7317 Traning Loss: tensor(0.1168)\n",
      "7318 Traning Loss: tensor(0.1165)\n",
      "7319 Traning Loss: tensor(0.1163)\n",
      "7320 Traning Loss: tensor(0.1163)\n",
      "7321 Traning Loss: tensor(0.1164)\n",
      "7322 Traning Loss: tensor(0.1165)\n",
      "7323 Traning Loss: tensor(0.1164)\n",
      "7324 Traning Loss: tensor(0.1162)\n",
      "7325 Traning Loss: tensor(0.1161)\n",
      "7326 Traning Loss: tensor(0.1160)\n",
      "7327 Traning Loss: tensor(0.1161)\n",
      "7328 Traning Loss: tensor(0.1161)\n",
      "7329 Traning Loss: tensor(0.1161)\n",
      "7330 Traning Loss: tensor(0.1160)\n",
      "7331 Traning Loss: tensor(0.1159)\n",
      "7332 Traning Loss: tensor(0.1158)\n",
      "7333 Traning Loss: tensor(0.1158)\n",
      "7334 Traning Loss: tensor(0.1158)\n",
      "7335 Traning Loss: tensor(0.1158)\n",
      "7336 Traning Loss: tensor(0.1157)\n",
      "7337 Traning Loss: tensor(0.1157)\n",
      "7338 Traning Loss: tensor(0.1156)\n",
      "7339 Traning Loss: tensor(0.1156)\n",
      "7340 Traning Loss: tensor(0.1155)\n",
      "7341 Traning Loss: tensor(0.1155)\n",
      "7342 Traning Loss: tensor(0.1155)\n",
      "7343 Traning Loss: tensor(0.1154)\n",
      "7344 Traning Loss: tensor(0.1154)\n",
      "7345 Traning Loss: tensor(0.1153)\n",
      "7346 Traning Loss: tensor(0.1153)\n",
      "7347 Traning Loss: tensor(0.1153)\n",
      "7348 Traning Loss: tensor(0.1153)\n",
      "7349 Traning Loss: tensor(0.1152)\n",
      "7350 Traning Loss: tensor(0.1152)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7351 Traning Loss: tensor(0.1151)\n",
      "7352 Traning Loss: tensor(0.1151)\n",
      "7353 Traning Loss: tensor(0.1151)\n",
      "7354 Traning Loss: tensor(0.1150)\n",
      "7355 Traning Loss: tensor(0.1150)\n",
      "7356 Traning Loss: tensor(0.1150)\n",
      "7357 Traning Loss: tensor(0.1149)\n",
      "7358 Traning Loss: tensor(0.1149)\n",
      "7359 Traning Loss: tensor(0.1148)\n",
      "7360 Traning Loss: tensor(0.1148)\n",
      "7361 Traning Loss: tensor(0.1148)\n",
      "7362 Traning Loss: tensor(0.1147)\n",
      "7363 Traning Loss: tensor(0.1147)\n",
      "7364 Traning Loss: tensor(0.1147)\n",
      "7365 Traning Loss: tensor(0.1146)\n",
      "7366 Traning Loss: tensor(0.1146)\n",
      "7367 Traning Loss: tensor(0.1145)\n",
      "7368 Traning Loss: tensor(0.1145)\n",
      "7369 Traning Loss: tensor(0.1145)\n",
      "7370 Traning Loss: tensor(0.1144)\n",
      "7371 Traning Loss: tensor(0.1144)\n",
      "7372 Traning Loss: tensor(0.1144)\n",
      "7373 Traning Loss: tensor(0.1143)\n",
      "7374 Traning Loss: tensor(0.1143)\n",
      "7375 Traning Loss: tensor(0.1143)\n",
      "7376 Traning Loss: tensor(0.1142)\n",
      "7377 Traning Loss: tensor(0.1142)\n",
      "7378 Traning Loss: tensor(0.1141)\n",
      "7379 Traning Loss: tensor(0.1141)\n",
      "7380 Traning Loss: tensor(0.1141)\n",
      "7381 Traning Loss: tensor(0.1140)\n",
      "7382 Traning Loss: tensor(0.1140)\n",
      "7383 Traning Loss: tensor(0.1140)\n",
      "7384 Traning Loss: tensor(0.1139)\n",
      "7385 Traning Loss: tensor(0.1139)\n",
      "7386 Traning Loss: tensor(0.1139)\n",
      "7387 Traning Loss: tensor(0.1138)\n",
      "7388 Traning Loss: tensor(0.1138)\n",
      "7389 Traning Loss: tensor(0.1137)\n",
      "7390 Traning Loss: tensor(0.1137)\n",
      "7391 Traning Loss: tensor(0.1137)\n",
      "7392 Traning Loss: tensor(0.1136)\n",
      "7393 Traning Loss: tensor(0.1136)\n",
      "7394 Traning Loss: tensor(0.1136)\n",
      "7395 Traning Loss: tensor(0.1135)\n",
      "7396 Traning Loss: tensor(0.1135)\n",
      "7397 Traning Loss: tensor(0.1135)\n",
      "7398 Traning Loss: tensor(0.1134)\n",
      "7399 Traning Loss: tensor(0.1134)\n",
      "7400 Traning Loss: tensor(0.1134)\n",
      "7401 Traning Loss: tensor(0.1133)\n",
      "7402 Traning Loss: tensor(0.1133)\n",
      "7403 Traning Loss: tensor(0.1133)\n",
      "7404 Traning Loss: tensor(0.1133)\n",
      "7405 Traning Loss: tensor(0.1133)\n",
      "7406 Traning Loss: tensor(0.1133)\n",
      "7407 Traning Loss: tensor(0.1133)\n",
      "7408 Traning Loss: tensor(0.1132)\n",
      "7409 Traning Loss: tensor(0.1131)\n",
      "7410 Traning Loss: tensor(0.1130)\n",
      "7411 Traning Loss: tensor(0.1130)\n",
      "7412 Traning Loss: tensor(0.1129)\n",
      "7413 Traning Loss: tensor(0.1129)\n",
      "7414 Traning Loss: tensor(0.1129)\n",
      "7415 Traning Loss: tensor(0.1129)\n",
      "7416 Traning Loss: tensor(0.1128)\n",
      "7417 Traning Loss: tensor(0.1128)\n",
      "7418 Traning Loss: tensor(0.1127)\n",
      "7419 Traning Loss: tensor(0.1127)\n",
      "7420 Traning Loss: tensor(0.1126)\n",
      "7421 Traning Loss: tensor(0.1126)\n",
      "7422 Traning Loss: tensor(0.1126)\n",
      "7423 Traning Loss: tensor(0.1125)\n",
      "7424 Traning Loss: tensor(0.1125)\n",
      "7425 Traning Loss: tensor(0.1124)\n",
      "7426 Traning Loss: tensor(0.1124)\n",
      "7427 Traning Loss: tensor(0.1124)\n",
      "7428 Traning Loss: tensor(0.1123)\n",
      "7429 Traning Loss: tensor(0.1123)\n",
      "7430 Traning Loss: tensor(0.1123)\n",
      "7431 Traning Loss: tensor(0.1122)\n",
      "7432 Traning Loss: tensor(0.1122)\n",
      "7433 Traning Loss: tensor(0.1122)\n",
      "7434 Traning Loss: tensor(0.1121)\n",
      "7435 Traning Loss: tensor(0.1121)\n",
      "7436 Traning Loss: tensor(0.1121)\n",
      "7437 Traning Loss: tensor(0.1121)\n",
      "7438 Traning Loss: tensor(0.1121)\n",
      "7439 Traning Loss: tensor(0.1121)\n",
      "7440 Traning Loss: tensor(0.1121)\n",
      "7441 Traning Loss: tensor(0.1122)\n",
      "7442 Traning Loss: tensor(0.1124)\n",
      "7443 Traning Loss: tensor(0.1126)\n",
      "7444 Traning Loss: tensor(0.1128)\n",
      "7445 Traning Loss: tensor(0.1131)\n",
      "7446 Traning Loss: tensor(0.1134)\n",
      "7447 Traning Loss: tensor(0.1136)\n",
      "7448 Traning Loss: tensor(0.1136)\n",
      "7449 Traning Loss: tensor(0.1133)\n",
      "7450 Traning Loss: tensor(0.1127)\n",
      "7451 Traning Loss: tensor(0.1120)\n",
      "7452 Traning Loss: tensor(0.1115)\n",
      "7453 Traning Loss: tensor(0.1114)\n",
      "7454 Traning Loss: tensor(0.1116)\n",
      "7455 Traning Loss: tensor(0.1119)\n",
      "7456 Traning Loss: tensor(0.1120)\n",
      "7457 Traning Loss: tensor(0.1120)\n",
      "7458 Traning Loss: tensor(0.1117)\n",
      "7459 Traning Loss: tensor(0.1114)\n",
      "7460 Traning Loss: tensor(0.1112)\n",
      "7461 Traning Loss: tensor(0.1111)\n",
      "7462 Traning Loss: tensor(0.1112)\n",
      "7463 Traning Loss: tensor(0.1113)\n",
      "7464 Traning Loss: tensor(0.1114)\n",
      "7465 Traning Loss: tensor(0.1113)\n",
      "7466 Traning Loss: tensor(0.1111)\n",
      "7467 Traning Loss: tensor(0.1110)\n",
      "7468 Traning Loss: tensor(0.1109)\n",
      "7469 Traning Loss: tensor(0.1109)\n",
      "7470 Traning Loss: tensor(0.1109)\n",
      "7471 Traning Loss: tensor(0.1109)\n",
      "7472 Traning Loss: tensor(0.1109)\n",
      "7473 Traning Loss: tensor(0.1108)\n",
      "7474 Traning Loss: tensor(0.1107)\n",
      "7475 Traning Loss: tensor(0.1106)\n",
      "7476 Traning Loss: tensor(0.1106)\n",
      "7477 Traning Loss: tensor(0.1106)\n",
      "7478 Traning Loss: tensor(0.1106)\n",
      "7479 Traning Loss: tensor(0.1105)\n",
      "7480 Traning Loss: tensor(0.1105)\n",
      "7481 Traning Loss: tensor(0.1105)\n",
      "7482 Traning Loss: tensor(0.1104)\n",
      "7483 Traning Loss: tensor(0.1104)\n",
      "7484 Traning Loss: tensor(0.1103)\n",
      "7485 Traning Loss: tensor(0.1103)\n",
      "7486 Traning Loss: tensor(0.1102)\n",
      "7487 Traning Loss: tensor(0.1102)\n",
      "7488 Traning Loss: tensor(0.1102)\n",
      "7489 Traning Loss: tensor(0.1102)\n",
      "7490 Traning Loss: tensor(0.1101)\n",
      "7491 Traning Loss: tensor(0.1101)\n",
      "7492 Traning Loss: tensor(0.1100)\n",
      "7493 Traning Loss: tensor(0.1100)\n",
      "7494 Traning Loss: tensor(0.1099)\n",
      "7495 Traning Loss: tensor(0.1099)\n",
      "7496 Traning Loss: tensor(0.1099)\n",
      "7497 Traning Loss: tensor(0.1099)\n",
      "7498 Traning Loss: tensor(0.1098)\n",
      "7499 Traning Loss: tensor(0.1098)\n",
      "7500 Traning Loss: tensor(0.1097)\n",
      "7501 Traning Loss: tensor(0.1097)\n",
      "7502 Traning Loss: tensor(0.1097)\n",
      "7503 Traning Loss: tensor(0.1096)\n",
      "7504 Traning Loss: tensor(0.1096)\n",
      "7505 Traning Loss: tensor(0.1096)\n",
      "7506 Traning Loss: tensor(0.1095)\n",
      "7507 Traning Loss: tensor(0.1095)\n",
      "7508 Traning Loss: tensor(0.1094)\n",
      "7509 Traning Loss: tensor(0.1094)\n",
      "7510 Traning Loss: tensor(0.1094)\n",
      "7511 Traning Loss: tensor(0.1093)\n",
      "7512 Traning Loss: tensor(0.1093)\n",
      "7513 Traning Loss: tensor(0.1093)\n",
      "7514 Traning Loss: tensor(0.1092)\n",
      "7515 Traning Loss: tensor(0.1092)\n",
      "7516 Traning Loss: tensor(0.1092)\n",
      "7517 Traning Loss: tensor(0.1091)\n",
      "7518 Traning Loss: tensor(0.1091)\n",
      "7519 Traning Loss: tensor(0.1090)\n",
      "7520 Traning Loss: tensor(0.1090)\n",
      "7521 Traning Loss: tensor(0.1090)\n",
      "7522 Traning Loss: tensor(0.1089)\n",
      "7523 Traning Loss: tensor(0.1089)\n",
      "7524 Traning Loss: tensor(0.1089)\n",
      "7525 Traning Loss: tensor(0.1088)\n",
      "7526 Traning Loss: tensor(0.1088)\n",
      "7527 Traning Loss: tensor(0.1088)\n",
      "7528 Traning Loss: tensor(0.1087)\n",
      "7529 Traning Loss: tensor(0.1087)\n",
      "7530 Traning Loss: tensor(0.1087)\n",
      "7531 Traning Loss: tensor(0.1086)\n",
      "7532 Traning Loss: tensor(0.1086)\n",
      "7533 Traning Loss: tensor(0.1085)\n",
      "7534 Traning Loss: tensor(0.1085)\n",
      "7535 Traning Loss: tensor(0.1085)\n",
      "7536 Traning Loss: tensor(0.1084)\n",
      "7537 Traning Loss: tensor(0.1084)\n",
      "7538 Traning Loss: tensor(0.1084)\n",
      "7539 Traning Loss: tensor(0.1083)\n",
      "7540 Traning Loss: tensor(0.1083)\n",
      "7541 Traning Loss: tensor(0.1083)\n",
      "7542 Traning Loss: tensor(0.1082)\n",
      "7543 Traning Loss: tensor(0.1082)\n",
      "7544 Traning Loss: tensor(0.1081)\n",
      "7545 Traning Loss: tensor(0.1081)\n",
      "7546 Traning Loss: tensor(0.1081)\n",
      "7547 Traning Loss: tensor(0.1080)\n",
      "7548 Traning Loss: tensor(0.1080)\n",
      "7549 Traning Loss: tensor(0.1080)\n",
      "7550 Traning Loss: tensor(0.1079)\n",
      "7551 Traning Loss: tensor(0.1079)\n",
      "7552 Traning Loss: tensor(0.1079)\n",
      "7553 Traning Loss: tensor(0.1078)\n",
      "7554 Traning Loss: tensor(0.1078)\n",
      "7555 Traning Loss: tensor(0.1077)\n",
      "7556 Traning Loss: tensor(0.1077)\n",
      "7557 Traning Loss: tensor(0.1077)\n",
      "7558 Traning Loss: tensor(0.1077)\n",
      "7559 Traning Loss: tensor(0.1076)\n",
      "7560 Traning Loss: tensor(0.1076)\n",
      "7561 Traning Loss: tensor(0.1076)\n",
      "7562 Traning Loss: tensor(0.1076)\n",
      "7563 Traning Loss: tensor(0.1076)\n",
      "7564 Traning Loss: tensor(0.1077)\n",
      "7565 Traning Loss: tensor(0.1079)\n",
      "7566 Traning Loss: tensor(0.1081)\n",
      "7567 Traning Loss: tensor(0.1085)\n",
      "7568 Traning Loss: tensor(0.1091)\n",
      "7569 Traning Loss: tensor(0.1100)\n",
      "7570 Traning Loss: tensor(0.1108)\n",
      "7571 Traning Loss: tensor(0.1113)\n",
      "7572 Traning Loss: tensor(0.1108)\n",
      "7573 Traning Loss: tensor(0.1095)\n",
      "7574 Traning Loss: tensor(0.1079)\n",
      "7575 Traning Loss: tensor(0.1070)\n",
      "7576 Traning Loss: tensor(0.1073)\n",
      "7577 Traning Loss: tensor(0.1082)\n",
      "7578 Traning Loss: tensor(0.1087)\n",
      "7579 Traning Loss: tensor(0.1083)\n",
      "7580 Traning Loss: tensor(0.1075)\n",
      "7581 Traning Loss: tensor(0.1069)\n",
      "7582 Traning Loss: tensor(0.1069)\n",
      "7583 Traning Loss: tensor(0.1074)\n",
      "7584 Traning Loss: tensor(0.1076)\n",
      "7585 Traning Loss: tensor(0.1074)\n",
      "7586 Traning Loss: tensor(0.1069)\n",
      "7587 Traning Loss: tensor(0.1066)\n",
      "7588 Traning Loss: tensor(0.1067)\n",
      "7589 Traning Loss: tensor(0.1070)\n",
      "7590 Traning Loss: tensor(0.1070)\n",
      "7591 Traning Loss: tensor(0.1068)\n",
      "7592 Traning Loss: tensor(0.1065)\n",
      "7593 Traning Loss: tensor(0.1064)\n",
      "7594 Traning Loss: tensor(0.1065)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7595 Traning Loss: tensor(0.1066)\n",
      "7596 Traning Loss: tensor(0.1066)\n",
      "7597 Traning Loss: tensor(0.1064)\n",
      "7598 Traning Loss: tensor(0.1062)\n",
      "7599 Traning Loss: tensor(0.1062)\n",
      "7600 Traning Loss: tensor(0.1063)\n",
      "7601 Traning Loss: tensor(0.1063)\n",
      "7602 Traning Loss: tensor(0.1062)\n",
      "7603 Traning Loss: tensor(0.1061)\n",
      "7604 Traning Loss: tensor(0.1060)\n",
      "7605 Traning Loss: tensor(0.1060)\n",
      "7606 Traning Loss: tensor(0.1060)\n",
      "7607 Traning Loss: tensor(0.1060)\n",
      "7608 Traning Loss: tensor(0.1059)\n",
      "7609 Traning Loss: tensor(0.1059)\n",
      "7610 Traning Loss: tensor(0.1058)\n",
      "7611 Traning Loss: tensor(0.1058)\n",
      "7612 Traning Loss: tensor(0.1058)\n",
      "7613 Traning Loss: tensor(0.1058)\n",
      "7614 Traning Loss: tensor(0.1057)\n",
      "7615 Traning Loss: tensor(0.1057)\n",
      "7616 Traning Loss: tensor(0.1056)\n",
      "7617 Traning Loss: tensor(0.1056)\n",
      "7618 Traning Loss: tensor(0.1056)\n",
      "7619 Traning Loss: tensor(0.1055)\n",
      "7620 Traning Loss: tensor(0.1055)\n",
      "7621 Traning Loss: tensor(0.1054)\n",
      "7622 Traning Loss: tensor(0.1054)\n",
      "7623 Traning Loss: tensor(0.1054)\n",
      "7624 Traning Loss: tensor(0.1053)\n",
      "7625 Traning Loss: tensor(0.1053)\n",
      "7626 Traning Loss: tensor(0.1053)\n",
      "7627 Traning Loss: tensor(0.1052)\n",
      "7628 Traning Loss: tensor(0.1052)\n",
      "7629 Traning Loss: tensor(0.1052)\n",
      "7630 Traning Loss: tensor(0.1051)\n",
      "7631 Traning Loss: tensor(0.1051)\n",
      "7632 Traning Loss: tensor(0.1051)\n",
      "7633 Traning Loss: tensor(0.1050)\n",
      "7634 Traning Loss: tensor(0.1050)\n",
      "7635 Traning Loss: tensor(0.1050)\n",
      "7636 Traning Loss: tensor(0.1049)\n",
      "7637 Traning Loss: tensor(0.1049)\n",
      "7638 Traning Loss: tensor(0.1049)\n",
      "7639 Traning Loss: tensor(0.1048)\n",
      "7640 Traning Loss: tensor(0.1048)\n",
      "7641 Traning Loss: tensor(0.1047)\n",
      "7642 Traning Loss: tensor(0.1047)\n",
      "7643 Traning Loss: tensor(0.1047)\n",
      "7644 Traning Loss: tensor(0.1046)\n",
      "7645 Traning Loss: tensor(0.1046)\n",
      "7646 Traning Loss: tensor(0.1046)\n",
      "7647 Traning Loss: tensor(0.1045)\n",
      "7648 Traning Loss: tensor(0.1045)\n",
      "7649 Traning Loss: tensor(0.1045)\n",
      "7650 Traning Loss: tensor(0.1044)\n",
      "7651 Traning Loss: tensor(0.1044)\n",
      "7652 Traning Loss: tensor(0.1044)\n",
      "7653 Traning Loss: tensor(0.1043)\n",
      "7654 Traning Loss: tensor(0.1043)\n",
      "7655 Traning Loss: tensor(0.1043)\n",
      "7656 Traning Loss: tensor(0.1042)\n",
      "7657 Traning Loss: tensor(0.1042)\n",
      "7658 Traning Loss: tensor(0.1042)\n",
      "7659 Traning Loss: tensor(0.1041)\n",
      "7660 Traning Loss: tensor(0.1041)\n",
      "7661 Traning Loss: tensor(0.1040)\n",
      "7662 Traning Loss: tensor(0.1040)\n",
      "7663 Traning Loss: tensor(0.1040)\n",
      "7664 Traning Loss: tensor(0.1039)\n",
      "7665 Traning Loss: tensor(0.1039)\n",
      "7666 Traning Loss: tensor(0.1039)\n",
      "7667 Traning Loss: tensor(0.1038)\n",
      "7668 Traning Loss: tensor(0.1038)\n",
      "7669 Traning Loss: tensor(0.1038)\n",
      "7670 Traning Loss: tensor(0.1038)\n",
      "7671 Traning Loss: tensor(0.1038)\n",
      "7672 Traning Loss: tensor(0.1038)\n",
      "7673 Traning Loss: tensor(0.1038)\n",
      "7674 Traning Loss: tensor(0.1038)\n",
      "7675 Traning Loss: tensor(0.1039)\n",
      "7676 Traning Loss: tensor(0.1039)\n",
      "7677 Traning Loss: tensor(0.1038)\n",
      "7678 Traning Loss: tensor(0.1036)\n",
      "7679 Traning Loss: tensor(0.1035)\n",
      "7680 Traning Loss: tensor(0.1034)\n",
      "7681 Traning Loss: tensor(0.1034)\n",
      "7682 Traning Loss: tensor(0.1034)\n",
      "7683 Traning Loss: tensor(0.1034)\n",
      "7684 Traning Loss: tensor(0.1033)\n",
      "7685 Traning Loss: tensor(0.1032)\n",
      "7686 Traning Loss: tensor(0.1032)\n",
      "7687 Traning Loss: tensor(0.1032)\n",
      "7688 Traning Loss: tensor(0.1032)\n",
      "7689 Traning Loss: tensor(0.1032)\n",
      "7690 Traning Loss: tensor(0.1031)\n",
      "7691 Traning Loss: tensor(0.1030)\n",
      "7692 Traning Loss: tensor(0.1030)\n",
      "7693 Traning Loss: tensor(0.1029)\n",
      "7694 Traning Loss: tensor(0.1029)\n",
      "7695 Traning Loss: tensor(0.1029)\n",
      "7696 Traning Loss: tensor(0.1028)\n",
      "7697 Traning Loss: tensor(0.1028)\n",
      "7698 Traning Loss: tensor(0.1028)\n",
      "7699 Traning Loss: tensor(0.1027)\n",
      "7700 Traning Loss: tensor(0.1027)\n",
      "7701 Traning Loss: tensor(0.1027)\n",
      "7702 Traning Loss: tensor(0.1026)\n",
      "7703 Traning Loss: tensor(0.1026)\n",
      "7704 Traning Loss: tensor(0.1025)\n",
      "7705 Traning Loss: tensor(0.1025)\n",
      "7706 Traning Loss: tensor(0.1025)\n",
      "7707 Traning Loss: tensor(0.1025)\n",
      "7708 Traning Loss: tensor(0.1024)\n",
      "7709 Traning Loss: tensor(0.1024)\n",
      "7710 Traning Loss: tensor(0.1023)\n",
      "7711 Traning Loss: tensor(0.1023)\n",
      "7712 Traning Loss: tensor(0.1023)\n",
      "7713 Traning Loss: tensor(0.1022)\n",
      "7714 Traning Loss: tensor(0.1022)\n",
      "7715 Traning Loss: tensor(0.1022)\n",
      "7716 Traning Loss: tensor(0.1021)\n",
      "7717 Traning Loss: tensor(0.1021)\n",
      "7718 Traning Loss: tensor(0.1021)\n",
      "7719 Traning Loss: tensor(0.1020)\n",
      "7720 Traning Loss: tensor(0.1020)\n",
      "7721 Traning Loss: tensor(0.1019)\n",
      "7722 Traning Loss: tensor(0.1019)\n",
      "7723 Traning Loss: tensor(0.1019)\n",
      "7724 Traning Loss: tensor(0.1018)\n",
      "7725 Traning Loss: tensor(0.1018)\n",
      "7726 Traning Loss: tensor(0.1018)\n",
      "7727 Traning Loss: tensor(0.1017)\n",
      "7728 Traning Loss: tensor(0.1017)\n",
      "7729 Traning Loss: tensor(0.1017)\n",
      "7730 Traning Loss: tensor(0.1016)\n",
      "7731 Traning Loss: tensor(0.1016)\n",
      "7732 Traning Loss: tensor(0.1016)\n",
      "7733 Traning Loss: tensor(0.1015)\n",
      "7734 Traning Loss: tensor(0.1015)\n",
      "7735 Traning Loss: tensor(0.1015)\n",
      "7736 Traning Loss: tensor(0.1014)\n",
      "7737 Traning Loss: tensor(0.1014)\n",
      "7738 Traning Loss: tensor(0.1014)\n",
      "7739 Traning Loss: tensor(0.1014)\n",
      "7740 Traning Loss: tensor(0.1014)\n",
      "7741 Traning Loss: tensor(0.1014)\n",
      "7742 Traning Loss: tensor(0.1015)\n",
      "7743 Traning Loss: tensor(0.1016)\n",
      "7744 Traning Loss: tensor(0.1018)\n",
      "7745 Traning Loss: tensor(0.1020)\n",
      "7746 Traning Loss: tensor(0.1024)\n",
      "7747 Traning Loss: tensor(0.1030)\n",
      "7748 Traning Loss: tensor(0.1036)\n",
      "7749 Traning Loss: tensor(0.1041)\n",
      "7750 Traning Loss: tensor(0.1041)\n",
      "7751 Traning Loss: tensor(0.1036)\n",
      "7752 Traning Loss: tensor(0.1024)\n",
      "7753 Traning Loss: tensor(0.1013)\n",
      "7754 Traning Loss: tensor(0.1008)\n",
      "7755 Traning Loss: tensor(0.1010)\n",
      "7756 Traning Loss: tensor(0.1015)\n",
      "7757 Traning Loss: tensor(0.1019)\n",
      "7758 Traning Loss: tensor(0.1019)\n",
      "7759 Traning Loss: tensor(0.1014)\n",
      "7760 Traning Loss: tensor(0.1008)\n",
      "7761 Traning Loss: tensor(0.1006)\n",
      "7762 Traning Loss: tensor(0.1007)\n",
      "7763 Traning Loss: tensor(0.1010)\n",
      "7764 Traning Loss: tensor(0.1011)\n",
      "7765 Traning Loss: tensor(0.1009)\n",
      "7766 Traning Loss: tensor(0.1006)\n",
      "7767 Traning Loss: tensor(0.1004)\n",
      "7768 Traning Loss: tensor(0.1004)\n",
      "7769 Traning Loss: tensor(0.1005)\n",
      "7770 Traning Loss: tensor(0.1006)\n",
      "7771 Traning Loss: tensor(0.1005)\n",
      "7772 Traning Loss: tensor(0.1004)\n",
      "7773 Traning Loss: tensor(0.1002)\n",
      "7774 Traning Loss: tensor(0.1001)\n",
      "7775 Traning Loss: tensor(0.1001)\n",
      "7776 Traning Loss: tensor(0.1002)\n",
      "7777 Traning Loss: tensor(0.1002)\n",
      "7778 Traning Loss: tensor(0.1001)\n",
      "7779 Traning Loss: tensor(0.1000)\n",
      "7780 Traning Loss: tensor(0.0999)\n",
      "7781 Traning Loss: tensor(0.0999)\n",
      "7782 Traning Loss: tensor(0.0999)\n",
      "7783 Traning Loss: tensor(0.0999)\n",
      "7784 Traning Loss: tensor(0.0999)\n",
      "7785 Traning Loss: tensor(0.0998)\n",
      "7786 Traning Loss: tensor(0.0997)\n",
      "7787 Traning Loss: tensor(0.0997)\n",
      "7788 Traning Loss: tensor(0.0997)\n",
      "7789 Traning Loss: tensor(0.0996)\n",
      "7790 Traning Loss: tensor(0.0996)\n",
      "7791 Traning Loss: tensor(0.0996)\n",
      "7792 Traning Loss: tensor(0.0995)\n",
      "7793 Traning Loss: tensor(0.0995)\n",
      "7794 Traning Loss: tensor(0.0995)\n",
      "7795 Traning Loss: tensor(0.0994)\n",
      "7796 Traning Loss: tensor(0.0994)\n",
      "7797 Traning Loss: tensor(0.0994)\n",
      "7798 Traning Loss: tensor(0.0993)\n",
      "7799 Traning Loss: tensor(0.0993)\n",
      "7800 Traning Loss: tensor(0.0993)\n",
      "7801 Traning Loss: tensor(0.0992)\n",
      "7802 Traning Loss: tensor(0.0992)\n",
      "7803 Traning Loss: tensor(0.0991)\n",
      "7804 Traning Loss: tensor(0.0991)\n",
      "7805 Traning Loss: tensor(0.0991)\n",
      "7806 Traning Loss: tensor(0.0991)\n",
      "7807 Traning Loss: tensor(0.0990)\n",
      "7808 Traning Loss: tensor(0.0990)\n",
      "7809 Traning Loss: tensor(0.0989)\n",
      "7810 Traning Loss: tensor(0.0989)\n",
      "7811 Traning Loss: tensor(0.0989)\n",
      "7812 Traning Loss: tensor(0.0988)\n",
      "7813 Traning Loss: tensor(0.0988)\n",
      "7814 Traning Loss: tensor(0.0988)\n",
      "7815 Traning Loss: tensor(0.0987)\n",
      "7816 Traning Loss: tensor(0.0987)\n",
      "7817 Traning Loss: tensor(0.0987)\n",
      "7818 Traning Loss: tensor(0.0986)\n",
      "7819 Traning Loss: tensor(0.0986)\n",
      "7820 Traning Loss: tensor(0.0986)\n",
      "7821 Traning Loss: tensor(0.0985)\n",
      "7822 Traning Loss: tensor(0.0985)\n",
      "7823 Traning Loss: tensor(0.0985)\n",
      "7824 Traning Loss: tensor(0.0984)\n",
      "7825 Traning Loss: tensor(0.0984)\n",
      "7826 Traning Loss: tensor(0.0984)\n",
      "7827 Traning Loss: tensor(0.0983)\n",
      "7828 Traning Loss: tensor(0.0983)\n",
      "7829 Traning Loss: tensor(0.0983)\n",
      "7830 Traning Loss: tensor(0.0982)\n",
      "7831 Traning Loss: tensor(0.0982)\n",
      "7832 Traning Loss: tensor(0.0982)\n",
      "7833 Traning Loss: tensor(0.0981)\n",
      "7834 Traning Loss: tensor(0.0981)\n",
      "7835 Traning Loss: tensor(0.0981)\n",
      "7836 Traning Loss: tensor(0.0980)\n",
      "7837 Traning Loss: tensor(0.0980)\n",
      "7838 Traning Loss: tensor(0.0980)\n",
      "7839 Traning Loss: tensor(0.0979)\n",
      "7840 Traning Loss: tensor(0.0979)\n",
      "7841 Traning Loss: tensor(0.0979)\n",
      "7842 Traning Loss: tensor(0.0978)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7843 Traning Loss: tensor(0.0978)\n",
      "7844 Traning Loss: tensor(0.0977)\n",
      "7845 Traning Loss: tensor(0.0977)\n",
      "7846 Traning Loss: tensor(0.0977)\n",
      "7847 Traning Loss: tensor(0.0976)\n",
      "7848 Traning Loss: tensor(0.0976)\n",
      "7849 Traning Loss: tensor(0.0976)\n",
      "7850 Traning Loss: tensor(0.0975)\n",
      "7851 Traning Loss: tensor(0.0975)\n",
      "7852 Traning Loss: tensor(0.0975)\n",
      "7853 Traning Loss: tensor(0.0974)\n",
      "7854 Traning Loss: tensor(0.0974)\n",
      "7855 Traning Loss: tensor(0.0974)\n",
      "7856 Traning Loss: tensor(0.0973)\n",
      "7857 Traning Loss: tensor(0.0973)\n",
      "7858 Traning Loss: tensor(0.0973)\n",
      "7859 Traning Loss: tensor(0.0972)\n",
      "7860 Traning Loss: tensor(0.0972)\n",
      "7861 Traning Loss: tensor(0.0972)\n",
      "7862 Traning Loss: tensor(0.0971)\n",
      "7863 Traning Loss: tensor(0.0971)\n",
      "7864 Traning Loss: tensor(0.0971)\n",
      "7865 Traning Loss: tensor(0.0970)\n",
      "7866 Traning Loss: tensor(0.0970)\n",
      "7867 Traning Loss: tensor(0.0970)\n",
      "7868 Traning Loss: tensor(0.0969)\n",
      "7869 Traning Loss: tensor(0.0969)\n",
      "7870 Traning Loss: tensor(0.0969)\n",
      "7871 Traning Loss: tensor(0.0968)\n",
      "7872 Traning Loss: tensor(0.0968)\n",
      "7873 Traning Loss: tensor(0.0968)\n",
      "7874 Traning Loss: tensor(0.0967)\n",
      "7875 Traning Loss: tensor(0.0967)\n",
      "7876 Traning Loss: tensor(0.0966)\n",
      "7877 Traning Loss: tensor(0.0966)\n",
      "7878 Traning Loss: tensor(0.0966)\n",
      "7879 Traning Loss: tensor(0.0965)\n",
      "7880 Traning Loss: tensor(0.0965)\n",
      "7881 Traning Loss: tensor(0.0965)\n",
      "7882 Traning Loss: tensor(0.0964)\n",
      "7883 Traning Loss: tensor(0.0964)\n",
      "7884 Traning Loss: tensor(0.0964)\n",
      "7885 Traning Loss: tensor(0.0964)\n",
      "7886 Traning Loss: tensor(0.0963)\n",
      "7887 Traning Loss: tensor(0.0963)\n",
      "7888 Traning Loss: tensor(0.0963)\n",
      "7889 Traning Loss: tensor(0.0963)\n",
      "7890 Traning Loss: tensor(0.0964)\n",
      "7891 Traning Loss: tensor(0.0964)\n",
      "7892 Traning Loss: tensor(0.0966)\n",
      "7893 Traning Loss: tensor(0.0967)\n",
      "7894 Traning Loss: tensor(0.0968)\n",
      "7895 Traning Loss: tensor(0.0969)\n",
      "7896 Traning Loss: tensor(0.0969)\n",
      "7897 Traning Loss: tensor(0.0971)\n",
      "7898 Traning Loss: tensor(0.0977)\n",
      "7899 Traning Loss: tensor(0.0984)\n",
      "7900 Traning Loss: tensor(0.0991)\n",
      "7901 Traning Loss: tensor(0.0993)\n",
      "7902 Traning Loss: tensor(0.0990)\n",
      "7903 Traning Loss: tensor(0.0979)\n",
      "7904 Traning Loss: tensor(0.0969)\n",
      "7905 Traning Loss: tensor(0.0961)\n",
      "7906 Traning Loss: tensor(0.0958)\n",
      "7907 Traning Loss: tensor(0.0961)\n",
      "7908 Traning Loss: tensor(0.0967)\n",
      "7909 Traning Loss: tensor(0.0970)\n",
      "7910 Traning Loss: tensor(0.0967)\n",
      "7911 Traning Loss: tensor(0.0960)\n",
      "7912 Traning Loss: tensor(0.0955)\n",
      "7913 Traning Loss: tensor(0.0955)\n",
      "7914 Traning Loss: tensor(0.0958)\n",
      "7915 Traning Loss: tensor(0.0960)\n",
      "7916 Traning Loss: tensor(0.0959)\n",
      "7917 Traning Loss: tensor(0.0957)\n",
      "7918 Traning Loss: tensor(0.0954)\n",
      "7919 Traning Loss: tensor(0.0953)\n",
      "7920 Traning Loss: tensor(0.0953)\n",
      "7921 Traning Loss: tensor(0.0954)\n",
      "7922 Traning Loss: tensor(0.0955)\n",
      "7923 Traning Loss: tensor(0.0954)\n",
      "7924 Traning Loss: tensor(0.0952)\n",
      "7925 Traning Loss: tensor(0.0950)\n",
      "7926 Traning Loss: tensor(0.0950)\n",
      "7927 Traning Loss: tensor(0.0951)\n",
      "7928 Traning Loss: tensor(0.0951)\n",
      "7929 Traning Loss: tensor(0.0950)\n",
      "7930 Traning Loss: tensor(0.0950)\n",
      "7931 Traning Loss: tensor(0.0949)\n",
      "7932 Traning Loss: tensor(0.0948)\n",
      "7933 Traning Loss: tensor(0.0948)\n",
      "7934 Traning Loss: tensor(0.0948)\n",
      "7935 Traning Loss: tensor(0.0948)\n",
      "7936 Traning Loss: tensor(0.0947)\n",
      "7937 Traning Loss: tensor(0.0947)\n",
      "7938 Traning Loss: tensor(0.0946)\n",
      "7939 Traning Loss: tensor(0.0946)\n",
      "7940 Traning Loss: tensor(0.0946)\n",
      "7941 Traning Loss: tensor(0.0945)\n",
      "7942 Traning Loss: tensor(0.0945)\n",
      "7943 Traning Loss: tensor(0.0945)\n",
      "7944 Traning Loss: tensor(0.0944)\n",
      "7945 Traning Loss: tensor(0.0944)\n",
      "7946 Traning Loss: tensor(0.0943)\n",
      "7947 Traning Loss: tensor(0.0943)\n",
      "7948 Traning Loss: tensor(0.0943)\n",
      "7949 Traning Loss: tensor(0.0943)\n",
      "7950 Traning Loss: tensor(0.0942)\n",
      "7951 Traning Loss: tensor(0.0942)\n",
      "7952 Traning Loss: tensor(0.0941)\n",
      "7953 Traning Loss: tensor(0.0941)\n",
      "7954 Traning Loss: tensor(0.0941)\n",
      "7955 Traning Loss: tensor(0.0940)\n",
      "7956 Traning Loss: tensor(0.0940)\n",
      "7957 Traning Loss: tensor(0.0940)\n",
      "7958 Traning Loss: tensor(0.0940)\n",
      "7959 Traning Loss: tensor(0.0939)\n",
      "7960 Traning Loss: tensor(0.0939)\n",
      "7961 Traning Loss: tensor(0.0938)\n",
      "7962 Traning Loss: tensor(0.0938)\n",
      "7963 Traning Loss: tensor(0.0938)\n",
      "7964 Traning Loss: tensor(0.0938)\n",
      "7965 Traning Loss: tensor(0.0937)\n",
      "7966 Traning Loss: tensor(0.0937)\n",
      "7967 Traning Loss: tensor(0.0937)\n",
      "7968 Traning Loss: tensor(0.0936)\n",
      "7969 Traning Loss: tensor(0.0936)\n",
      "7970 Traning Loss: tensor(0.0936)\n",
      "7971 Traning Loss: tensor(0.0935)\n",
      "7972 Traning Loss: tensor(0.0935)\n",
      "7973 Traning Loss: tensor(0.0935)\n",
      "7974 Traning Loss: tensor(0.0934)\n",
      "7975 Traning Loss: tensor(0.0934)\n",
      "7976 Traning Loss: tensor(0.0934)\n",
      "7977 Traning Loss: tensor(0.0933)\n",
      "7978 Traning Loss: tensor(0.0933)\n",
      "7979 Traning Loss: tensor(0.0933)\n",
      "7980 Traning Loss: tensor(0.0932)\n",
      "7981 Traning Loss: tensor(0.0932)\n",
      "7982 Traning Loss: tensor(0.0932)\n",
      "7983 Traning Loss: tensor(0.0931)\n",
      "7984 Traning Loss: tensor(0.0931)\n",
      "7985 Traning Loss: tensor(0.0931)\n",
      "7986 Traning Loss: tensor(0.0930)\n",
      "7987 Traning Loss: tensor(0.0930)\n",
      "7988 Traning Loss: tensor(0.0930)\n",
      "7989 Traning Loss: tensor(0.0929)\n",
      "7990 Traning Loss: tensor(0.0929)\n",
      "7991 Traning Loss: tensor(0.0929)\n",
      "7992 Traning Loss: tensor(0.0928)\n",
      "7993 Traning Loss: tensor(0.0928)\n",
      "7994 Traning Loss: tensor(0.0928)\n",
      "7995 Traning Loss: tensor(0.0927)\n",
      "7996 Traning Loss: tensor(0.0927)\n",
      "7997 Traning Loss: tensor(0.0927)\n",
      "7998 Traning Loss: tensor(0.0926)\n",
      "7999 Traning Loss: tensor(0.0926)\n",
      "8000 Traning Loss: tensor(0.0926)\n",
      "8001 Traning Loss: tensor(0.0925)\n",
      "8002 Traning Loss: tensor(0.0925)\n",
      "8003 Traning Loss: tensor(0.0925)\n",
      "8004 Traning Loss: tensor(0.0924)\n",
      "8005 Traning Loss: tensor(0.0924)\n",
      "8006 Traning Loss: tensor(0.0924)\n",
      "8007 Traning Loss: tensor(0.0923)\n",
      "8008 Traning Loss: tensor(0.0923)\n",
      "8009 Traning Loss: tensor(0.0923)\n",
      "8010 Traning Loss: tensor(0.0922)\n",
      "8011 Traning Loss: tensor(0.0922)\n",
      "8012 Traning Loss: tensor(0.0922)\n",
      "8013 Traning Loss: tensor(0.0921)\n",
      "8014 Traning Loss: tensor(0.0921)\n",
      "8015 Traning Loss: tensor(0.0921)\n",
      "8016 Traning Loss: tensor(0.0920)\n",
      "8017 Traning Loss: tensor(0.0920)\n",
      "8018 Traning Loss: tensor(0.0920)\n",
      "8019 Traning Loss: tensor(0.0919)\n",
      "8020 Traning Loss: tensor(0.0919)\n",
      "8021 Traning Loss: tensor(0.0919)\n",
      "8022 Traning Loss: tensor(0.0918)\n",
      "8023 Traning Loss: tensor(0.0918)\n",
      "8024 Traning Loss: tensor(0.0918)\n",
      "8025 Traning Loss: tensor(0.0918)\n",
      "8026 Traning Loss: tensor(0.0917)\n",
      "8027 Traning Loss: tensor(0.0917)\n",
      "8028 Traning Loss: tensor(0.0917)\n",
      "8029 Traning Loss: tensor(0.0916)\n",
      "8030 Traning Loss: tensor(0.0916)\n",
      "8031 Traning Loss: tensor(0.0916)\n",
      "8032 Traning Loss: tensor(0.0915)\n",
      "8033 Traning Loss: tensor(0.0915)\n",
      "8034 Traning Loss: tensor(0.0915)\n",
      "8035 Traning Loss: tensor(0.0914)\n",
      "8036 Traning Loss: tensor(0.0914)\n",
      "8037 Traning Loss: tensor(0.0914)\n",
      "8038 Traning Loss: tensor(0.0913)\n",
      "8039 Traning Loss: tensor(0.0913)\n",
      "8040 Traning Loss: tensor(0.0913)\n",
      "8041 Traning Loss: tensor(0.0912)\n",
      "8042 Traning Loss: tensor(0.0912)\n",
      "8043 Traning Loss: tensor(0.0912)\n",
      "8044 Traning Loss: tensor(0.0912)\n",
      "8045 Traning Loss: tensor(0.0911)\n",
      "8046 Traning Loss: tensor(0.0911)\n",
      "8047 Traning Loss: tensor(0.0912)\n",
      "8048 Traning Loss: tensor(0.0912)\n",
      "8049 Traning Loss: tensor(0.0913)\n",
      "8050 Traning Loss: tensor(0.0915)\n",
      "8051 Traning Loss: tensor(0.0918)\n",
      "8052 Traning Loss: tensor(0.0923)\n",
      "8053 Traning Loss: tensor(0.0930)\n",
      "8054 Traning Loss: tensor(0.0939)\n",
      "8055 Traning Loss: tensor(0.0948)\n",
      "8056 Traning Loss: tensor(0.0952)\n",
      "8057 Traning Loss: tensor(0.0948)\n",
      "8058 Traning Loss: tensor(0.0933)\n",
      "8059 Traning Loss: tensor(0.0916)\n",
      "8060 Traning Loss: tensor(0.0906)\n",
      "8061 Traning Loss: tensor(0.0909)\n",
      "8062 Traning Loss: tensor(0.0918)\n",
      "8063 Traning Loss: tensor(0.0924)\n",
      "8064 Traning Loss: tensor(0.0922)\n",
      "8065 Traning Loss: tensor(0.0913)\n",
      "8066 Traning Loss: tensor(0.0905)\n",
      "8067 Traning Loss: tensor(0.0905)\n",
      "8068 Traning Loss: tensor(0.0909)\n",
      "8069 Traning Loss: tensor(0.0913)\n",
      "8070 Traning Loss: tensor(0.0912)\n",
      "8071 Traning Loss: tensor(0.0907)\n",
      "8072 Traning Loss: tensor(0.0903)\n",
      "8073 Traning Loss: tensor(0.0903)\n",
      "8074 Traning Loss: tensor(0.0905)\n",
      "8075 Traning Loss: tensor(0.0907)\n",
      "8076 Traning Loss: tensor(0.0905)\n",
      "8077 Traning Loss: tensor(0.0902)\n",
      "8078 Traning Loss: tensor(0.0901)\n",
      "8079 Traning Loss: tensor(0.0901)\n",
      "8080 Traning Loss: tensor(0.0902)\n",
      "8081 Traning Loss: tensor(0.0902)\n",
      "8082 Traning Loss: tensor(0.0901)\n",
      "8083 Traning Loss: tensor(0.0900)\n",
      "8084 Traning Loss: tensor(0.0899)\n",
      "8085 Traning Loss: tensor(0.0899)\n",
      "8086 Traning Loss: tensor(0.0899)\n",
      "8087 Traning Loss: tensor(0.0899)\n",
      "8088 Traning Loss: tensor(0.0898)\n",
      "8089 Traning Loss: tensor(0.0897)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8090 Traning Loss: tensor(0.0897)\n",
      "8091 Traning Loss: tensor(0.0897)\n",
      "8092 Traning Loss: tensor(0.0897)\n",
      "8093 Traning Loss: tensor(0.0897)\n",
      "8094 Traning Loss: tensor(0.0896)\n",
      "8095 Traning Loss: tensor(0.0895)\n",
      "8096 Traning Loss: tensor(0.0895)\n",
      "8097 Traning Loss: tensor(0.0895)\n",
      "8098 Traning Loss: tensor(0.0895)\n",
      "8099 Traning Loss: tensor(0.0894)\n",
      "8100 Traning Loss: tensor(0.0894)\n",
      "8101 Traning Loss: tensor(0.0893)\n",
      "8102 Traning Loss: tensor(0.0893)\n",
      "8103 Traning Loss: tensor(0.0893)\n",
      "8104 Traning Loss: tensor(0.0892)\n",
      "8105 Traning Loss: tensor(0.0892)\n",
      "8106 Traning Loss: tensor(0.0892)\n",
      "8107 Traning Loss: tensor(0.0891)\n",
      "8108 Traning Loss: tensor(0.0891)\n",
      "8109 Traning Loss: tensor(0.0891)\n",
      "8110 Traning Loss: tensor(0.0890)\n",
      "8111 Traning Loss: tensor(0.0890)\n",
      "8112 Traning Loss: tensor(0.0890)\n",
      "8113 Traning Loss: tensor(0.0889)\n",
      "8114 Traning Loss: tensor(0.0889)\n",
      "8115 Traning Loss: tensor(0.0889)\n",
      "8116 Traning Loss: tensor(0.0889)\n",
      "8117 Traning Loss: tensor(0.0888)\n",
      "8118 Traning Loss: tensor(0.0888)\n",
      "8119 Traning Loss: tensor(0.0888)\n",
      "8120 Traning Loss: tensor(0.0887)\n",
      "8121 Traning Loss: tensor(0.0887)\n",
      "8122 Traning Loss: tensor(0.0887)\n",
      "8123 Traning Loss: tensor(0.0886)\n",
      "8124 Traning Loss: tensor(0.0886)\n",
      "8125 Traning Loss: tensor(0.0886)\n",
      "8126 Traning Loss: tensor(0.0885)\n",
      "8127 Traning Loss: tensor(0.0885)\n",
      "8128 Traning Loss: tensor(0.0885)\n",
      "8129 Traning Loss: tensor(0.0884)\n",
      "8130 Traning Loss: tensor(0.0884)\n",
      "8131 Traning Loss: tensor(0.0884)\n",
      "8132 Traning Loss: tensor(0.0883)\n",
      "8133 Traning Loss: tensor(0.0883)\n",
      "8134 Traning Loss: tensor(0.0883)\n",
      "8135 Traning Loss: tensor(0.0882)\n",
      "8136 Traning Loss: tensor(0.0882)\n",
      "8137 Traning Loss: tensor(0.0882)\n",
      "8138 Traning Loss: tensor(0.0882)\n",
      "8139 Traning Loss: tensor(0.0881)\n",
      "8140 Traning Loss: tensor(0.0881)\n",
      "8141 Traning Loss: tensor(0.0881)\n",
      "8142 Traning Loss: tensor(0.0880)\n",
      "8143 Traning Loss: tensor(0.0880)\n",
      "8144 Traning Loss: tensor(0.0880)\n",
      "8145 Traning Loss: tensor(0.0879)\n",
      "8146 Traning Loss: tensor(0.0879)\n",
      "8147 Traning Loss: tensor(0.0879)\n",
      "8148 Traning Loss: tensor(0.0878)\n",
      "8149 Traning Loss: tensor(0.0878)\n",
      "8150 Traning Loss: tensor(0.0878)\n",
      "8151 Traning Loss: tensor(0.0877)\n",
      "8152 Traning Loss: tensor(0.0877)\n",
      "8153 Traning Loss: tensor(0.0877)\n",
      "8154 Traning Loss: tensor(0.0876)\n",
      "8155 Traning Loss: tensor(0.0876)\n",
      "8156 Traning Loss: tensor(0.0876)\n",
      "8157 Traning Loss: tensor(0.0876)\n",
      "8158 Traning Loss: tensor(0.0875)\n",
      "8159 Traning Loss: tensor(0.0875)\n",
      "8160 Traning Loss: tensor(0.0875)\n",
      "8161 Traning Loss: tensor(0.0874)\n",
      "8162 Traning Loss: tensor(0.0874)\n",
      "8163 Traning Loss: tensor(0.0874)\n",
      "8164 Traning Loss: tensor(0.0873)\n",
      "8165 Traning Loss: tensor(0.0873)\n",
      "8166 Traning Loss: tensor(0.0873)\n",
      "8167 Traning Loss: tensor(0.0872)\n",
      "8168 Traning Loss: tensor(0.0872)\n",
      "8169 Traning Loss: tensor(0.0872)\n",
      "8170 Traning Loss: tensor(0.0871)\n",
      "8171 Traning Loss: tensor(0.0871)\n",
      "8172 Traning Loss: tensor(0.0871)\n",
      "8173 Traning Loss: tensor(0.0870)\n",
      "8174 Traning Loss: tensor(0.0870)\n",
      "8175 Traning Loss: tensor(0.0870)\n",
      "8176 Traning Loss: tensor(0.0870)\n",
      "8177 Traning Loss: tensor(0.0869)\n",
      "8178 Traning Loss: tensor(0.0869)\n",
      "8179 Traning Loss: tensor(0.0869)\n",
      "8180 Traning Loss: tensor(0.0868)\n",
      "8181 Traning Loss: tensor(0.0868)\n",
      "8182 Traning Loss: tensor(0.0868)\n",
      "8183 Traning Loss: tensor(0.0867)\n",
      "8184 Traning Loss: tensor(0.0867)\n",
      "8185 Traning Loss: tensor(0.0867)\n",
      "8186 Traning Loss: tensor(0.0866)\n",
      "8187 Traning Loss: tensor(0.0866)\n",
      "8188 Traning Loss: tensor(0.0866)\n",
      "8189 Traning Loss: tensor(0.0865)\n",
      "8190 Traning Loss: tensor(0.0865)\n",
      "8191 Traning Loss: tensor(0.0865)\n",
      "8192 Traning Loss: tensor(0.0864)\n",
      "8193 Traning Loss: tensor(0.0864)\n",
      "8194 Traning Loss: tensor(0.0864)\n",
      "8195 Traning Loss: tensor(0.0863)\n",
      "8196 Traning Loss: tensor(0.0863)\n",
      "8197 Traning Loss: tensor(0.0863)\n",
      "8198 Traning Loss: tensor(0.0863)\n",
      "8199 Traning Loss: tensor(0.0862)\n",
      "8200 Traning Loss: tensor(0.0862)\n",
      "8201 Traning Loss: tensor(0.0862)\n",
      "8202 Traning Loss: tensor(0.0861)\n",
      "8203 Traning Loss: tensor(0.0861)\n",
      "8204 Traning Loss: tensor(0.0861)\n",
      "8205 Traning Loss: tensor(0.0860)\n",
      "8206 Traning Loss: tensor(0.0860)\n",
      "8207 Traning Loss: tensor(0.0860)\n",
      "8208 Traning Loss: tensor(0.0860)\n",
      "8209 Traning Loss: tensor(0.0860)\n",
      "8210 Traning Loss: tensor(0.0860)\n",
      "8211 Traning Loss: tensor(0.0860)\n",
      "8212 Traning Loss: tensor(0.0861)\n",
      "8213 Traning Loss: tensor(0.0861)\n",
      "8214 Traning Loss: tensor(0.0862)\n",
      "8215 Traning Loss: tensor(0.0863)\n",
      "8216 Traning Loss: tensor(0.0862)\n",
      "8217 Traning Loss: tensor(0.0860)\n",
      "8218 Traning Loss: tensor(0.0858)\n",
      "8219 Traning Loss: tensor(0.0859)\n",
      "8220 Traning Loss: tensor(0.0861)\n",
      "8221 Traning Loss: tensor(0.0863)\n",
      "8222 Traning Loss: tensor(0.0865)\n",
      "8223 Traning Loss: tensor(0.0867)\n",
      "8224 Traning Loss: tensor(0.0869)\n",
      "8225 Traning Loss: tensor(0.0872)\n",
      "8226 Traning Loss: tensor(0.0876)\n",
      "8227 Traning Loss: tensor(0.0877)\n",
      "8228 Traning Loss: tensor(0.0875)\n",
      "8229 Traning Loss: tensor(0.0869)\n",
      "8230 Traning Loss: tensor(0.0862)\n",
      "8231 Traning Loss: tensor(0.0857)\n",
      "8232 Traning Loss: tensor(0.0853)\n",
      "8233 Traning Loss: tensor(0.0852)\n",
      "8234 Traning Loss: tensor(0.0854)\n",
      "8235 Traning Loss: tensor(0.0856)\n",
      "8236 Traning Loss: tensor(0.0859)\n",
      "8237 Traning Loss: tensor(0.0858)\n",
      "8238 Traning Loss: tensor(0.0856)\n",
      "8239 Traning Loss: tensor(0.0853)\n",
      "8240 Traning Loss: tensor(0.0850)\n",
      "8241 Traning Loss: tensor(0.0849)\n",
      "8242 Traning Loss: tensor(0.0850)\n",
      "8243 Traning Loss: tensor(0.0850)\n",
      "8244 Traning Loss: tensor(0.0851)\n",
      "8245 Traning Loss: tensor(0.0851)\n",
      "8246 Traning Loss: tensor(0.0851)\n",
      "8247 Traning Loss: tensor(0.0849)\n",
      "8248 Traning Loss: tensor(0.0848)\n",
      "8249 Traning Loss: tensor(0.0847)\n",
      "8250 Traning Loss: tensor(0.0847)\n",
      "8251 Traning Loss: tensor(0.0847)\n",
      "8252 Traning Loss: tensor(0.0847)\n",
      "8253 Traning Loss: tensor(0.0847)\n",
      "8254 Traning Loss: tensor(0.0847)\n",
      "8255 Traning Loss: tensor(0.0846)\n",
      "8256 Traning Loss: tensor(0.0845)\n",
      "8257 Traning Loss: tensor(0.0844)\n",
      "8258 Traning Loss: tensor(0.0844)\n",
      "8259 Traning Loss: tensor(0.0844)\n",
      "8260 Traning Loss: tensor(0.0844)\n",
      "8261 Traning Loss: tensor(0.0844)\n",
      "8262 Traning Loss: tensor(0.0843)\n",
      "8263 Traning Loss: tensor(0.0843)\n",
      "8264 Traning Loss: tensor(0.0843)\n",
      "8265 Traning Loss: tensor(0.0842)\n",
      "8266 Traning Loss: tensor(0.0842)\n",
      "8267 Traning Loss: tensor(0.0841)\n",
      "8268 Traning Loss: tensor(0.0841)\n",
      "8269 Traning Loss: tensor(0.0841)\n",
      "8270 Traning Loss: tensor(0.0840)\n",
      "8271 Traning Loss: tensor(0.0840)\n",
      "8272 Traning Loss: tensor(0.0840)\n",
      "8273 Traning Loss: tensor(0.0840)\n",
      "8274 Traning Loss: tensor(0.0839)\n",
      "8275 Traning Loss: tensor(0.0839)\n",
      "8276 Traning Loss: tensor(0.0839)\n",
      "8277 Traning Loss: tensor(0.0838)\n",
      "8278 Traning Loss: tensor(0.0838)\n",
      "8279 Traning Loss: tensor(0.0838)\n",
      "8280 Traning Loss: tensor(0.0837)\n",
      "8281 Traning Loss: tensor(0.0837)\n",
      "8282 Traning Loss: tensor(0.0837)\n",
      "8283 Traning Loss: tensor(0.0836)\n",
      "8284 Traning Loss: tensor(0.0836)\n",
      "8285 Traning Loss: tensor(0.0836)\n",
      "8286 Traning Loss: tensor(0.0835)\n",
      "8287 Traning Loss: tensor(0.0835)\n",
      "8288 Traning Loss: tensor(0.0835)\n",
      "8289 Traning Loss: tensor(0.0834)\n",
      "8290 Traning Loss: tensor(0.0834)\n",
      "8291 Traning Loss: tensor(0.0834)\n",
      "8292 Traning Loss: tensor(0.0834)\n",
      "8293 Traning Loss: tensor(0.0833)\n",
      "8294 Traning Loss: tensor(0.0833)\n",
      "8295 Traning Loss: tensor(0.0833)\n",
      "8296 Traning Loss: tensor(0.0832)\n",
      "8297 Traning Loss: tensor(0.0832)\n",
      "8298 Traning Loss: tensor(0.0832)\n",
      "8299 Traning Loss: tensor(0.0831)\n",
      "8300 Traning Loss: tensor(0.0831)\n",
      "8301 Traning Loss: tensor(0.0831)\n",
      "8302 Traning Loss: tensor(0.0831)\n",
      "8303 Traning Loss: tensor(0.0830)\n",
      "8304 Traning Loss: tensor(0.0830)\n",
      "8305 Traning Loss: tensor(0.0830)\n",
      "8306 Traning Loss: tensor(0.0829)\n",
      "8307 Traning Loss: tensor(0.0829)\n",
      "8308 Traning Loss: tensor(0.0829)\n",
      "8309 Traning Loss: tensor(0.0828)\n",
      "8310 Traning Loss: tensor(0.0828)\n",
      "8311 Traning Loss: tensor(0.0828)\n",
      "8312 Traning Loss: tensor(0.0827)\n",
      "8313 Traning Loss: tensor(0.0827)\n",
      "8314 Traning Loss: tensor(0.0827)\n",
      "8315 Traning Loss: tensor(0.0827)\n",
      "8316 Traning Loss: tensor(0.0826)\n",
      "8317 Traning Loss: tensor(0.0826)\n",
      "8318 Traning Loss: tensor(0.0826)\n",
      "8319 Traning Loss: tensor(0.0825)\n",
      "8320 Traning Loss: tensor(0.0825)\n",
      "8321 Traning Loss: tensor(0.0825)\n",
      "8322 Traning Loss: tensor(0.0824)\n",
      "8323 Traning Loss: tensor(0.0824)\n",
      "8324 Traning Loss: tensor(0.0824)\n",
      "8325 Traning Loss: tensor(0.0824)\n",
      "8326 Traning Loss: tensor(0.0823)\n",
      "8327 Traning Loss: tensor(0.0823)\n",
      "8328 Traning Loss: tensor(0.0823)\n",
      "8329 Traning Loss: tensor(0.0823)\n",
      "8330 Traning Loss: tensor(0.0823)\n",
      "8331 Traning Loss: tensor(0.0823)\n",
      "8332 Traning Loss: tensor(0.0824)\n",
      "8333 Traning Loss: tensor(0.0825)\n",
      "8334 Traning Loss: tensor(0.0826)\n",
      "8335 Traning Loss: tensor(0.0829)\n",
      "8336 Traning Loss: tensor(0.0832)\n",
      "8337 Traning Loss: tensor(0.0837)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8338 Traning Loss: tensor(0.0843)\n",
      "8339 Traning Loss: tensor(0.0848)\n",
      "8340 Traning Loss: tensor(0.0852)\n",
      "8341 Traning Loss: tensor(0.0851)\n",
      "8342 Traning Loss: tensor(0.0844)\n",
      "8343 Traning Loss: tensor(0.0833)\n",
      "8344 Traning Loss: tensor(0.0823)\n",
      "8345 Traning Loss: tensor(0.0818)\n",
      "8346 Traning Loss: tensor(0.0819)\n",
      "8347 Traning Loss: tensor(0.0824)\n",
      "8348 Traning Loss: tensor(0.0828)\n",
      "8349 Traning Loss: tensor(0.0829)\n",
      "8350 Traning Loss: tensor(0.0825)\n",
      "8351 Traning Loss: tensor(0.0820)\n",
      "8352 Traning Loss: tensor(0.0816)\n",
      "8353 Traning Loss: tensor(0.0815)\n",
      "8354 Traning Loss: tensor(0.0818)\n",
      "8355 Traning Loss: tensor(0.0820)\n",
      "8356 Traning Loss: tensor(0.0820)\n",
      "8357 Traning Loss: tensor(0.0818)\n",
      "8358 Traning Loss: tensor(0.0815)\n",
      "8359 Traning Loss: tensor(0.0814)\n",
      "8360 Traning Loss: tensor(0.0813)\n",
      "8361 Traning Loss: tensor(0.0814)\n",
      "8362 Traning Loss: tensor(0.0815)\n",
      "8363 Traning Loss: tensor(0.0815)\n",
      "8364 Traning Loss: tensor(0.0814)\n",
      "8365 Traning Loss: tensor(0.0812)\n",
      "8366 Traning Loss: tensor(0.0811)\n",
      "8367 Traning Loss: tensor(0.0811)\n",
      "8368 Traning Loss: tensor(0.0811)\n",
      "8369 Traning Loss: tensor(0.0812)\n",
      "8370 Traning Loss: tensor(0.0811)\n",
      "8371 Traning Loss: tensor(0.0811)\n",
      "8372 Traning Loss: tensor(0.0810)\n",
      "8373 Traning Loss: tensor(0.0809)\n",
      "8374 Traning Loss: tensor(0.0809)\n",
      "8375 Traning Loss: tensor(0.0809)\n",
      "8376 Traning Loss: tensor(0.0809)\n",
      "8377 Traning Loss: tensor(0.0809)\n",
      "8378 Traning Loss: tensor(0.0808)\n",
      "8379 Traning Loss: tensor(0.0808)\n",
      "8380 Traning Loss: tensor(0.0807)\n",
      "8381 Traning Loss: tensor(0.0807)\n",
      "8382 Traning Loss: tensor(0.0807)\n",
      "8383 Traning Loss: tensor(0.0806)\n",
      "8384 Traning Loss: tensor(0.0806)\n",
      "8385 Traning Loss: tensor(0.0806)\n",
      "8386 Traning Loss: tensor(0.0806)\n",
      "8387 Traning Loss: tensor(0.0805)\n",
      "8388 Traning Loss: tensor(0.0805)\n",
      "8389 Traning Loss: tensor(0.0804)\n",
      "8390 Traning Loss: tensor(0.0804)\n",
      "8391 Traning Loss: tensor(0.0804)\n",
      "8392 Traning Loss: tensor(0.0804)\n",
      "8393 Traning Loss: tensor(0.0803)\n",
      "8394 Traning Loss: tensor(0.0803)\n",
      "8395 Traning Loss: tensor(0.0803)\n",
      "8396 Traning Loss: tensor(0.0802)\n",
      "8397 Traning Loss: tensor(0.0802)\n",
      "8398 Traning Loss: tensor(0.0802)\n",
      "8399 Traning Loss: tensor(0.0801)\n",
      "8400 Traning Loss: tensor(0.0801)\n",
      "8401 Traning Loss: tensor(0.0801)\n",
      "8402 Traning Loss: tensor(0.0801)\n",
      "8403 Traning Loss: tensor(0.0800)\n",
      "8404 Traning Loss: tensor(0.0800)\n",
      "8405 Traning Loss: tensor(0.0800)\n",
      "8406 Traning Loss: tensor(0.0799)\n",
      "8407 Traning Loss: tensor(0.0799)\n",
      "8408 Traning Loss: tensor(0.0799)\n",
      "8409 Traning Loss: tensor(0.0798)\n",
      "8410 Traning Loss: tensor(0.0798)\n",
      "8411 Traning Loss: tensor(0.0798)\n",
      "8412 Traning Loss: tensor(0.0798)\n",
      "8413 Traning Loss: tensor(0.0797)\n",
      "8414 Traning Loss: tensor(0.0797)\n",
      "8415 Traning Loss: tensor(0.0797)\n",
      "8416 Traning Loss: tensor(0.0796)\n",
      "8417 Traning Loss: tensor(0.0796)\n",
      "8418 Traning Loss: tensor(0.0796)\n",
      "8419 Traning Loss: tensor(0.0795)\n",
      "8420 Traning Loss: tensor(0.0795)\n",
      "8421 Traning Loss: tensor(0.0795)\n",
      "8422 Traning Loss: tensor(0.0795)\n",
      "8423 Traning Loss: tensor(0.0794)\n",
      "8424 Traning Loss: tensor(0.0794)\n",
      "8425 Traning Loss: tensor(0.0794)\n",
      "8426 Traning Loss: tensor(0.0793)\n",
      "8427 Traning Loss: tensor(0.0793)\n",
      "8428 Traning Loss: tensor(0.0793)\n",
      "8429 Traning Loss: tensor(0.0793)\n",
      "8430 Traning Loss: tensor(0.0792)\n",
      "8431 Traning Loss: tensor(0.0792)\n",
      "8432 Traning Loss: tensor(0.0792)\n",
      "8433 Traning Loss: tensor(0.0791)\n",
      "8434 Traning Loss: tensor(0.0791)\n",
      "8435 Traning Loss: tensor(0.0791)\n",
      "8436 Traning Loss: tensor(0.0790)\n",
      "8437 Traning Loss: tensor(0.0790)\n",
      "8438 Traning Loss: tensor(0.0790)\n",
      "8439 Traning Loss: tensor(0.0790)\n",
      "8440 Traning Loss: tensor(0.0789)\n",
      "8441 Traning Loss: tensor(0.0789)\n",
      "8442 Traning Loss: tensor(0.0789)\n",
      "8443 Traning Loss: tensor(0.0788)\n",
      "8444 Traning Loss: tensor(0.0788)\n",
      "8445 Traning Loss: tensor(0.0788)\n",
      "8446 Traning Loss: tensor(0.0787)\n",
      "8447 Traning Loss: tensor(0.0787)\n",
      "8448 Traning Loss: tensor(0.0787)\n",
      "8449 Traning Loss: tensor(0.0787)\n",
      "8450 Traning Loss: tensor(0.0786)\n",
      "8451 Traning Loss: tensor(0.0786)\n",
      "8452 Traning Loss: tensor(0.0786)\n",
      "8453 Traning Loss: tensor(0.0785)\n",
      "8454 Traning Loss: tensor(0.0785)\n",
      "8455 Traning Loss: tensor(0.0785)\n",
      "8456 Traning Loss: tensor(0.0784)\n",
      "8457 Traning Loss: tensor(0.0784)\n",
      "8458 Traning Loss: tensor(0.0784)\n",
      "8459 Traning Loss: tensor(0.0784)\n",
      "8460 Traning Loss: tensor(0.0783)\n",
      "8461 Traning Loss: tensor(0.0783)\n",
      "8462 Traning Loss: tensor(0.0783)\n",
      "8463 Traning Loss: tensor(0.0782)\n",
      "8464 Traning Loss: tensor(0.0782)\n",
      "8465 Traning Loss: tensor(0.0782)\n",
      "8466 Traning Loss: tensor(0.0781)\n",
      "8467 Traning Loss: tensor(0.0781)\n",
      "8468 Traning Loss: tensor(0.0781)\n",
      "8469 Traning Loss: tensor(0.0781)\n",
      "8470 Traning Loss: tensor(0.0780)\n",
      "8471 Traning Loss: tensor(0.0780)\n",
      "8472 Traning Loss: tensor(0.0780)\n",
      "8473 Traning Loss: tensor(0.0781)\n",
      "8474 Traning Loss: tensor(0.0781)\n",
      "8475 Traning Loss: tensor(0.0782)\n",
      "8476 Traning Loss: tensor(0.0783)\n",
      "8477 Traning Loss: tensor(0.0785)\n",
      "8478 Traning Loss: tensor(0.0786)\n",
      "8479 Traning Loss: tensor(0.0786)\n",
      "8480 Traning Loss: tensor(0.0786)\n",
      "8481 Traning Loss: tensor(0.0787)\n",
      "8482 Traning Loss: tensor(0.0792)\n",
      "8483 Traning Loss: tensor(0.0799)\n",
      "8484 Traning Loss: tensor(0.0809)\n",
      "8485 Traning Loss: tensor(0.0816)\n",
      "8486 Traning Loss: tensor(0.0820)\n",
      "8487 Traning Loss: tensor(0.0814)\n",
      "8488 Traning Loss: tensor(0.0803)\n",
      "8489 Traning Loss: tensor(0.0789)\n",
      "8490 Traning Loss: tensor(0.0778)\n",
      "8491 Traning Loss: tensor(0.0776)\n",
      "8492 Traning Loss: tensor(0.0781)\n",
      "8493 Traning Loss: tensor(0.0789)\n",
      "8494 Traning Loss: tensor(0.0791)\n",
      "8495 Traning Loss: tensor(0.0786)\n",
      "8496 Traning Loss: tensor(0.0778)\n",
      "8497 Traning Loss: tensor(0.0773)\n",
      "8498 Traning Loss: tensor(0.0774)\n",
      "8499 Traning Loss: tensor(0.0778)\n",
      "8500 Traning Loss: tensor(0.0780)\n",
      "8501 Traning Loss: tensor(0.0779)\n",
      "8502 Traning Loss: tensor(0.0775)\n",
      "8503 Traning Loss: tensor(0.0772)\n",
      "8504 Traning Loss: tensor(0.0771)\n",
      "8505 Traning Loss: tensor(0.0772)\n",
      "8506 Traning Loss: tensor(0.0774)\n",
      "8507 Traning Loss: tensor(0.0774)\n",
      "8508 Traning Loss: tensor(0.0772)\n",
      "8509 Traning Loss: tensor(0.0770)\n",
      "8510 Traning Loss: tensor(0.0769)\n",
      "8511 Traning Loss: tensor(0.0769)\n",
      "8512 Traning Loss: tensor(0.0770)\n",
      "8513 Traning Loss: tensor(0.0770)\n",
      "8514 Traning Loss: tensor(0.0769)\n",
      "8515 Traning Loss: tensor(0.0768)\n",
      "8516 Traning Loss: tensor(0.0767)\n",
      "8517 Traning Loss: tensor(0.0767)\n",
      "8518 Traning Loss: tensor(0.0767)\n",
      "8519 Traning Loss: tensor(0.0767)\n",
      "8520 Traning Loss: tensor(0.0767)\n",
      "8521 Traning Loss: tensor(0.0766)\n",
      "8522 Traning Loss: tensor(0.0766)\n",
      "8523 Traning Loss: tensor(0.0765)\n",
      "8524 Traning Loss: tensor(0.0765)\n",
      "8525 Traning Loss: tensor(0.0765)\n",
      "8526 Traning Loss: tensor(0.0765)\n",
      "8527 Traning Loss: tensor(0.0764)\n",
      "8528 Traning Loss: tensor(0.0764)\n",
      "8529 Traning Loss: tensor(0.0763)\n",
      "8530 Traning Loss: tensor(0.0763)\n",
      "8531 Traning Loss: tensor(0.0763)\n",
      "8532 Traning Loss: tensor(0.0763)\n",
      "8533 Traning Loss: tensor(0.0763)\n",
      "8534 Traning Loss: tensor(0.0762)\n",
      "8535 Traning Loss: tensor(0.0762)\n",
      "8536 Traning Loss: tensor(0.0761)\n",
      "8537 Traning Loss: tensor(0.0761)\n",
      "8538 Traning Loss: tensor(0.0761)\n",
      "8539 Traning Loss: tensor(0.0761)\n",
      "8540 Traning Loss: tensor(0.0760)\n",
      "8541 Traning Loss: tensor(0.0760)\n",
      "8542 Traning Loss: tensor(0.0760)\n",
      "8543 Traning Loss: tensor(0.0759)\n",
      "8544 Traning Loss: tensor(0.0759)\n",
      "8545 Traning Loss: tensor(0.0759)\n",
      "8546 Traning Loss: tensor(0.0759)\n",
      "8547 Traning Loss: tensor(0.0758)\n",
      "8548 Traning Loss: tensor(0.0758)\n",
      "8549 Traning Loss: tensor(0.0758)\n",
      "8550 Traning Loss: tensor(0.0757)\n",
      "8551 Traning Loss: tensor(0.0757)\n",
      "8552 Traning Loss: tensor(0.0757)\n",
      "8553 Traning Loss: tensor(0.0757)\n",
      "8554 Traning Loss: tensor(0.0756)\n",
      "8555 Traning Loss: tensor(0.0756)\n",
      "8556 Traning Loss: tensor(0.0756)\n",
      "8557 Traning Loss: tensor(0.0756)\n",
      "8558 Traning Loss: tensor(0.0755)\n",
      "8559 Traning Loss: tensor(0.0755)\n",
      "8560 Traning Loss: tensor(0.0755)\n",
      "8561 Traning Loss: tensor(0.0754)\n",
      "8562 Traning Loss: tensor(0.0754)\n",
      "8563 Traning Loss: tensor(0.0754)\n",
      "8564 Traning Loss: tensor(0.0754)\n",
      "8565 Traning Loss: tensor(0.0753)\n",
      "8566 Traning Loss: tensor(0.0753)\n",
      "8567 Traning Loss: tensor(0.0753)\n",
      "8568 Traning Loss: tensor(0.0752)\n",
      "8569 Traning Loss: tensor(0.0752)\n",
      "8570 Traning Loss: tensor(0.0752)\n",
      "8571 Traning Loss: tensor(0.0752)\n",
      "8572 Traning Loss: tensor(0.0751)\n",
      "8573 Traning Loss: tensor(0.0751)\n",
      "8574 Traning Loss: tensor(0.0751)\n",
      "8575 Traning Loss: tensor(0.0750)\n",
      "8576 Traning Loss: tensor(0.0750)\n",
      "8577 Traning Loss: tensor(0.0750)\n",
      "8578 Traning Loss: tensor(0.0750)\n",
      "8579 Traning Loss: tensor(0.0749)\n",
      "8580 Traning Loss: tensor(0.0749)\n",
      "8581 Traning Loss: tensor(0.0749)\n",
      "8582 Traning Loss: tensor(0.0748)\n",
      "8583 Traning Loss: tensor(0.0748)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8584 Traning Loss: tensor(0.0748)\n",
      "8585 Traning Loss: tensor(0.0748)\n",
      "8586 Traning Loss: tensor(0.0747)\n",
      "8587 Traning Loss: tensor(0.0747)\n",
      "8588 Traning Loss: tensor(0.0747)\n",
      "8589 Traning Loss: tensor(0.0746)\n",
      "8590 Traning Loss: tensor(0.0746)\n",
      "8591 Traning Loss: tensor(0.0746)\n",
      "8592 Traning Loss: tensor(0.0746)\n",
      "8593 Traning Loss: tensor(0.0745)\n",
      "8594 Traning Loss: tensor(0.0745)\n",
      "8595 Traning Loss: tensor(0.0745)\n",
      "8596 Traning Loss: tensor(0.0744)\n",
      "8597 Traning Loss: tensor(0.0744)\n",
      "8598 Traning Loss: tensor(0.0744)\n",
      "8599 Traning Loss: tensor(0.0744)\n",
      "8600 Traning Loss: tensor(0.0743)\n",
      "8601 Traning Loss: tensor(0.0743)\n",
      "8602 Traning Loss: tensor(0.0743)\n",
      "8603 Traning Loss: tensor(0.0742)\n",
      "8604 Traning Loss: tensor(0.0742)\n",
      "8605 Traning Loss: tensor(0.0742)\n",
      "8606 Traning Loss: tensor(0.0742)\n",
      "8607 Traning Loss: tensor(0.0741)\n",
      "8608 Traning Loss: tensor(0.0741)\n",
      "8609 Traning Loss: tensor(0.0741)\n",
      "8610 Traning Loss: tensor(0.0740)\n",
      "8611 Traning Loss: tensor(0.0740)\n",
      "8612 Traning Loss: tensor(0.0740)\n",
      "8613 Traning Loss: tensor(0.0740)\n",
      "8614 Traning Loss: tensor(0.0739)\n",
      "8615 Traning Loss: tensor(0.0739)\n",
      "8616 Traning Loss: tensor(0.0739)\n",
      "8617 Traning Loss: tensor(0.0738)\n",
      "8618 Traning Loss: tensor(0.0738)\n",
      "8619 Traning Loss: tensor(0.0738)\n",
      "8620 Traning Loss: tensor(0.0738)\n",
      "8621 Traning Loss: tensor(0.0737)\n",
      "8622 Traning Loss: tensor(0.0737)\n",
      "8623 Traning Loss: tensor(0.0737)\n",
      "8624 Traning Loss: tensor(0.0736)\n",
      "8625 Traning Loss: tensor(0.0736)\n",
      "8626 Traning Loss: tensor(0.0736)\n",
      "8627 Traning Loss: tensor(0.0736)\n",
      "8628 Traning Loss: tensor(0.0735)\n",
      "8629 Traning Loss: tensor(0.0735)\n",
      "8630 Traning Loss: tensor(0.0735)\n",
      "8631 Traning Loss: tensor(0.0734)\n",
      "8632 Traning Loss: tensor(0.0734)\n",
      "8633 Traning Loss: tensor(0.0734)\n",
      "8634 Traning Loss: tensor(0.0734)\n",
      "8635 Traning Loss: tensor(0.0733)\n",
      "8636 Traning Loss: tensor(0.0733)\n",
      "8637 Traning Loss: tensor(0.0733)\n",
      "8638 Traning Loss: tensor(0.0732)\n",
      "8639 Traning Loss: tensor(0.0732)\n",
      "8640 Traning Loss: tensor(0.0732)\n",
      "8641 Traning Loss: tensor(0.0732)\n",
      "8642 Traning Loss: tensor(0.0731)\n",
      "8643 Traning Loss: tensor(0.0731)\n",
      "8644 Traning Loss: tensor(0.0731)\n",
      "8645 Traning Loss: tensor(0.0731)\n",
      "8646 Traning Loss: tensor(0.0731)\n",
      "8647 Traning Loss: tensor(0.0731)\n",
      "8648 Traning Loss: tensor(0.0731)\n",
      "8649 Traning Loss: tensor(0.0732)\n",
      "8650 Traning Loss: tensor(0.0733)\n",
      "8651 Traning Loss: tensor(0.0735)\n",
      "8652 Traning Loss: tensor(0.0740)\n",
      "8653 Traning Loss: tensor(0.0747)\n",
      "8654 Traning Loss: tensor(0.0758)\n",
      "8655 Traning Loss: tensor(0.0773)\n",
      "8656 Traning Loss: tensor(0.0789)\n",
      "8657 Traning Loss: tensor(0.0798)\n",
      "8658 Traning Loss: tensor(0.0788)\n",
      "8659 Traning Loss: tensor(0.0762)\n",
      "8660 Traning Loss: tensor(0.0734)\n",
      "8661 Traning Loss: tensor(0.0726)\n",
      "8662 Traning Loss: tensor(0.0738)\n",
      "8663 Traning Loss: tensor(0.0753)\n",
      "8664 Traning Loss: tensor(0.0755)\n",
      "8665 Traning Loss: tensor(0.0741)\n",
      "8666 Traning Loss: tensor(0.0727)\n",
      "8667 Traning Loss: tensor(0.0726)\n",
      "8668 Traning Loss: tensor(0.0735)\n",
      "8669 Traning Loss: tensor(0.0741)\n",
      "8670 Traning Loss: tensor(0.0736)\n",
      "8671 Traning Loss: tensor(0.0727)\n",
      "8672 Traning Loss: tensor(0.0723)\n",
      "8673 Traning Loss: tensor(0.0727)\n",
      "8674 Traning Loss: tensor(0.0732)\n",
      "8675 Traning Loss: tensor(0.0730)\n",
      "8676 Traning Loss: tensor(0.0725)\n",
      "8677 Traning Loss: tensor(0.0722)\n",
      "8678 Traning Loss: tensor(0.0724)\n",
      "8679 Traning Loss: tensor(0.0726)\n",
      "8680 Traning Loss: tensor(0.0726)\n",
      "8681 Traning Loss: tensor(0.0722)\n",
      "8682 Traning Loss: tensor(0.0720)\n",
      "8683 Traning Loss: tensor(0.0721)\n",
      "8684 Traning Loss: tensor(0.0723)\n",
      "8685 Traning Loss: tensor(0.0723)\n",
      "8686 Traning Loss: tensor(0.0721)\n",
      "8687 Traning Loss: tensor(0.0719)\n",
      "8688 Traning Loss: tensor(0.0719)\n",
      "8689 Traning Loss: tensor(0.0720)\n",
      "8690 Traning Loss: tensor(0.0720)\n",
      "8691 Traning Loss: tensor(0.0719)\n",
      "8692 Traning Loss: tensor(0.0718)\n",
      "8693 Traning Loss: tensor(0.0717)\n",
      "8694 Traning Loss: tensor(0.0718)\n",
      "8695 Traning Loss: tensor(0.0718)\n",
      "8696 Traning Loss: tensor(0.0717)\n",
      "8697 Traning Loss: tensor(0.0716)\n",
      "8698 Traning Loss: tensor(0.0716)\n",
      "8699 Traning Loss: tensor(0.0716)\n",
      "8700 Traning Loss: tensor(0.0716)\n",
      "8701 Traning Loss: tensor(0.0716)\n",
      "8702 Traning Loss: tensor(0.0715)\n",
      "8703 Traning Loss: tensor(0.0714)\n",
      "8704 Traning Loss: tensor(0.0714)\n",
      "8705 Traning Loss: tensor(0.0714)\n",
      "8706 Traning Loss: tensor(0.0714)\n",
      "8707 Traning Loss: tensor(0.0714)\n",
      "8708 Traning Loss: tensor(0.0713)\n",
      "8709 Traning Loss: tensor(0.0713)\n",
      "8710 Traning Loss: tensor(0.0713)\n",
      "8711 Traning Loss: tensor(0.0712)\n",
      "8712 Traning Loss: tensor(0.0712)\n",
      "8713 Traning Loss: tensor(0.0712)\n",
      "8714 Traning Loss: tensor(0.0711)\n",
      "8715 Traning Loss: tensor(0.0711)\n",
      "8716 Traning Loss: tensor(0.0711)\n",
      "8717 Traning Loss: tensor(0.0711)\n",
      "8718 Traning Loss: tensor(0.0710)\n",
      "8719 Traning Loss: tensor(0.0710)\n",
      "8720 Traning Loss: tensor(0.0710)\n",
      "8721 Traning Loss: tensor(0.0710)\n",
      "8722 Traning Loss: tensor(0.0709)\n",
      "8723 Traning Loss: tensor(0.0709)\n",
      "8724 Traning Loss: tensor(0.0709)\n",
      "8725 Traning Loss: tensor(0.0708)\n",
      "8726 Traning Loss: tensor(0.0708)\n",
      "8727 Traning Loss: tensor(0.0708)\n",
      "8728 Traning Loss: tensor(0.0708)\n",
      "8729 Traning Loss: tensor(0.0707)\n",
      "8730 Traning Loss: tensor(0.0707)\n",
      "8731 Traning Loss: tensor(0.0707)\n",
      "8732 Traning Loss: tensor(0.0707)\n",
      "8733 Traning Loss: tensor(0.0706)\n",
      "8734 Traning Loss: tensor(0.0706)\n",
      "8735 Traning Loss: tensor(0.0706)\n",
      "8736 Traning Loss: tensor(0.0705)\n",
      "8737 Traning Loss: tensor(0.0705)\n",
      "8738 Traning Loss: tensor(0.0705)\n",
      "8739 Traning Loss: tensor(0.0705)\n",
      "8740 Traning Loss: tensor(0.0704)\n",
      "8741 Traning Loss: tensor(0.0704)\n",
      "8742 Traning Loss: tensor(0.0704)\n",
      "8743 Traning Loss: tensor(0.0704)\n",
      "8744 Traning Loss: tensor(0.0703)\n",
      "8745 Traning Loss: tensor(0.0703)\n",
      "8746 Traning Loss: tensor(0.0703)\n",
      "8747 Traning Loss: tensor(0.0702)\n",
      "8748 Traning Loss: tensor(0.0702)\n",
      "8749 Traning Loss: tensor(0.0702)\n",
      "8750 Traning Loss: tensor(0.0702)\n",
      "8751 Traning Loss: tensor(0.0701)\n",
      "8752 Traning Loss: tensor(0.0701)\n",
      "8753 Traning Loss: tensor(0.0701)\n",
      "8754 Traning Loss: tensor(0.0701)\n",
      "8755 Traning Loss: tensor(0.0700)\n",
      "8756 Traning Loss: tensor(0.0700)\n",
      "8757 Traning Loss: tensor(0.0700)\n",
      "8758 Traning Loss: tensor(0.0699)\n",
      "8759 Traning Loss: tensor(0.0699)\n",
      "8760 Traning Loss: tensor(0.0699)\n",
      "8761 Traning Loss: tensor(0.0699)\n",
      "8762 Traning Loss: tensor(0.0698)\n",
      "8763 Traning Loss: tensor(0.0698)\n",
      "8764 Traning Loss: tensor(0.0698)\n",
      "8765 Traning Loss: tensor(0.0697)\n",
      "8766 Traning Loss: tensor(0.0697)\n",
      "8767 Traning Loss: tensor(0.0697)\n",
      "8768 Traning Loss: tensor(0.0697)\n",
      "8769 Traning Loss: tensor(0.0696)\n",
      "8770 Traning Loss: tensor(0.0696)\n",
      "8771 Traning Loss: tensor(0.0696)\n",
      "8772 Traning Loss: tensor(0.0696)\n",
      "8773 Traning Loss: tensor(0.0695)\n",
      "8774 Traning Loss: tensor(0.0695)\n",
      "8775 Traning Loss: tensor(0.0695)\n",
      "8776 Traning Loss: tensor(0.0694)\n",
      "8777 Traning Loss: tensor(0.0694)\n",
      "8778 Traning Loss: tensor(0.0694)\n",
      "8779 Traning Loss: tensor(0.0694)\n",
      "8780 Traning Loss: tensor(0.0693)\n",
      "8781 Traning Loss: tensor(0.0693)\n",
      "8782 Traning Loss: tensor(0.0693)\n",
      "8783 Traning Loss: tensor(0.0693)\n",
      "8784 Traning Loss: tensor(0.0693)\n",
      "8785 Traning Loss: tensor(0.0693)\n",
      "8786 Traning Loss: tensor(0.0693)\n",
      "8787 Traning Loss: tensor(0.0694)\n",
      "8788 Traning Loss: tensor(0.0694)\n",
      "8789 Traning Loss: tensor(0.0695)\n",
      "8790 Traning Loss: tensor(0.0695)\n",
      "8791 Traning Loss: tensor(0.0695)\n",
      "8792 Traning Loss: tensor(0.0693)\n",
      "8793 Traning Loss: tensor(0.0691)\n",
      "8794 Traning Loss: tensor(0.0690)\n",
      "8795 Traning Loss: tensor(0.0690)\n",
      "8796 Traning Loss: tensor(0.0690)\n",
      "8797 Traning Loss: tensor(0.0691)\n",
      "8798 Traning Loss: tensor(0.0690)\n",
      "8799 Traning Loss: tensor(0.0689)\n",
      "8800 Traning Loss: tensor(0.0688)\n",
      "8801 Traning Loss: tensor(0.0688)\n",
      "8802 Traning Loss: tensor(0.0688)\n",
      "8803 Traning Loss: tensor(0.0688)\n",
      "8804 Traning Loss: tensor(0.0688)\n",
      "8805 Traning Loss: tensor(0.0687)\n",
      "8806 Traning Loss: tensor(0.0686)\n",
      "8807 Traning Loss: tensor(0.0686)\n",
      "8808 Traning Loss: tensor(0.0686)\n",
      "8809 Traning Loss: tensor(0.0686)\n",
      "8810 Traning Loss: tensor(0.0686)\n",
      "8811 Traning Loss: tensor(0.0685)\n",
      "8812 Traning Loss: tensor(0.0685)\n",
      "8813 Traning Loss: tensor(0.0684)\n",
      "8814 Traning Loss: tensor(0.0684)\n",
      "8815 Traning Loss: tensor(0.0684)\n",
      "8816 Traning Loss: tensor(0.0684)\n",
      "8817 Traning Loss: tensor(0.0683)\n",
      "8818 Traning Loss: tensor(0.0683)\n",
      "8819 Traning Loss: tensor(0.0683)\n",
      "8820 Traning Loss: tensor(0.0683)\n",
      "8821 Traning Loss: tensor(0.0682)\n",
      "8822 Traning Loss: tensor(0.0682)\n",
      "8823 Traning Loss: tensor(0.0682)\n",
      "8824 Traning Loss: tensor(0.0681)\n",
      "8825 Traning Loss: tensor(0.0681)\n",
      "8826 Traning Loss: tensor(0.0681)\n",
      "8827 Traning Loss: tensor(0.0681)\n",
      "8828 Traning Loss: tensor(0.0680)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829 Traning Loss: tensor(0.0680)\n",
      "8830 Traning Loss: tensor(0.0680)\n",
      "8831 Traning Loss: tensor(0.0679)\n",
      "8832 Traning Loss: tensor(0.0679)\n",
      "8833 Traning Loss: tensor(0.0679)\n",
      "8834 Traning Loss: tensor(0.0679)\n",
      "8835 Traning Loss: tensor(0.0678)\n",
      "8836 Traning Loss: tensor(0.0678)\n",
      "8837 Traning Loss: tensor(0.0678)\n",
      "8838 Traning Loss: tensor(0.0678)\n",
      "8839 Traning Loss: tensor(0.0677)\n",
      "8840 Traning Loss: tensor(0.0677)\n",
      "8841 Traning Loss: tensor(0.0677)\n",
      "8842 Traning Loss: tensor(0.0676)\n",
      "8843 Traning Loss: tensor(0.0676)\n",
      "8844 Traning Loss: tensor(0.0676)\n",
      "8845 Traning Loss: tensor(0.0676)\n",
      "8846 Traning Loss: tensor(0.0675)\n",
      "8847 Traning Loss: tensor(0.0675)\n",
      "8848 Traning Loss: tensor(0.0675)\n",
      "8849 Traning Loss: tensor(0.0674)\n",
      "8850 Traning Loss: tensor(0.0674)\n",
      "8851 Traning Loss: tensor(0.0674)\n",
      "8852 Traning Loss: tensor(0.0674)\n",
      "8853 Traning Loss: tensor(0.0673)\n",
      "8854 Traning Loss: tensor(0.0673)\n",
      "8855 Traning Loss: tensor(0.0673)\n",
      "8856 Traning Loss: tensor(0.0673)\n",
      "8857 Traning Loss: tensor(0.0672)\n",
      "8858 Traning Loss: tensor(0.0672)\n",
      "8859 Traning Loss: tensor(0.0672)\n",
      "8860 Traning Loss: tensor(0.0672)\n",
      "8861 Traning Loss: tensor(0.0672)\n",
      "8862 Traning Loss: tensor(0.0672)\n",
      "8863 Traning Loss: tensor(0.0672)\n",
      "8864 Traning Loss: tensor(0.0672)\n",
      "8865 Traning Loss: tensor(0.0673)\n",
      "8866 Traning Loss: tensor(0.0674)\n",
      "8867 Traning Loss: tensor(0.0676)\n",
      "8868 Traning Loss: tensor(0.0679)\n",
      "8869 Traning Loss: tensor(0.0683)\n",
      "8870 Traning Loss: tensor(0.0690)\n",
      "8871 Traning Loss: tensor(0.0699)\n",
      "8872 Traning Loss: tensor(0.0708)\n",
      "8873 Traning Loss: tensor(0.0716)\n",
      "8874 Traning Loss: tensor(0.0715)\n",
      "8875 Traning Loss: tensor(0.0705)\n",
      "8876 Traning Loss: tensor(0.0688)\n",
      "8877 Traning Loss: tensor(0.0672)\n",
      "8878 Traning Loss: tensor(0.0667)\n",
      "8879 Traning Loss: tensor(0.0671)\n",
      "8880 Traning Loss: tensor(0.0680)\n",
      "8881 Traning Loss: tensor(0.0685)\n",
      "8882 Traning Loss: tensor(0.0683)\n",
      "8883 Traning Loss: tensor(0.0674)\n",
      "8884 Traning Loss: tensor(0.0667)\n",
      "8885 Traning Loss: tensor(0.0665)\n",
      "8886 Traning Loss: tensor(0.0669)\n",
      "8887 Traning Loss: tensor(0.0673)\n",
      "8888 Traning Loss: tensor(0.0674)\n",
      "8889 Traning Loss: tensor(0.0670)\n",
      "8890 Traning Loss: tensor(0.0665)\n",
      "8891 Traning Loss: tensor(0.0663)\n",
      "8892 Traning Loss: tensor(0.0664)\n",
      "8893 Traning Loss: tensor(0.0667)\n",
      "8894 Traning Loss: tensor(0.0668)\n",
      "8895 Traning Loss: tensor(0.0666)\n",
      "8896 Traning Loss: tensor(0.0663)\n",
      "8897 Traning Loss: tensor(0.0662)\n",
      "8898 Traning Loss: tensor(0.0662)\n",
      "8899 Traning Loss: tensor(0.0663)\n",
      "8900 Traning Loss: tensor(0.0663)\n",
      "8901 Traning Loss: tensor(0.0663)\n",
      "8902 Traning Loss: tensor(0.0661)\n",
      "8903 Traning Loss: tensor(0.0660)\n",
      "8904 Traning Loss: tensor(0.0660)\n",
      "8905 Traning Loss: tensor(0.0660)\n",
      "8906 Traning Loss: tensor(0.0661)\n",
      "8907 Traning Loss: tensor(0.0660)\n",
      "8908 Traning Loss: tensor(0.0660)\n",
      "8909 Traning Loss: tensor(0.0659)\n",
      "8910 Traning Loss: tensor(0.0658)\n",
      "8911 Traning Loss: tensor(0.0658)\n",
      "8912 Traning Loss: tensor(0.0658)\n",
      "8913 Traning Loss: tensor(0.0658)\n",
      "8914 Traning Loss: tensor(0.0658)\n",
      "8915 Traning Loss: tensor(0.0657)\n",
      "8916 Traning Loss: tensor(0.0657)\n",
      "8917 Traning Loss: tensor(0.0656)\n",
      "8918 Traning Loss: tensor(0.0656)\n",
      "8919 Traning Loss: tensor(0.0656)\n",
      "8920 Traning Loss: tensor(0.0656)\n",
      "8921 Traning Loss: tensor(0.0656)\n",
      "8922 Traning Loss: tensor(0.0655)\n",
      "8923 Traning Loss: tensor(0.0655)\n",
      "8924 Traning Loss: tensor(0.0655)\n",
      "8925 Traning Loss: tensor(0.0654)\n",
      "8926 Traning Loss: tensor(0.0654)\n",
      "8927 Traning Loss: tensor(0.0654)\n",
      "8928 Traning Loss: tensor(0.0654)\n",
      "8929 Traning Loss: tensor(0.0653)\n",
      "8930 Traning Loss: tensor(0.0653)\n",
      "8931 Traning Loss: tensor(0.0653)\n",
      "8932 Traning Loss: tensor(0.0652)\n",
      "8933 Traning Loss: tensor(0.0652)\n",
      "8934 Traning Loss: tensor(0.0652)\n",
      "8935 Traning Loss: tensor(0.0652)\n",
      "8936 Traning Loss: tensor(0.0651)\n",
      "8937 Traning Loss: tensor(0.0651)\n",
      "8938 Traning Loss: tensor(0.0651)\n",
      "8939 Traning Loss: tensor(0.0651)\n",
      "8940 Traning Loss: tensor(0.0650)\n",
      "8941 Traning Loss: tensor(0.0650)\n",
      "8942 Traning Loss: tensor(0.0650)\n",
      "8943 Traning Loss: tensor(0.0650)\n",
      "8944 Traning Loss: tensor(0.0649)\n",
      "8945 Traning Loss: tensor(0.0649)\n",
      "8946 Traning Loss: tensor(0.0649)\n",
      "8947 Traning Loss: tensor(0.0648)\n",
      "8948 Traning Loss: tensor(0.0648)\n",
      "8949 Traning Loss: tensor(0.0648)\n",
      "8950 Traning Loss: tensor(0.0648)\n",
      "8951 Traning Loss: tensor(0.0647)\n",
      "8952 Traning Loss: tensor(0.0647)\n",
      "8953 Traning Loss: tensor(0.0647)\n",
      "8954 Traning Loss: tensor(0.0647)\n",
      "8955 Traning Loss: tensor(0.0646)\n",
      "8956 Traning Loss: tensor(0.0646)\n",
      "8957 Traning Loss: tensor(0.0646)\n",
      "8958 Traning Loss: tensor(0.0646)\n",
      "8959 Traning Loss: tensor(0.0645)\n",
      "8960 Traning Loss: tensor(0.0645)\n",
      "8961 Traning Loss: tensor(0.0645)\n",
      "8962 Traning Loss: tensor(0.0645)\n",
      "8963 Traning Loss: tensor(0.0644)\n",
      "8964 Traning Loss: tensor(0.0644)\n",
      "8965 Traning Loss: tensor(0.0644)\n",
      "8966 Traning Loss: tensor(0.0643)\n",
      "8967 Traning Loss: tensor(0.0643)\n",
      "8968 Traning Loss: tensor(0.0643)\n",
      "8969 Traning Loss: tensor(0.0643)\n",
      "8970 Traning Loss: tensor(0.0642)\n",
      "8971 Traning Loss: tensor(0.0642)\n",
      "8972 Traning Loss: tensor(0.0642)\n",
      "8973 Traning Loss: tensor(0.0642)\n",
      "8974 Traning Loss: tensor(0.0641)\n",
      "8975 Traning Loss: tensor(0.0641)\n",
      "8976 Traning Loss: tensor(0.0641)\n",
      "8977 Traning Loss: tensor(0.0641)\n",
      "8978 Traning Loss: tensor(0.0640)\n",
      "8979 Traning Loss: tensor(0.0640)\n",
      "8980 Traning Loss: tensor(0.0640)\n",
      "8981 Traning Loss: tensor(0.0639)\n",
      "8982 Traning Loss: tensor(0.0639)\n",
      "8983 Traning Loss: tensor(0.0639)\n",
      "8984 Traning Loss: tensor(0.0639)\n",
      "8985 Traning Loss: tensor(0.0638)\n",
      "8986 Traning Loss: tensor(0.0638)\n",
      "8987 Traning Loss: tensor(0.0638)\n",
      "8988 Traning Loss: tensor(0.0638)\n",
      "8989 Traning Loss: tensor(0.0637)\n",
      "8990 Traning Loss: tensor(0.0637)\n",
      "8991 Traning Loss: tensor(0.0637)\n",
      "8992 Traning Loss: tensor(0.0637)\n",
      "8993 Traning Loss: tensor(0.0637)\n",
      "8994 Traning Loss: tensor(0.0637)\n",
      "8995 Traning Loss: tensor(0.0637)\n",
      "8996 Traning Loss: tensor(0.0637)\n",
      "8997 Traning Loss: tensor(0.0637)\n",
      "8998 Traning Loss: tensor(0.0638)\n",
      "8999 Traning Loss: tensor(0.0639)\n",
      "9000 Traning Loss: tensor(0.0639)\n",
      "9001 Traning Loss: tensor(0.0639)\n",
      "9002 Traning Loss: tensor(0.0637)\n",
      "9003 Traning Loss: tensor(0.0635)\n",
      "9004 Traning Loss: tensor(0.0634)\n",
      "9005 Traning Loss: tensor(0.0634)\n",
      "9006 Traning Loss: tensor(0.0634)\n",
      "9007 Traning Loss: tensor(0.0635)\n",
      "9008 Traning Loss: tensor(0.0635)\n",
      "9009 Traning Loss: tensor(0.0634)\n",
      "9010 Traning Loss: tensor(0.0633)\n",
      "9011 Traning Loss: tensor(0.0632)\n",
      "9012 Traning Loss: tensor(0.0632)\n",
      "9013 Traning Loss: tensor(0.0633)\n",
      "9014 Traning Loss: tensor(0.0633)\n",
      "9015 Traning Loss: tensor(0.0633)\n",
      "9016 Traning Loss: tensor(0.0633)\n",
      "9017 Traning Loss: tensor(0.0633)\n",
      "9018 Traning Loss: tensor(0.0633)\n",
      "9019 Traning Loss: tensor(0.0634)\n",
      "9020 Traning Loss: tensor(0.0635)\n",
      "9021 Traning Loss: tensor(0.0637)\n",
      "9022 Traning Loss: tensor(0.0638)\n",
      "9023 Traning Loss: tensor(0.0639)\n",
      "9024 Traning Loss: tensor(0.0641)\n",
      "9025 Traning Loss: tensor(0.0642)\n",
      "9026 Traning Loss: tensor(0.0643)\n",
      "9027 Traning Loss: tensor(0.0643)\n",
      "9028 Traning Loss: tensor(0.0641)\n",
      "9029 Traning Loss: tensor(0.0639)\n",
      "9030 Traning Loss: tensor(0.0635)\n",
      "9031 Traning Loss: tensor(0.0632)\n",
      "9032 Traning Loss: tensor(0.0629)\n",
      "9033 Traning Loss: tensor(0.0627)\n",
      "9034 Traning Loss: tensor(0.0626)\n",
      "9035 Traning Loss: tensor(0.0626)\n",
      "9036 Traning Loss: tensor(0.0627)\n",
      "9037 Traning Loss: tensor(0.0628)\n",
      "9038 Traning Loss: tensor(0.0629)\n",
      "9039 Traning Loss: tensor(0.0629)\n",
      "9040 Traning Loss: tensor(0.0628)\n",
      "9041 Traning Loss: tensor(0.0627)\n",
      "9042 Traning Loss: tensor(0.0626)\n",
      "9043 Traning Loss: tensor(0.0625)\n",
      "9044 Traning Loss: tensor(0.0624)\n",
      "9045 Traning Loss: tensor(0.0623)\n",
      "9046 Traning Loss: tensor(0.0623)\n",
      "9047 Traning Loss: tensor(0.0623)\n",
      "9048 Traning Loss: tensor(0.0623)\n",
      "9049 Traning Loss: tensor(0.0623)\n",
      "9050 Traning Loss: tensor(0.0623)\n",
      "9051 Traning Loss: tensor(0.0623)\n",
      "9052 Traning Loss: tensor(0.0622)\n",
      "9053 Traning Loss: tensor(0.0622)\n",
      "9054 Traning Loss: tensor(0.0622)\n",
      "9055 Traning Loss: tensor(0.0621)\n",
      "9056 Traning Loss: tensor(0.0620)\n",
      "9057 Traning Loss: tensor(0.0620)\n",
      "9058 Traning Loss: tensor(0.0620)\n",
      "9059 Traning Loss: tensor(0.0619)\n",
      "9060 Traning Loss: tensor(0.0619)\n",
      "9061 Traning Loss: tensor(0.0619)\n",
      "9062 Traning Loss: tensor(0.0619)\n",
      "9063 Traning Loss: tensor(0.0618)\n",
      "9064 Traning Loss: tensor(0.0618)\n",
      "9065 Traning Loss: tensor(0.0618)\n",
      "9066 Traning Loss: tensor(0.0618)\n",
      "9067 Traning Loss: tensor(0.0618)\n",
      "9068 Traning Loss: tensor(0.0617)\n",
      "9069 Traning Loss: tensor(0.0617)\n",
      "9070 Traning Loss: tensor(0.0617)\n",
      "9071 Traning Loss: tensor(0.0617)\n",
      "9072 Traning Loss: tensor(0.0616)\n",
      "9073 Traning Loss: tensor(0.0616)\n",
      "9074 Traning Loss: tensor(0.0616)\n",
      "9075 Traning Loss: tensor(0.0615)\n",
      "9076 Traning Loss: tensor(0.0615)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9077 Traning Loss: tensor(0.0615)\n",
      "9078 Traning Loss: tensor(0.0615)\n",
      "9079 Traning Loss: tensor(0.0614)\n",
      "9080 Traning Loss: tensor(0.0614)\n",
      "9081 Traning Loss: tensor(0.0614)\n",
      "9082 Traning Loss: tensor(0.0613)\n",
      "9083 Traning Loss: tensor(0.0613)\n",
      "9084 Traning Loss: tensor(0.0613)\n",
      "9085 Traning Loss: tensor(0.0613)\n",
      "9086 Traning Loss: tensor(0.0612)\n",
      "9087 Traning Loss: tensor(0.0612)\n",
      "9088 Traning Loss: tensor(0.0612)\n",
      "9089 Traning Loss: tensor(0.0612)\n",
      "9090 Traning Loss: tensor(0.0612)\n",
      "9091 Traning Loss: tensor(0.0611)\n",
      "9092 Traning Loss: tensor(0.0611)\n",
      "9093 Traning Loss: tensor(0.0611)\n",
      "9094 Traning Loss: tensor(0.0611)\n",
      "9095 Traning Loss: tensor(0.0611)\n",
      "9096 Traning Loss: tensor(0.0611)\n",
      "9097 Traning Loss: tensor(0.0611)\n",
      "9098 Traning Loss: tensor(0.0611)\n",
      "9099 Traning Loss: tensor(0.0612)\n",
      "9100 Traning Loss: tensor(0.0613)\n",
      "9101 Traning Loss: tensor(0.0615)\n",
      "9102 Traning Loss: tensor(0.0617)\n",
      "9103 Traning Loss: tensor(0.0620)\n",
      "9104 Traning Loss: tensor(0.0624)\n",
      "9105 Traning Loss: tensor(0.0630)\n",
      "9106 Traning Loss: tensor(0.0635)\n",
      "9107 Traning Loss: tensor(0.0639)\n",
      "9108 Traning Loss: tensor(0.0641)\n",
      "9109 Traning Loss: tensor(0.0637)\n",
      "9110 Traning Loss: tensor(0.0629)\n",
      "9111 Traning Loss: tensor(0.0618)\n",
      "9112 Traning Loss: tensor(0.0609)\n",
      "9113 Traning Loss: tensor(0.0606)\n",
      "9114 Traning Loss: tensor(0.0607)\n",
      "9115 Traning Loss: tensor(0.0612)\n",
      "9116 Traning Loss: tensor(0.0616)\n",
      "9117 Traning Loss: tensor(0.0617)\n",
      "9118 Traning Loss: tensor(0.0614)\n",
      "9119 Traning Loss: tensor(0.0610)\n",
      "9120 Traning Loss: tensor(0.0605)\n",
      "9121 Traning Loss: tensor(0.0604)\n",
      "9122 Traning Loss: tensor(0.0605)\n",
      "9123 Traning Loss: tensor(0.0607)\n",
      "9124 Traning Loss: tensor(0.0608)\n",
      "9125 Traning Loss: tensor(0.0608)\n",
      "9126 Traning Loss: tensor(0.0606)\n",
      "9127 Traning Loss: tensor(0.0604)\n",
      "9128 Traning Loss: tensor(0.0602)\n",
      "9129 Traning Loss: tensor(0.0602)\n",
      "9130 Traning Loss: tensor(0.0602)\n",
      "9131 Traning Loss: tensor(0.0603)\n",
      "9132 Traning Loss: tensor(0.0603)\n",
      "9133 Traning Loss: tensor(0.0603)\n",
      "9134 Traning Loss: tensor(0.0602)\n",
      "9135 Traning Loss: tensor(0.0601)\n",
      "9136 Traning Loss: tensor(0.0600)\n",
      "9137 Traning Loss: tensor(0.0600)\n",
      "9138 Traning Loss: tensor(0.0600)\n",
      "9139 Traning Loss: tensor(0.0600)\n",
      "9140 Traning Loss: tensor(0.0600)\n",
      "9141 Traning Loss: tensor(0.0600)\n",
      "9142 Traning Loss: tensor(0.0599)\n",
      "9143 Traning Loss: tensor(0.0598)\n",
      "9144 Traning Loss: tensor(0.0598)\n",
      "9145 Traning Loss: tensor(0.0598)\n",
      "9146 Traning Loss: tensor(0.0598)\n",
      "9147 Traning Loss: tensor(0.0598)\n",
      "9148 Traning Loss: tensor(0.0597)\n",
      "9149 Traning Loss: tensor(0.0597)\n",
      "9150 Traning Loss: tensor(0.0597)\n",
      "9151 Traning Loss: tensor(0.0596)\n",
      "9152 Traning Loss: tensor(0.0596)\n",
      "9153 Traning Loss: tensor(0.0596)\n",
      "9154 Traning Loss: tensor(0.0595)\n",
      "9155 Traning Loss: tensor(0.0595)\n",
      "9156 Traning Loss: tensor(0.0595)\n",
      "9157 Traning Loss: tensor(0.0595)\n",
      "9158 Traning Loss: tensor(0.0595)\n",
      "9159 Traning Loss: tensor(0.0594)\n",
      "9160 Traning Loss: tensor(0.0594)\n",
      "9161 Traning Loss: tensor(0.0594)\n",
      "9162 Traning Loss: tensor(0.0594)\n",
      "9163 Traning Loss: tensor(0.0593)\n",
      "9164 Traning Loss: tensor(0.0593)\n",
      "9165 Traning Loss: tensor(0.0593)\n",
      "9166 Traning Loss: tensor(0.0593)\n",
      "9167 Traning Loss: tensor(0.0592)\n",
      "9168 Traning Loss: tensor(0.0592)\n",
      "9169 Traning Loss: tensor(0.0592)\n",
      "9170 Traning Loss: tensor(0.0592)\n",
      "9171 Traning Loss: tensor(0.0591)\n",
      "9172 Traning Loss: tensor(0.0591)\n",
      "9173 Traning Loss: tensor(0.0591)\n",
      "9174 Traning Loss: tensor(0.0591)\n",
      "9175 Traning Loss: tensor(0.0590)\n",
      "9176 Traning Loss: tensor(0.0590)\n",
      "9177 Traning Loss: tensor(0.0590)\n",
      "9178 Traning Loss: tensor(0.0590)\n",
      "9179 Traning Loss: tensor(0.0589)\n",
      "9180 Traning Loss: tensor(0.0589)\n",
      "9181 Traning Loss: tensor(0.0589)\n",
      "9182 Traning Loss: tensor(0.0589)\n",
      "9183 Traning Loss: tensor(0.0588)\n",
      "9184 Traning Loss: tensor(0.0588)\n",
      "9185 Traning Loss: tensor(0.0588)\n",
      "9186 Traning Loss: tensor(0.0588)\n",
      "9187 Traning Loss: tensor(0.0588)\n",
      "9188 Traning Loss: tensor(0.0587)\n",
      "9189 Traning Loss: tensor(0.0587)\n",
      "9190 Traning Loss: tensor(0.0587)\n",
      "9191 Traning Loss: tensor(0.0587)\n",
      "9192 Traning Loss: tensor(0.0587)\n",
      "9193 Traning Loss: tensor(0.0587)\n",
      "9194 Traning Loss: tensor(0.0588)\n",
      "9195 Traning Loss: tensor(0.0588)\n",
      "9196 Traning Loss: tensor(0.0588)\n",
      "9197 Traning Loss: tensor(0.0588)\n",
      "9198 Traning Loss: tensor(0.0588)\n",
      "9199 Traning Loss: tensor(0.0587)\n",
      "9200 Traning Loss: tensor(0.0585)\n",
      "9201 Traning Loss: tensor(0.0584)\n",
      "9202 Traning Loss: tensor(0.0584)\n",
      "9203 Traning Loss: tensor(0.0584)\n",
      "9204 Traning Loss: tensor(0.0584)\n",
      "9205 Traning Loss: tensor(0.0585)\n",
      "9206 Traning Loss: tensor(0.0584)\n",
      "9207 Traning Loss: tensor(0.0584)\n",
      "9208 Traning Loss: tensor(0.0583)\n",
      "9209 Traning Loss: tensor(0.0583)\n",
      "9210 Traning Loss: tensor(0.0582)\n",
      "9211 Traning Loss: tensor(0.0582)\n",
      "9212 Traning Loss: tensor(0.0583)\n",
      "9213 Traning Loss: tensor(0.0583)\n",
      "9214 Traning Loss: tensor(0.0583)\n",
      "9215 Traning Loss: tensor(0.0582)\n",
      "9216 Traning Loss: tensor(0.0582)\n",
      "9217 Traning Loss: tensor(0.0583)\n",
      "9218 Traning Loss: tensor(0.0583)\n",
      "9219 Traning Loss: tensor(0.0584)\n",
      "9220 Traning Loss: tensor(0.0585)\n",
      "9221 Traning Loss: tensor(0.0587)\n",
      "9222 Traning Loss: tensor(0.0588)\n",
      "9223 Traning Loss: tensor(0.0591)\n",
      "9224 Traning Loss: tensor(0.0593)\n",
      "9225 Traning Loss: tensor(0.0596)\n",
      "9226 Traning Loss: tensor(0.0598)\n",
      "9227 Traning Loss: tensor(0.0599)\n",
      "9228 Traning Loss: tensor(0.0598)\n",
      "9229 Traning Loss: tensor(0.0595)\n",
      "9230 Traning Loss: tensor(0.0590)\n",
      "9231 Traning Loss: tensor(0.0584)\n",
      "9232 Traning Loss: tensor(0.0580)\n",
      "9233 Traning Loss: tensor(0.0577)\n",
      "9234 Traning Loss: tensor(0.0576)\n",
      "9235 Traning Loss: tensor(0.0577)\n",
      "9236 Traning Loss: tensor(0.0579)\n",
      "9237 Traning Loss: tensor(0.0581)\n",
      "9238 Traning Loss: tensor(0.0582)\n",
      "9239 Traning Loss: tensor(0.0581)\n",
      "9240 Traning Loss: tensor(0.0580)\n",
      "9241 Traning Loss: tensor(0.0578)\n",
      "9242 Traning Loss: tensor(0.0576)\n",
      "9243 Traning Loss: tensor(0.0574)\n",
      "9244 Traning Loss: tensor(0.0574)\n",
      "9245 Traning Loss: tensor(0.0574)\n",
      "9246 Traning Loss: tensor(0.0574)\n",
      "9247 Traning Loss: tensor(0.0575)\n",
      "9248 Traning Loss: tensor(0.0575)\n",
      "9249 Traning Loss: tensor(0.0575)\n",
      "9250 Traning Loss: tensor(0.0574)\n",
      "9251 Traning Loss: tensor(0.0574)\n",
      "9252 Traning Loss: tensor(0.0573)\n",
      "9253 Traning Loss: tensor(0.0572)\n",
      "9254 Traning Loss: tensor(0.0571)\n",
      "9255 Traning Loss: tensor(0.0571)\n",
      "9256 Traning Loss: tensor(0.0571)\n",
      "9257 Traning Loss: tensor(0.0571)\n",
      "9258 Traning Loss: tensor(0.0571)\n",
      "9259 Traning Loss: tensor(0.0571)\n",
      "9260 Traning Loss: tensor(0.0571)\n",
      "9261 Traning Loss: tensor(0.0571)\n",
      "9262 Traning Loss: tensor(0.0570)\n",
      "9263 Traning Loss: tensor(0.0570)\n",
      "9264 Traning Loss: tensor(0.0569)\n",
      "9265 Traning Loss: tensor(0.0569)\n",
      "9266 Traning Loss: tensor(0.0569)\n",
      "9267 Traning Loss: tensor(0.0568)\n",
      "9268 Traning Loss: tensor(0.0568)\n",
      "9269 Traning Loss: tensor(0.0568)\n",
      "9270 Traning Loss: tensor(0.0568)\n",
      "9271 Traning Loss: tensor(0.0568)\n",
      "9272 Traning Loss: tensor(0.0567)\n",
      "9273 Traning Loss: tensor(0.0567)\n",
      "9274 Traning Loss: tensor(0.0567)\n",
      "9275 Traning Loss: tensor(0.0567)\n",
      "9276 Traning Loss: tensor(0.0566)\n",
      "9277 Traning Loss: tensor(0.0566)\n",
      "9278 Traning Loss: tensor(0.0566)\n",
      "9279 Traning Loss: tensor(0.0566)\n",
      "9280 Traning Loss: tensor(0.0565)\n",
      "9281 Traning Loss: tensor(0.0565)\n",
      "9282 Traning Loss: tensor(0.0565)\n",
      "9283 Traning Loss: tensor(0.0565)\n",
      "9284 Traning Loss: tensor(0.0564)\n",
      "9285 Traning Loss: tensor(0.0564)\n",
      "9286 Traning Loss: tensor(0.0564)\n",
      "9287 Traning Loss: tensor(0.0564)\n",
      "9288 Traning Loss: tensor(0.0563)\n",
      "9289 Traning Loss: tensor(0.0563)\n",
      "9290 Traning Loss: tensor(0.0563)\n",
      "9291 Traning Loss: tensor(0.0563)\n",
      "9292 Traning Loss: tensor(0.0563)\n",
      "9293 Traning Loss: tensor(0.0562)\n",
      "9294 Traning Loss: tensor(0.0562)\n",
      "9295 Traning Loss: tensor(0.0562)\n",
      "9296 Traning Loss: tensor(0.0562)\n",
      "9297 Traning Loss: tensor(0.0561)\n",
      "9298 Traning Loss: tensor(0.0561)\n",
      "9299 Traning Loss: tensor(0.0561)\n",
      "9300 Traning Loss: tensor(0.0561)\n",
      "9301 Traning Loss: tensor(0.0561)\n",
      "9302 Traning Loss: tensor(0.0560)\n",
      "9303 Traning Loss: tensor(0.0560)\n",
      "9304 Traning Loss: tensor(0.0560)\n",
      "9305 Traning Loss: tensor(0.0560)\n",
      "9306 Traning Loss: tensor(0.0560)\n",
      "9307 Traning Loss: tensor(0.0560)\n",
      "9308 Traning Loss: tensor(0.0560)\n",
      "9309 Traning Loss: tensor(0.0560)\n",
      "9310 Traning Loss: tensor(0.0561)\n",
      "9311 Traning Loss: tensor(0.0562)\n",
      "9312 Traning Loss: tensor(0.0563)\n",
      "9313 Traning Loss: tensor(0.0566)\n",
      "9314 Traning Loss: tensor(0.0569)\n",
      "9315 Traning Loss: tensor(0.0574)\n",
      "9316 Traning Loss: tensor(0.0580)\n",
      "9317 Traning Loss: tensor(0.0587)\n",
      "9318 Traning Loss: tensor(0.0594)\n",
      "9319 Traning Loss: tensor(0.0598)\n",
      "9320 Traning Loss: tensor(0.0596)\n",
      "9321 Traning Loss: tensor(0.0586)\n",
      "9322 Traning Loss: tensor(0.0573)\n",
      "9323 Traning Loss: tensor(0.0561)\n",
      "9324 Traning Loss: tensor(0.0555)\n",
      "9325 Traning Loss: tensor(0.0558)\n",
      "9326 Traning Loss: tensor(0.0564)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9327 Traning Loss: tensor(0.0569)\n",
      "9328 Traning Loss: tensor(0.0570)\n",
      "9329 Traning Loss: tensor(0.0566)\n",
      "9330 Traning Loss: tensor(0.0559)\n",
      "9331 Traning Loss: tensor(0.0554)\n",
      "9332 Traning Loss: tensor(0.0554)\n",
      "9333 Traning Loss: tensor(0.0556)\n",
      "9334 Traning Loss: tensor(0.0559)\n",
      "9335 Traning Loss: tensor(0.0560)\n",
      "9336 Traning Loss: tensor(0.0559)\n",
      "9337 Traning Loss: tensor(0.0555)\n",
      "9338 Traning Loss: tensor(0.0553)\n",
      "9339 Traning Loss: tensor(0.0552)\n",
      "9340 Traning Loss: tensor(0.0553)\n",
      "9341 Traning Loss: tensor(0.0554)\n",
      "9342 Traning Loss: tensor(0.0555)\n",
      "9343 Traning Loss: tensor(0.0554)\n",
      "9344 Traning Loss: tensor(0.0553)\n",
      "9345 Traning Loss: tensor(0.0551)\n",
      "9346 Traning Loss: tensor(0.0550)\n",
      "9347 Traning Loss: tensor(0.0550)\n",
      "9348 Traning Loss: tensor(0.0551)\n",
      "9349 Traning Loss: tensor(0.0551)\n",
      "9350 Traning Loss: tensor(0.0551)\n",
      "9351 Traning Loss: tensor(0.0550)\n",
      "9352 Traning Loss: tensor(0.0549)\n",
      "9353 Traning Loss: tensor(0.0549)\n",
      "9354 Traning Loss: tensor(0.0549)\n",
      "9355 Traning Loss: tensor(0.0549)\n",
      "9356 Traning Loss: tensor(0.0549)\n",
      "9357 Traning Loss: tensor(0.0549)\n",
      "9358 Traning Loss: tensor(0.0548)\n",
      "9359 Traning Loss: tensor(0.0548)\n",
      "9360 Traning Loss: tensor(0.0547)\n",
      "9361 Traning Loss: tensor(0.0547)\n",
      "9362 Traning Loss: tensor(0.0547)\n",
      "9363 Traning Loss: tensor(0.0547)\n",
      "9364 Traning Loss: tensor(0.0547)\n",
      "9365 Traning Loss: tensor(0.0546)\n",
      "9366 Traning Loss: tensor(0.0546)\n",
      "9367 Traning Loss: tensor(0.0546)\n",
      "9368 Traning Loss: tensor(0.0546)\n",
      "9369 Traning Loss: tensor(0.0545)\n",
      "9370 Traning Loss: tensor(0.0545)\n",
      "9371 Traning Loss: tensor(0.0545)\n",
      "9372 Traning Loss: tensor(0.0545)\n",
      "9373 Traning Loss: tensor(0.0545)\n",
      "9374 Traning Loss: tensor(0.0545)\n",
      "9375 Traning Loss: tensor(0.0545)\n",
      "9376 Traning Loss: tensor(0.0545)\n",
      "9377 Traning Loss: tensor(0.0545)\n",
      "9378 Traning Loss: tensor(0.0545)\n",
      "9379 Traning Loss: tensor(0.0546)\n",
      "9380 Traning Loss: tensor(0.0546)\n",
      "9381 Traning Loss: tensor(0.0546)\n",
      "9382 Traning Loss: tensor(0.0546)\n",
      "9383 Traning Loss: tensor(0.0545)\n",
      "9384 Traning Loss: tensor(0.0543)\n",
      "9385 Traning Loss: tensor(0.0542)\n",
      "9386 Traning Loss: tensor(0.0541)\n",
      "9387 Traning Loss: tensor(0.0542)\n",
      "9388 Traning Loss: tensor(0.0542)\n",
      "9389 Traning Loss: tensor(0.0542)\n",
      "9390 Traning Loss: tensor(0.0542)\n",
      "9391 Traning Loss: tensor(0.0541)\n",
      "9392 Traning Loss: tensor(0.0541)\n",
      "9393 Traning Loss: tensor(0.0540)\n",
      "9394 Traning Loss: tensor(0.0540)\n",
      "9395 Traning Loss: tensor(0.0540)\n",
      "9396 Traning Loss: tensor(0.0540)\n",
      "9397 Traning Loss: tensor(0.0540)\n",
      "9398 Traning Loss: tensor(0.0539)\n",
      "9399 Traning Loss: tensor(0.0539)\n",
      "9400 Traning Loss: tensor(0.0538)\n",
      "9401 Traning Loss: tensor(0.0538)\n",
      "9402 Traning Loss: tensor(0.0538)\n",
      "9403 Traning Loss: tensor(0.0538)\n",
      "9404 Traning Loss: tensor(0.0538)\n",
      "9405 Traning Loss: tensor(0.0538)\n",
      "9406 Traning Loss: tensor(0.0537)\n",
      "9407 Traning Loss: tensor(0.0537)\n",
      "9408 Traning Loss: tensor(0.0537)\n",
      "9409 Traning Loss: tensor(0.0536)\n",
      "9410 Traning Loss: tensor(0.0536)\n",
      "9411 Traning Loss: tensor(0.0536)\n",
      "9412 Traning Loss: tensor(0.0536)\n",
      "9413 Traning Loss: tensor(0.0536)\n",
      "9414 Traning Loss: tensor(0.0535)\n",
      "9415 Traning Loss: tensor(0.0535)\n",
      "9416 Traning Loss: tensor(0.0535)\n",
      "9417 Traning Loss: tensor(0.0535)\n",
      "9418 Traning Loss: tensor(0.0535)\n",
      "9419 Traning Loss: tensor(0.0534)\n",
      "9420 Traning Loss: tensor(0.0534)\n",
      "9421 Traning Loss: tensor(0.0534)\n",
      "9422 Traning Loss: tensor(0.0534)\n",
      "9423 Traning Loss: tensor(0.0533)\n",
      "9424 Traning Loss: tensor(0.0533)\n",
      "9425 Traning Loss: tensor(0.0533)\n",
      "9426 Traning Loss: tensor(0.0533)\n",
      "9427 Traning Loss: tensor(0.0533)\n",
      "9428 Traning Loss: tensor(0.0532)\n",
      "9429 Traning Loss: tensor(0.0532)\n",
      "9430 Traning Loss: tensor(0.0532)\n",
      "9431 Traning Loss: tensor(0.0532)\n",
      "9432 Traning Loss: tensor(0.0531)\n",
      "9433 Traning Loss: tensor(0.0531)\n",
      "9434 Traning Loss: tensor(0.0531)\n",
      "9435 Traning Loss: tensor(0.0531)\n",
      "9436 Traning Loss: tensor(0.0531)\n",
      "9437 Traning Loss: tensor(0.0530)\n",
      "9438 Traning Loss: tensor(0.0530)\n",
      "9439 Traning Loss: tensor(0.0530)\n",
      "9440 Traning Loss: tensor(0.0530)\n",
      "9441 Traning Loss: tensor(0.0530)\n",
      "9442 Traning Loss: tensor(0.0529)\n",
      "9443 Traning Loss: tensor(0.0529)\n",
      "9444 Traning Loss: tensor(0.0529)\n",
      "9445 Traning Loss: tensor(0.0529)\n",
      "9446 Traning Loss: tensor(0.0528)\n",
      "9447 Traning Loss: tensor(0.0528)\n",
      "9448 Traning Loss: tensor(0.0528)\n",
      "9449 Traning Loss: tensor(0.0528)\n",
      "9450 Traning Loss: tensor(0.0528)\n",
      "9451 Traning Loss: tensor(0.0528)\n",
      "9452 Traning Loss: tensor(0.0528)\n",
      "9453 Traning Loss: tensor(0.0528)\n",
      "9454 Traning Loss: tensor(0.0528)\n",
      "9455 Traning Loss: tensor(0.0528)\n",
      "9456 Traning Loss: tensor(0.0529)\n",
      "9457 Traning Loss: tensor(0.0531)\n",
      "9458 Traning Loss: tensor(0.0534)\n",
      "9459 Traning Loss: tensor(0.0539)\n",
      "9460 Traning Loss: tensor(0.0547)\n",
      "9461 Traning Loss: tensor(0.0559)\n",
      "9462 Traning Loss: tensor(0.0574)\n",
      "9463 Traning Loss: tensor(0.0591)\n",
      "9464 Traning Loss: tensor(0.0600)\n",
      "9465 Traning Loss: tensor(0.0596)\n",
      "9466 Traning Loss: tensor(0.0570)\n",
      "9467 Traning Loss: tensor(0.0540)\n",
      "9468 Traning Loss: tensor(0.0524)\n",
      "9469 Traning Loss: tensor(0.0530)\n",
      "9470 Traning Loss: tensor(0.0547)\n",
      "9471 Traning Loss: tensor(0.0556)\n",
      "9472 Traning Loss: tensor(0.0550)\n",
      "9473 Traning Loss: tensor(0.0533)\n",
      "9474 Traning Loss: tensor(0.0523)\n",
      "9475 Traning Loss: tensor(0.0526)\n",
      "9476 Traning Loss: tensor(0.0536)\n",
      "9477 Traning Loss: tensor(0.0540)\n",
      "9478 Traning Loss: tensor(0.0534)\n",
      "9479 Traning Loss: tensor(0.0524)\n",
      "9480 Traning Loss: tensor(0.0522)\n",
      "9481 Traning Loss: tensor(0.0526)\n",
      "9482 Traning Loss: tensor(0.0530)\n",
      "9483 Traning Loss: tensor(0.0530)\n",
      "9484 Traning Loss: tensor(0.0525)\n",
      "9485 Traning Loss: tensor(0.0521)\n",
      "9486 Traning Loss: tensor(0.0521)\n",
      "9487 Traning Loss: tensor(0.0524)\n",
      "9488 Traning Loss: tensor(0.0525)\n",
      "9489 Traning Loss: tensor(0.0523)\n",
      "9490 Traning Loss: tensor(0.0520)\n",
      "9491 Traning Loss: tensor(0.0519)\n",
      "9492 Traning Loss: tensor(0.0521)\n",
      "9493 Traning Loss: tensor(0.0522)\n",
      "9494 Traning Loss: tensor(0.0521)\n",
      "9495 Traning Loss: tensor(0.0520)\n",
      "9496 Traning Loss: tensor(0.0518)\n",
      "9497 Traning Loss: tensor(0.0518)\n",
      "9498 Traning Loss: tensor(0.0519)\n",
      "9499 Traning Loss: tensor(0.0519)\n",
      "9500 Traning Loss: tensor(0.0519)\n",
      "9501 Traning Loss: tensor(0.0518)\n",
      "9502 Traning Loss: tensor(0.0517)\n",
      "9503 Traning Loss: tensor(0.0517)\n",
      "9504 Traning Loss: tensor(0.0518)\n",
      "9505 Traning Loss: tensor(0.0517)\n",
      "9506 Traning Loss: tensor(0.0517)\n",
      "9507 Traning Loss: tensor(0.0516)\n",
      "9508 Traning Loss: tensor(0.0516)\n",
      "9509 Traning Loss: tensor(0.0516)\n",
      "9510 Traning Loss: tensor(0.0516)\n",
      "9511 Traning Loss: tensor(0.0516)\n",
      "9512 Traning Loss: tensor(0.0515)\n",
      "9513 Traning Loss: tensor(0.0515)\n",
      "9514 Traning Loss: tensor(0.0515)\n",
      "9515 Traning Loss: tensor(0.0515)\n",
      "9516 Traning Loss: tensor(0.0515)\n",
      "9517 Traning Loss: tensor(0.0514)\n",
      "9518 Traning Loss: tensor(0.0514)\n",
      "9519 Traning Loss: tensor(0.0514)\n",
      "9520 Traning Loss: tensor(0.0513)\n",
      "9521 Traning Loss: tensor(0.0513)\n",
      "9522 Traning Loss: tensor(0.0513)\n",
      "9523 Traning Loss: tensor(0.0513)\n",
      "9524 Traning Loss: tensor(0.0513)\n",
      "9525 Traning Loss: tensor(0.0512)\n",
      "9526 Traning Loss: tensor(0.0512)\n",
      "9527 Traning Loss: tensor(0.0512)\n",
      "9528 Traning Loss: tensor(0.0512)\n",
      "9529 Traning Loss: tensor(0.0512)\n",
      "9530 Traning Loss: tensor(0.0511)\n",
      "9531 Traning Loss: tensor(0.0511)\n",
      "9532 Traning Loss: tensor(0.0511)\n",
      "9533 Traning Loss: tensor(0.0511)\n",
      "9534 Traning Loss: tensor(0.0511)\n",
      "9535 Traning Loss: tensor(0.0510)\n",
      "9536 Traning Loss: tensor(0.0510)\n",
      "9537 Traning Loss: tensor(0.0510)\n",
      "9538 Traning Loss: tensor(0.0510)\n",
      "9539 Traning Loss: tensor(0.0510)\n",
      "9540 Traning Loss: tensor(0.0509)\n",
      "9541 Traning Loss: tensor(0.0509)\n",
      "9542 Traning Loss: tensor(0.0509)\n",
      "9543 Traning Loss: tensor(0.0509)\n",
      "9544 Traning Loss: tensor(0.0509)\n",
      "9545 Traning Loss: tensor(0.0508)\n",
      "9546 Traning Loss: tensor(0.0508)\n",
      "9547 Traning Loss: tensor(0.0508)\n",
      "9548 Traning Loss: tensor(0.0508)\n",
      "9549 Traning Loss: tensor(0.0508)\n",
      "9550 Traning Loss: tensor(0.0507)\n",
      "9551 Traning Loss: tensor(0.0507)\n",
      "9552 Traning Loss: tensor(0.0507)\n",
      "9553 Traning Loss: tensor(0.0507)\n",
      "9554 Traning Loss: tensor(0.0507)\n",
      "9555 Traning Loss: tensor(0.0507)\n",
      "9556 Traning Loss: tensor(0.0507)\n",
      "9557 Traning Loss: tensor(0.0507)\n",
      "9558 Traning Loss: tensor(0.0507)\n",
      "9559 Traning Loss: tensor(0.0508)\n",
      "9560 Traning Loss: tensor(0.0509)\n",
      "9561 Traning Loss: tensor(0.0510)\n",
      "9562 Traning Loss: tensor(0.0512)\n",
      "9563 Traning Loss: tensor(0.0513)\n",
      "9564 Traning Loss: tensor(0.0512)\n",
      "9565 Traning Loss: tensor(0.0509)\n",
      "9566 Traning Loss: tensor(0.0505)\n",
      "9567 Traning Loss: tensor(0.0504)\n",
      "9568 Traning Loss: tensor(0.0505)\n",
      "9569 Traning Loss: tensor(0.0507)\n",
      "9570 Traning Loss: tensor(0.0507)\n",
      "9571 Traning Loss: tensor(0.0505)\n",
      "9572 Traning Loss: tensor(0.0503)\n",
      "9573 Traning Loss: tensor(0.0503)\n",
      "9574 Traning Loss: tensor(0.0504)\n",
      "9575 Traning Loss: tensor(0.0504)\n",
      "9576 Traning Loss: tensor(0.0504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9577 Traning Loss: tensor(0.0503)\n",
      "9578 Traning Loss: tensor(0.0502)\n",
      "9579 Traning Loss: tensor(0.0502)\n",
      "9580 Traning Loss: tensor(0.0503)\n",
      "9581 Traning Loss: tensor(0.0502)\n",
      "9582 Traning Loss: tensor(0.0502)\n",
      "9583 Traning Loss: tensor(0.0501)\n",
      "9584 Traning Loss: tensor(0.0501)\n",
      "9585 Traning Loss: tensor(0.0501)\n",
      "9586 Traning Loss: tensor(0.0501)\n",
      "9587 Traning Loss: tensor(0.0501)\n",
      "9588 Traning Loss: tensor(0.0500)\n",
      "9589 Traning Loss: tensor(0.0500)\n",
      "9590 Traning Loss: tensor(0.0500)\n",
      "9591 Traning Loss: tensor(0.0500)\n",
      "9592 Traning Loss: tensor(0.0500)\n",
      "9593 Traning Loss: tensor(0.0499)\n",
      "9594 Traning Loss: tensor(0.0499)\n",
      "9595 Traning Loss: tensor(0.0499)\n",
      "9596 Traning Loss: tensor(0.0499)\n",
      "9597 Traning Loss: tensor(0.0498)\n",
      "9598 Traning Loss: tensor(0.0498)\n",
      "9599 Traning Loss: tensor(0.0498)\n",
      "9600 Traning Loss: tensor(0.0498)\n",
      "9601 Traning Loss: tensor(0.0498)\n",
      "9602 Traning Loss: tensor(0.0497)\n",
      "9603 Traning Loss: tensor(0.0497)\n",
      "9604 Traning Loss: tensor(0.0497)\n",
      "9605 Traning Loss: tensor(0.0497)\n",
      "9606 Traning Loss: tensor(0.0497)\n",
      "9607 Traning Loss: tensor(0.0496)\n",
      "9608 Traning Loss: tensor(0.0496)\n",
      "9609 Traning Loss: tensor(0.0496)\n",
      "9610 Traning Loss: tensor(0.0496)\n",
      "9611 Traning Loss: tensor(0.0496)\n",
      "9612 Traning Loss: tensor(0.0495)\n",
      "9613 Traning Loss: tensor(0.0495)\n",
      "9614 Traning Loss: tensor(0.0495)\n",
      "9615 Traning Loss: tensor(0.0495)\n",
      "9616 Traning Loss: tensor(0.0495)\n",
      "9617 Traning Loss: tensor(0.0494)\n",
      "9618 Traning Loss: tensor(0.0494)\n",
      "9619 Traning Loss: tensor(0.0494)\n",
      "9620 Traning Loss: tensor(0.0494)\n",
      "9621 Traning Loss: tensor(0.0494)\n",
      "9622 Traning Loss: tensor(0.0494)\n",
      "9623 Traning Loss: tensor(0.0493)\n",
      "9624 Traning Loss: tensor(0.0493)\n",
      "9625 Traning Loss: tensor(0.0493)\n",
      "9626 Traning Loss: tensor(0.0493)\n",
      "9627 Traning Loss: tensor(0.0493)\n",
      "9628 Traning Loss: tensor(0.0492)\n",
      "9629 Traning Loss: tensor(0.0492)\n",
      "9630 Traning Loss: tensor(0.0492)\n",
      "9631 Traning Loss: tensor(0.0492)\n",
      "9632 Traning Loss: tensor(0.0492)\n",
      "9633 Traning Loss: tensor(0.0491)\n",
      "9634 Traning Loss: tensor(0.0491)\n",
      "9635 Traning Loss: tensor(0.0491)\n",
      "9636 Traning Loss: tensor(0.0491)\n",
      "9637 Traning Loss: tensor(0.0491)\n",
      "9638 Traning Loss: tensor(0.0490)\n",
      "9639 Traning Loss: tensor(0.0490)\n",
      "9640 Traning Loss: tensor(0.0490)\n",
      "9641 Traning Loss: tensor(0.0490)\n",
      "9642 Traning Loss: tensor(0.0490)\n",
      "9643 Traning Loss: tensor(0.0490)\n",
      "9644 Traning Loss: tensor(0.0489)\n",
      "9645 Traning Loss: tensor(0.0489)\n",
      "9646 Traning Loss: tensor(0.0489)\n",
      "9647 Traning Loss: tensor(0.0489)\n",
      "9648 Traning Loss: tensor(0.0489)\n",
      "9649 Traning Loss: tensor(0.0489)\n",
      "9650 Traning Loss: tensor(0.0488)\n",
      "9651 Traning Loss: tensor(0.0488)\n",
      "9652 Traning Loss: tensor(0.0488)\n",
      "9653 Traning Loss: tensor(0.0488)\n",
      "9654 Traning Loss: tensor(0.0489)\n",
      "9655 Traning Loss: tensor(0.0489)\n",
      "9656 Traning Loss: tensor(0.0490)\n",
      "9657 Traning Loss: tensor(0.0492)\n",
      "9658 Traning Loss: tensor(0.0495)\n",
      "9659 Traning Loss: tensor(0.0500)\n",
      "9660 Traning Loss: tensor(0.0507)\n",
      "9661 Traning Loss: tensor(0.0517)\n",
      "9662 Traning Loss: tensor(0.0530)\n",
      "9663 Traning Loss: tensor(0.0545)\n",
      "9664 Traning Loss: tensor(0.0553)\n",
      "9665 Traning Loss: tensor(0.0551)\n",
      "9666 Traning Loss: tensor(0.0532)\n",
      "9667 Traning Loss: tensor(0.0506)\n",
      "9668 Traning Loss: tensor(0.0487)\n",
      "9669 Traning Loss: tensor(0.0487)\n",
      "9670 Traning Loss: tensor(0.0499)\n",
      "9671 Traning Loss: tensor(0.0511)\n",
      "9672 Traning Loss: tensor(0.0512)\n",
      "9673 Traning Loss: tensor(0.0501)\n",
      "9674 Traning Loss: tensor(0.0488)\n",
      "9675 Traning Loss: tensor(0.0484)\n",
      "9676 Traning Loss: tensor(0.0489)\n",
      "9677 Traning Loss: tensor(0.0496)\n",
      "9678 Traning Loss: tensor(0.0498)\n",
      "9679 Traning Loss: tensor(0.0492)\n",
      "9680 Traning Loss: tensor(0.0485)\n",
      "9681 Traning Loss: tensor(0.0483)\n",
      "9682 Traning Loss: tensor(0.0485)\n",
      "9683 Traning Loss: tensor(0.0489)\n",
      "9684 Traning Loss: tensor(0.0490)\n",
      "9685 Traning Loss: tensor(0.0486)\n",
      "9686 Traning Loss: tensor(0.0483)\n",
      "9687 Traning Loss: tensor(0.0482)\n",
      "9688 Traning Loss: tensor(0.0483)\n",
      "9689 Traning Loss: tensor(0.0485)\n",
      "9690 Traning Loss: tensor(0.0485)\n",
      "9691 Traning Loss: tensor(0.0483)\n",
      "9692 Traning Loss: tensor(0.0481)\n",
      "9693 Traning Loss: tensor(0.0480)\n",
      "9694 Traning Loss: tensor(0.0481)\n",
      "9695 Traning Loss: tensor(0.0482)\n",
      "9696 Traning Loss: tensor(0.0482)\n",
      "9697 Traning Loss: tensor(0.0481)\n",
      "9698 Traning Loss: tensor(0.0480)\n",
      "9699 Traning Loss: tensor(0.0479)\n",
      "9700 Traning Loss: tensor(0.0480)\n",
      "9701 Traning Loss: tensor(0.0480)\n",
      "9702 Traning Loss: tensor(0.0480)\n",
      "9703 Traning Loss: tensor(0.0479)\n",
      "9704 Traning Loss: tensor(0.0479)\n",
      "9705 Traning Loss: tensor(0.0478)\n",
      "9706 Traning Loss: tensor(0.0478)\n",
      "9707 Traning Loss: tensor(0.0479)\n",
      "9708 Traning Loss: tensor(0.0478)\n",
      "9709 Traning Loss: tensor(0.0478)\n",
      "9710 Traning Loss: tensor(0.0478)\n",
      "9711 Traning Loss: tensor(0.0477)\n",
      "9712 Traning Loss: tensor(0.0477)\n",
      "9713 Traning Loss: tensor(0.0477)\n",
      "9714 Traning Loss: tensor(0.0477)\n",
      "9715 Traning Loss: tensor(0.0477)\n",
      "9716 Traning Loss: tensor(0.0476)\n",
      "9717 Traning Loss: tensor(0.0476)\n",
      "9718 Traning Loss: tensor(0.0476)\n",
      "9719 Traning Loss: tensor(0.0476)\n",
      "9720 Traning Loss: tensor(0.0476)\n",
      "9721 Traning Loss: tensor(0.0476)\n",
      "9722 Traning Loss: tensor(0.0475)\n",
      "9723 Traning Loss: tensor(0.0475)\n",
      "9724 Traning Loss: tensor(0.0475)\n",
      "9725 Traning Loss: tensor(0.0475)\n",
      "9726 Traning Loss: tensor(0.0475)\n",
      "9727 Traning Loss: tensor(0.0474)\n",
      "9728 Traning Loss: tensor(0.0474)\n",
      "9729 Traning Loss: tensor(0.0474)\n",
      "9730 Traning Loss: tensor(0.0474)\n",
      "9731 Traning Loss: tensor(0.0474)\n",
      "9732 Traning Loss: tensor(0.0473)\n",
      "9733 Traning Loss: tensor(0.0473)\n",
      "9734 Traning Loss: tensor(0.0473)\n",
      "9735 Traning Loss: tensor(0.0473)\n",
      "9736 Traning Loss: tensor(0.0473)\n",
      "9737 Traning Loss: tensor(0.0473)\n",
      "9738 Traning Loss: tensor(0.0472)\n",
      "9739 Traning Loss: tensor(0.0472)\n",
      "9740 Traning Loss: tensor(0.0472)\n",
      "9741 Traning Loss: tensor(0.0472)\n",
      "9742 Traning Loss: tensor(0.0472)\n",
      "9743 Traning Loss: tensor(0.0472)\n",
      "9744 Traning Loss: tensor(0.0471)\n",
      "9745 Traning Loss: tensor(0.0471)\n",
      "9746 Traning Loss: tensor(0.0471)\n",
      "9747 Traning Loss: tensor(0.0471)\n",
      "9748 Traning Loss: tensor(0.0471)\n",
      "9749 Traning Loss: tensor(0.0470)\n",
      "9750 Traning Loss: tensor(0.0470)\n",
      "9751 Traning Loss: tensor(0.0470)\n",
      "9752 Traning Loss: tensor(0.0470)\n",
      "9753 Traning Loss: tensor(0.0470)\n",
      "9754 Traning Loss: tensor(0.0470)\n",
      "9755 Traning Loss: tensor(0.0469)\n",
      "9756 Traning Loss: tensor(0.0469)\n",
      "9757 Traning Loss: tensor(0.0469)\n",
      "9758 Traning Loss: tensor(0.0469)\n",
      "9759 Traning Loss: tensor(0.0469)\n",
      "9760 Traning Loss: tensor(0.0469)\n",
      "9761 Traning Loss: tensor(0.0468)\n",
      "9762 Traning Loss: tensor(0.0468)\n",
      "9763 Traning Loss: tensor(0.0468)\n",
      "9764 Traning Loss: tensor(0.0468)\n",
      "9765 Traning Loss: tensor(0.0468)\n",
      "9766 Traning Loss: tensor(0.0467)\n",
      "9767 Traning Loss: tensor(0.0467)\n",
      "9768 Traning Loss: tensor(0.0467)\n",
      "9769 Traning Loss: tensor(0.0467)\n",
      "9770 Traning Loss: tensor(0.0467)\n",
      "9771 Traning Loss: tensor(0.0467)\n",
      "9772 Traning Loss: tensor(0.0466)\n",
      "9773 Traning Loss: tensor(0.0466)\n",
      "9774 Traning Loss: tensor(0.0466)\n",
      "9775 Traning Loss: tensor(0.0466)\n",
      "9776 Traning Loss: tensor(0.0466)\n",
      "9777 Traning Loss: tensor(0.0466)\n",
      "9778 Traning Loss: tensor(0.0465)\n",
      "9779 Traning Loss: tensor(0.0465)\n",
      "9780 Traning Loss: tensor(0.0465)\n",
      "9781 Traning Loss: tensor(0.0465)\n",
      "9782 Traning Loss: tensor(0.0465)\n",
      "9783 Traning Loss: tensor(0.0464)\n",
      "9784 Traning Loss: tensor(0.0464)\n",
      "9785 Traning Loss: tensor(0.0464)\n",
      "9786 Traning Loss: tensor(0.0464)\n",
      "9787 Traning Loss: tensor(0.0464)\n",
      "9788 Traning Loss: tensor(0.0464)\n",
      "9789 Traning Loss: tensor(0.0463)\n",
      "9790 Traning Loss: tensor(0.0463)\n",
      "9791 Traning Loss: tensor(0.0463)\n",
      "9792 Traning Loss: tensor(0.0463)\n",
      "9793 Traning Loss: tensor(0.0463)\n",
      "9794 Traning Loss: tensor(0.0463)\n",
      "9795 Traning Loss: tensor(0.0463)\n",
      "9796 Traning Loss: tensor(0.0462)\n",
      "9797 Traning Loss: tensor(0.0462)\n",
      "9798 Traning Loss: tensor(0.0462)\n",
      "9799 Traning Loss: tensor(0.0463)\n",
      "9800 Traning Loss: tensor(0.0463)\n",
      "9801 Traning Loss: tensor(0.0464)\n",
      "9802 Traning Loss: tensor(0.0465)\n",
      "9803 Traning Loss: tensor(0.0467)\n",
      "9804 Traning Loss: tensor(0.0468)\n",
      "9805 Traning Loss: tensor(0.0468)\n",
      "9806 Traning Loss: tensor(0.0466)\n",
      "9807 Traning Loss: tensor(0.0463)\n",
      "9808 Traning Loss: tensor(0.0461)\n",
      "9809 Traning Loss: tensor(0.0460)\n",
      "9810 Traning Loss: tensor(0.0461)\n",
      "9811 Traning Loss: tensor(0.0463)\n",
      "9812 Traning Loss: tensor(0.0463)\n",
      "9813 Traning Loss: tensor(0.0461)\n",
      "9814 Traning Loss: tensor(0.0460)\n",
      "9815 Traning Loss: tensor(0.0459)\n",
      "9816 Traning Loss: tensor(0.0460)\n",
      "9817 Traning Loss: tensor(0.0460)\n",
      "9818 Traning Loss: tensor(0.0460)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9819 Traning Loss: tensor(0.0459)\n",
      "9820 Traning Loss: tensor(0.0458)\n",
      "9821 Traning Loss: tensor(0.0458)\n",
      "9822 Traning Loss: tensor(0.0459)\n",
      "9823 Traning Loss: tensor(0.0459)\n",
      "9824 Traning Loss: tensor(0.0459)\n",
      "9825 Traning Loss: tensor(0.0458)\n",
      "9826 Traning Loss: tensor(0.0458)\n",
      "9827 Traning Loss: tensor(0.0458)\n",
      "9828 Traning Loss: tensor(0.0459)\n",
      "9829 Traning Loss: tensor(0.0460)\n",
      "9830 Traning Loss: tensor(0.0460)\n",
      "9831 Traning Loss: tensor(0.0461)\n",
      "9832 Traning Loss: tensor(0.0463)\n",
      "9833 Traning Loss: tensor(0.0466)\n",
      "9834 Traning Loss: tensor(0.0470)\n",
      "9835 Traning Loss: tensor(0.0475)\n",
      "9836 Traning Loss: tensor(0.0481)\n",
      "9837 Traning Loss: tensor(0.0488)\n",
      "9838 Traning Loss: tensor(0.0493)\n",
      "9839 Traning Loss: tensor(0.0495)\n",
      "9840 Traning Loss: tensor(0.0491)\n",
      "9841 Traning Loss: tensor(0.0482)\n",
      "9842 Traning Loss: tensor(0.0469)\n",
      "9843 Traning Loss: tensor(0.0459)\n",
      "9844 Traning Loss: tensor(0.0454)\n",
      "9845 Traning Loss: tensor(0.0456)\n",
      "9846 Traning Loss: tensor(0.0461)\n",
      "9847 Traning Loss: tensor(0.0466)\n",
      "9848 Traning Loss: tensor(0.0468)\n",
      "9849 Traning Loss: tensor(0.0466)\n",
      "9850 Traning Loss: tensor(0.0461)\n",
      "9851 Traning Loss: tensor(0.0456)\n",
      "9852 Traning Loss: tensor(0.0453)\n",
      "9853 Traning Loss: tensor(0.0453)\n",
      "9854 Traning Loss: tensor(0.0456)\n",
      "9855 Traning Loss: tensor(0.0458)\n",
      "9856 Traning Loss: tensor(0.0459)\n",
      "9857 Traning Loss: tensor(0.0457)\n",
      "9858 Traning Loss: tensor(0.0455)\n",
      "9859 Traning Loss: tensor(0.0452)\n",
      "9860 Traning Loss: tensor(0.0451)\n",
      "9861 Traning Loss: tensor(0.0452)\n",
      "9862 Traning Loss: tensor(0.0453)\n",
      "9863 Traning Loss: tensor(0.0454)\n",
      "9864 Traning Loss: tensor(0.0454)\n",
      "9865 Traning Loss: tensor(0.0453)\n",
      "9866 Traning Loss: tensor(0.0452)\n",
      "9867 Traning Loss: tensor(0.0451)\n",
      "9868 Traning Loss: tensor(0.0450)\n",
      "9869 Traning Loss: tensor(0.0450)\n",
      "9870 Traning Loss: tensor(0.0451)\n",
      "9871 Traning Loss: tensor(0.0451)\n",
      "9872 Traning Loss: tensor(0.0451)\n",
      "9873 Traning Loss: tensor(0.0450)\n",
      "9874 Traning Loss: tensor(0.0450)\n",
      "9875 Traning Loss: tensor(0.0449)\n",
      "9876 Traning Loss: tensor(0.0449)\n",
      "9877 Traning Loss: tensor(0.0449)\n",
      "9878 Traning Loss: tensor(0.0449)\n",
      "9879 Traning Loss: tensor(0.0449)\n",
      "9880 Traning Loss: tensor(0.0449)\n",
      "9881 Traning Loss: tensor(0.0449)\n",
      "9882 Traning Loss: tensor(0.0448)\n",
      "9883 Traning Loss: tensor(0.0448)\n",
      "9884 Traning Loss: tensor(0.0448)\n",
      "9885 Traning Loss: tensor(0.0447)\n",
      "9886 Traning Loss: tensor(0.0447)\n",
      "9887 Traning Loss: tensor(0.0447)\n",
      "9888 Traning Loss: tensor(0.0447)\n",
      "9889 Traning Loss: tensor(0.0447)\n",
      "9890 Traning Loss: tensor(0.0447)\n",
      "9891 Traning Loss: tensor(0.0447)\n",
      "9892 Traning Loss: tensor(0.0446)\n",
      "9893 Traning Loss: tensor(0.0446)\n",
      "9894 Traning Loss: tensor(0.0446)\n",
      "9895 Traning Loss: tensor(0.0446)\n",
      "9896 Traning Loss: tensor(0.0446)\n",
      "9897 Traning Loss: tensor(0.0445)\n",
      "9898 Traning Loss: tensor(0.0445)\n",
      "9899 Traning Loss: tensor(0.0445)\n",
      "9900 Traning Loss: tensor(0.0445)\n",
      "9901 Traning Loss: tensor(0.0445)\n",
      "9902 Traning Loss: tensor(0.0445)\n",
      "9903 Traning Loss: tensor(0.0445)\n",
      "9904 Traning Loss: tensor(0.0444)\n",
      "9905 Traning Loss: tensor(0.0444)\n",
      "9906 Traning Loss: tensor(0.0444)\n",
      "9907 Traning Loss: tensor(0.0444)\n",
      "9908 Traning Loss: tensor(0.0444)\n",
      "9909 Traning Loss: tensor(0.0444)\n",
      "9910 Traning Loss: tensor(0.0443)\n",
      "9911 Traning Loss: tensor(0.0443)\n",
      "9912 Traning Loss: tensor(0.0443)\n",
      "9913 Traning Loss: tensor(0.0443)\n",
      "9914 Traning Loss: tensor(0.0443)\n",
      "9915 Traning Loss: tensor(0.0443)\n",
      "9916 Traning Loss: tensor(0.0442)\n",
      "9917 Traning Loss: tensor(0.0442)\n",
      "9918 Traning Loss: tensor(0.0442)\n",
      "9919 Traning Loss: tensor(0.0442)\n",
      "9920 Traning Loss: tensor(0.0442)\n",
      "9921 Traning Loss: tensor(0.0442)\n",
      "9922 Traning Loss: tensor(0.0441)\n",
      "9923 Traning Loss: tensor(0.0441)\n",
      "9924 Traning Loss: tensor(0.0441)\n",
      "9925 Traning Loss: tensor(0.0441)\n",
      "9926 Traning Loss: tensor(0.0441)\n",
      "9927 Traning Loss: tensor(0.0441)\n",
      "9928 Traning Loss: tensor(0.0440)\n",
      "9929 Traning Loss: tensor(0.0440)\n",
      "9930 Traning Loss: tensor(0.0440)\n",
      "9931 Traning Loss: tensor(0.0440)\n",
      "9932 Traning Loss: tensor(0.0440)\n",
      "9933 Traning Loss: tensor(0.0440)\n",
      "9934 Traning Loss: tensor(0.0440)\n",
      "9935 Traning Loss: tensor(0.0439)\n",
      "9936 Traning Loss: tensor(0.0439)\n",
      "9937 Traning Loss: tensor(0.0439)\n",
      "9938 Traning Loss: tensor(0.0439)\n",
      "9939 Traning Loss: tensor(0.0439)\n",
      "9940 Traning Loss: tensor(0.0439)\n",
      "9941 Traning Loss: tensor(0.0438)\n",
      "9942 Traning Loss: tensor(0.0438)\n",
      "9943 Traning Loss: tensor(0.0438)\n",
      "9944 Traning Loss: tensor(0.0438)\n",
      "9945 Traning Loss: tensor(0.0438)\n",
      "9946 Traning Loss: tensor(0.0438)\n",
      "9947 Traning Loss: tensor(0.0437)\n",
      "9948 Traning Loss: tensor(0.0437)\n",
      "9949 Traning Loss: tensor(0.0437)\n",
      "9950 Traning Loss: tensor(0.0437)\n",
      "9951 Traning Loss: tensor(0.0437)\n",
      "9952 Traning Loss: tensor(0.0437)\n",
      "9953 Traning Loss: tensor(0.0437)\n",
      "9954 Traning Loss: tensor(0.0437)\n",
      "9955 Traning Loss: tensor(0.0437)\n",
      "9956 Traning Loss: tensor(0.0437)\n",
      "9957 Traning Loss: tensor(0.0437)\n",
      "9958 Traning Loss: tensor(0.0437)\n",
      "9959 Traning Loss: tensor(0.0438)\n",
      "9960 Traning Loss: tensor(0.0439)\n",
      "9961 Traning Loss: tensor(0.0442)\n",
      "9962 Traning Loss: tensor(0.0446)\n",
      "9963 Traning Loss: tensor(0.0452)\n",
      "9964 Traning Loss: tensor(0.0461)\n",
      "9965 Traning Loss: tensor(0.0474)\n",
      "9966 Traning Loss: tensor(0.0490)\n",
      "9967 Traning Loss: tensor(0.0505)\n",
      "9968 Traning Loss: tensor(0.0513)\n",
      "9969 Traning Loss: tensor(0.0502)\n",
      "9970 Traning Loss: tensor(0.0476)\n",
      "9971 Traning Loss: tensor(0.0447)\n",
      "9972 Traning Loss: tensor(0.0434)\n",
      "9973 Traning Loss: tensor(0.0441)\n",
      "9974 Traning Loss: tensor(0.0457)\n",
      "9975 Traning Loss: tensor(0.0466)\n",
      "9976 Traning Loss: tensor(0.0460)\n",
      "9977 Traning Loss: tensor(0.0445)\n",
      "9978 Traning Loss: tensor(0.0434)\n",
      "9979 Traning Loss: tensor(0.0435)\n",
      "9980 Traning Loss: tensor(0.0444)\n",
      "9981 Traning Loss: tensor(0.0449)\n",
      "9982 Traning Loss: tensor(0.0446)\n",
      "9983 Traning Loss: tensor(0.0438)\n",
      "9984 Traning Loss: tensor(0.0432)\n",
      "9985 Traning Loss: tensor(0.0433)\n",
      "9986 Traning Loss: tensor(0.0438)\n",
      "9987 Traning Loss: tensor(0.0441)\n",
      "9988 Traning Loss: tensor(0.0438)\n",
      "9989 Traning Loss: tensor(0.0433)\n",
      "9990 Traning Loss: tensor(0.0431)\n",
      "9991 Traning Loss: tensor(0.0432)\n",
      "9992 Traning Loss: tensor(0.0435)\n",
      "9993 Traning Loss: tensor(0.0435)\n",
      "9994 Traning Loss: tensor(0.0433)\n",
      "9995 Traning Loss: tensor(0.0431)\n",
      "9996 Traning Loss: tensor(0.0430)\n",
      "9997 Traning Loss: tensor(0.0431)\n",
      "9998 Traning Loss: tensor(0.0432)\n",
      "9999 Traning Loss: tensor(0.0432)\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "for epoch in range(iterations):\n",
    "    optimizer.zero_grad() # to make the gradients zero\n",
    "    \n",
    "    # Loss based on boundary conditions\n",
    "    pt_x_bc = Variable(torch.from_numpy(x_bc).float(), requires_grad=False).to(device)\n",
    "    pt_t_bc = Variable(torch.from_numpy(t_bc).float(), requires_grad=False).to(device)\n",
    "    pt_u_bc = Variable(torch.from_numpy(u_bc).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    net_bc_out = net(pt_x_bc, pt_t_bc) # output of u(x,t)\n",
    "    mse_u = mse_cost_function(net_bc_out, pt_u_bc)\n",
    "    \n",
    "    # Loss based on periodic conditions\n",
    "    pt_x_periodic = Variable(torch.from_numpy(x_periodic).float(), requires_grad=True).to(device)\n",
    "    pt_x_periodic_plusone = Variable(torch.from_numpy(x_periodic_plusone).float(), requires_grad=True).to(device)\n",
    "    pt_x_periodic_minusone = Variable(torch.from_numpy(x_periodic_minusone).float(), requires_grad=True).to(device)\n",
    "    pt_t_periodic = Variable(torch.from_numpy(t_periodic).float(), requires_grad=True).to(device)\n",
    "\n",
    "    \n",
    "    net_periodiccondition_out = net(pt_x_periodic, pt_t_periodic)\n",
    "    net_periodiccondition_out1 = net(pt_x_periodic_plusone, pt_t_periodic)\n",
    "    net_periodiccondition_out2 = net(pt_x_periodic_minusone, pt_t_periodic)\n",
    "    \n",
    "    mse_pc1 = mse_cost_function(net_periodiccondition_out, net_periodiccondition_out1)\n",
    "    mse_pc2 = mse_cost_function(net_periodiccondition_out, net_periodiccondition_out2)\n",
    "    \n",
    "    # Loss based on PDE\n",
    "    pt_x_collocation = Variable(torch.from_numpy(x_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_t_collocation = Variable(torch.from_numpy(t_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_all_zeros = Variable(torch.from_numpy(all_zeros).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    f_out = f(pt_x_collocation, pt_t_collocation, net) # output of f(x,t)\n",
    "    mse_f = mse_cost_function(f_out, pt_all_zeros)\n",
    "    \n",
    "    # Combining the loss functions\n",
    "    loss = alf*mse_f + beta1*mse_u + beta2*mse_pc1+ beta3*mse_pc2\n",
    "    \n",
    "    \n",
    "    loss.backward() # This is for computing gradients using backward propagation\n",
    "    optimizer.step() # This is equivalent to : theta_new = theta_old - alpha * derivative of J w.r.t theta\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "        print(epoch,\"Traning Loss:\",loss.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "x=np.arange(0,1,0.02)\n",
    "t=np.arange(0,1,0.02)\n",
    "ms_x, ms_t = np.meshgrid(x, t)\n",
    "\n",
    "## Just because meshgrid is used, we need to do the following adjustment\n",
    "x = np.ravel(ms_x).reshape(-1,1)\n",
    "t = np.ravel(ms_t).reshape(-1,1)\n",
    "\n",
    "pt_x = Variable(torch.from_numpy(x).float(), requires_grad=True).to(device)\n",
    "pt_t = Variable(torch.from_numpy(t).float(), requires_grad=True).to(device)\n",
    "pt_u = net(pt_x,pt_t)\n",
    "u=pt_u.data.cpu().numpy()\n",
    "ms_u = u.reshape(ms_x.shape)\n",
    "\n",
    "surf = ax.plot_surface(ms_x,ms_t,ms_u, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "             \n",
    "             \n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$t$')\n",
    "ax.set_zlabel('$u(x,t)$')\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
